

# **Recommended Books for Deep Learning Approaches (21CSC558J)
* 1. Charu C. Aggarwal, “Neural Networks and Deep Learning”, Springer, 2018.
* 2. Ian Good Fellow, Yoshua Bengio, Aaron Courville, “Deep Learning”, MIT Press, 2017.
* 3. Francois Chollet, “Deep Learning with Python”, Manning Publications, 2018.
* 4. Phil Kim, “Matlab Deep Learning: With Machine Learning, Neural Networks and Artificial Intelligence”, Apress, 2017.
* 5. Ragav Venkatesan, Baoxin Li, “Convolutional Neural Networks in Visual Computing”, CRC Press, 2018.
* 6. Navin Kumar Manaswi, “Deep Learning with Applications Using Python”, Apress, 2018.

# 1. Neural Networks and Deep Learning: A Textbook 1st ed. 2018 Edition
<img src="https://m.media-amazon.com/images/I/71IcMdUyGYL._SL1175_.jpg" alt="thumbnail" width="150">

<img src="https://m.media-amazon.com/images/I/A10G+oKN3LL._SL1500_.jpg" alt="thumbnail2" width="150">

<img src="https://m.media-amazon.com/images/I/717vXoWd3OL._SL1500_.jpg" alt="thumbnail2" width="150">


<img src="https://m.media-amazon.com/images/I/613rw3G6q4L._SL1180_.jpg" alt="thumbnail2" width="150">


<img src="https://m.media-amazon.com/images/I/81sWwwu-rDL._SL1500_.jpg" alt="thumbnail2" width="150">
[[Convolutional_Neural_Networks_in_Visual_Computing-_A_Concise_--_Ragav_Venkatesan,_Baoxin_Li_--_(_WeLib.org_).pdf]]


<img src="https://m.media-amazon.com/images/I/61PonczWf1L._SL1254_.jpg" alt="thumbnail2" width="150">
[[Deep_Learning_with_Applications_Using_Python.pdf]]


---

# **Week-3 Sessions 7,8,9** 

| **Book**                 | **Relevant Chapters** | **Key Concepts Covered**                                                           | **Best Use in Session**                     | **Limitations**                     |     |
| ------------------------ | --------------------- | ---------------------------------------------------------------------------------- | ------------------------------------------- | ----------------------------------- | --- |
| Aggarwal (2018)          | Ch. 1, 2, 3           | Neurons, XOR, sigmoid/tanh/ReLU, gradients, vanishing gradients, Universal Approx. | Theoretical depth, derivations, XOR hook    | Swish/GELU may be missing           |     |
| Goodfellow et al. (2017) | Ch. 6, 8              | MLPs, all activations, gradients, Universal Approx., vanishing/dying ReLU          | Core theory, rigorous math, gradient issues | Swish/GELU likely absent            |     |
| Chollet (2018)           | Ch. 2, 4              | Sigmoid/tanh/ReLU, Python demos, applications (spam, sentiment)                    | Python plotting, practical bridges          | Light on derivations, no Swish/GELU |     |
| Kim (2017)               | Ch. 2, 3              | Perceptrons, XOR, sigmoid/tanh/ReLU, gradients                                     | XOR and classical activations (Matlab)      | Matlab focus, no Swish/GELU         |     |
| Venkatesan & Li (2018)   | Ch. 2, 3/4            | ReLU in CNNs, gradients, vision applications                                       | ReLU vision example                         | CNN-focused, limited XOR/MLPs       |     |
| Manaswi (2018)           | Ch. 2, 3              | XOR, sigmoid/tanh/ReLU, Python, applications                                       | Python demos, practical examples            | No Swish/GELU, light derivations    |     |
