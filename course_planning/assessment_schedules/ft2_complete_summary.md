# FT2 (Formative Test 2) - Complete Materials Summary

**Course:** 21CSE558T - Deep Neural Network Architectures
**Test Date:** November 14, 2025
**Coverage:** Modules 3-4 (Image Processing & CNNs)
**Total Marks:** 25 marks
**Status:** âœ… ALL MATERIALS COMPLETE

---

## ğŸ“¦ Complete Materials Created

### 1. **Question Banks**

#### **MCQ Bank (40 questions)** âœ…
**File:** `ft2_mcq_bank_40_questions.md`

**Distribution:**
- Module 3 (Image Processing): 20 MCQs
  - Image Representation: 3
  - Image Enhancement: 3
  - Noise Removal: 2
  - Edge Detection: 3
  - Segmentation: 3
  - Feature Extraction: 4
  - OpenCV Operations: 2

- Module 4 (CNNs & Transfer Learning): 20 MCQs
  - Convolution Operation: 3
  - Pooling Layers: 3
  - Batch Normalization: 2
  - Dropout: 2
  - Data Augmentation: 2
  - Famous Architectures: 4
  - Transfer Learning: 4

**Key Features:**
- âœ… NO overlap with FT1 (Modules 1-2)
- âœ… CNN-specific applications (not general concepts)
- âœ… Balanced 20-20 distribution
- âœ… All questions have answers and explanations
- âœ… Includes Transfer Learning topics

---

#### **SAQ Bank (7 questions, 5 marks each)** âœ…
**File:** `ft2_saq_bank_7_questions.md`

**Distribution:**
- Module 3: 3 SAQs
  - Q1: Feature Extraction Comparison (Traditional vs Deep Learning)
  - Q2: Segmentation Techniques (Thresholding vs Region-based)
  - Q3: Edge Detection Selection (Sobel vs Canny)

- Module 4: 4 SAQs
  - Q4: Batch Normalization Placement (Convâ†’BNâ†’ReLU vs Convâ†’ReLUâ†’BN)
  - Q5: Dropout Placement Strategy (Progressive rates, NEVER after output)
  - Q6: Data Augmentation for CIFAR-10 (Appropriate augmentations)
  - Q7: Transfer Learning Strategy (VGG16 for small dataset)

**Key Features:**
- âœ… Scenario-based explanations (like FT1 format)
- âœ… Conceptual focus, light calculations
- âœ… NO code debugging questions
- âœ… CNN-specific applications
- âœ… Complete answers with marking schemes

---

### 2. **Test Papers**

#### **Set A** âœ…
**File:** `ft2_set_a.md`

**Part A (10 MCQs):**
- Module 3: Q1-Q5 (Image channels, noise removal, Canny, Otsu's, LBP)
- Module 4: Q6-Q10 (Convolution, Max pooling, Dropout placement, LeNet-5, Transfer learning)

**Part B (3 SAQs):**
- Q11: Feature extraction comparison (Module 3)
- Q12: BatchNorm placement (Module 4)
- Q13: Transfer learning strategy (Module 4)

**Total:** 25 marks (10 + 15)

---

#### **Set B** âœ…
**File:** `ft2_set_b.md`

**Part A (10 MCQs):**
- Module 3: Q1-Q5 (Pixel values, histogram, Laplacian, watershed, OpenCV)
- Module 4: Q6-Q10 (Padding, GlobalAvgPool, BatchNorm, AlexNet, Freezing)

**Part B (3 SAQs):**
- Q11: Segmentation comparison (Module 3)
- Q12: Dropout placement strategy (Module 4)
- Q13: Data augmentation (Module 4)

**Total:** 25 marks (10 + 15)

---

### 3. **Answer Keys & Grading** âœ…
**File:** `ft2_answer_keys.md`

**Contents:**
- âœ… Complete answer key for Set A (Part A + Part B)
- âœ… Complete answer key for Set B (Part A + Part B)
- âœ… Detailed explanations for all MCQs
- âœ… Full expected answers for all SAQs
- âœ… Marking schemes for each SAQ (breakdown)
- âœ… Grading rubric (5-mark scale)
- âœ… Common mistakes guide for graders

---

## ğŸ“Š FT2 Format Summary

### Structure (Both Sets A and B)
```
Part A: Multiple Choice Questions
  - 10 questions Ã— 1 mark = 10 marks
  - 5 from Module 3 + 5 from Module 4
  - All questions mandatory

Part B: Short Answer Questions
  - 3 questions Ã— 5 marks = 15 marks
  - 1-2 from Module 3 + 1-2 from Module 4
  - All questions mandatory

Total: 25 marks
```

### Tabular Format (Like FT1)
- âœ… Table with columns: Q.No | Question | Marks | BL | CO | PO | PI Code
- âœ… Complete CO-PO-PI mapping
- âœ… Bloom's Taxonomy levels indicated

---

## ğŸ¯ Key Differentiators from FT1

### What's DIFFERENT (NO overlap):

**FT1 Covered (Modules 1-2):**
- âŒ Perceptron, XOR, linear separability
- âŒ TensorFlow basics, tensors
- âŒ Activation functions (general)
- âŒ Loss functions
- âŒ Backpropagation
- âŒ Gradient descent (general)
- âŒ Optimizers (Adam, SGD, etc.)
- âŒ L1/L2 regularization (general)
- âŒ Dropout (general concept)
- âŒ Batch Normalization (general concept)

**FT2 Covers (Modules 3-4):**
- âœ… Image Processing (channels, enhancement, noise, edges, segmentation, features, OpenCV)
- âœ… CNNs (convolution, pooling, architecture design)
- âœ… **CNN-SPECIFIC BatchNorm** (placement: Convâ†’BNâ†’Activation)
- âœ… **CNN-SPECIFIC Dropout** (progressive rates, placement strategy)
- âœ… **Image-SPECIFIC Augmentation** (rotation, flip, shift, zoom)
- âœ… Famous architectures (LeNet-5, AlexNet, VGG, ResNet)
- âœ… Transfer Learning (freezing, fine-tuning, pre-trained models)

---

## âœ… Quality Checklist

### Content Coverage:
- [x] Module 3 adequately covered (20 MCQs + 3 SAQs)
- [x] Module 4 adequately covered (20 MCQs + 4 SAQs)
- [x] NO overlap with FT1 topics
- [x] CNN-specific focus (not general ML concepts)
- [x] Transfer Learning included
- [x] Balanced distribution across topics

### Format Requirements:
- [x] Tabular format with CO-PO-PI mapping
- [x] Bloom's Taxonomy levels indicated
- [x] Clear instructions for students
- [x] Proper marking schemes
- [x] 25 marks total (10 + 15)

### Question Quality:
- [x] Conceptual focus (light calculations)
- [x] NO code-based debugging questions
- [x] Scenario-based SAQs (like FT1)
- [x] Clear, unambiguous wording
- [x] Appropriate difficulty distribution

### Answer Keys:
- [x] All MCQ answers provided
- [x] All SAQ answers provided
- [x] Detailed explanations included
- [x] Marking schemes with breakdown
- [x] Grading rubric (0-5 marks)

---

## ğŸ“ File Organization

```
course_planning/assessment_schedules/
â”œâ”€â”€ ft2_mcq_bank_40_questions.md      (40 MCQs with answers)
â”œâ”€â”€ ft2_saq_bank_7_questions.md       (7 SAQs with full answers)
â”œâ”€â”€ ft2_set_a.md                      (Test paper Set A)
â”œâ”€â”€ ft2_set_b.md                      (Test paper Set B)
â”œâ”€â”€ ft2_answer_keys.md                (Complete answer keys + rubric)
â””â”€â”€ ft2_complete_summary.md           (This file)
```

**Total Files:** 6
**Total Size:** ~65KB
**Status:** âœ… Complete and ready for deployment

---

## ğŸ“ Usage Instructions

### For Instructors:

**Before Test Day:**
1. Review both Set A and Set B
2. Choose which set to use (or use both for different batches)
3. Print test papers (one set per student)
4. Keep answer keys confidential
5. Brief TAs on grading rubric

**On Test Day:**
1. Distribute test papers
2. Announce duration (TBD - please confirm)
3. Clarify any format questions
4. Collect completed papers

**After Test:**
1. Use answer keys for grading
2. Apply grading rubric consistently
3. Provide feedback to students
4. Analyze performance statistics

---

### For Students:

**Preparation:**
1. Review Modules 3-4 lecture notes
2. Focus on Week 11 content (CNN regularization techniques)
3. Practice convolution parameter calculations (light)
4. Understand BatchNorm placement (Convâ†’BNâ†’Activation)
5. Know dropout placement strategy (progressive rates)
6. Study data augmentation appropriateness
7. Understand transfer learning concepts

**During Test:**
1. Read all questions carefully
2. Part A: Choose ONE answer per MCQ
3. Part B: Write complete explanations with reasoning
4. Manage time: ~40% for Part A, ~60% for Part B
5. Review answers before submission

---

## ğŸ“ˆ Expected Performance

### Target Accuracy:
- **Excellent students (20-25 marks):** Deep understanding of CNNs and image processing
- **Good students (15-19 marks):** Solid grasp of concepts, minor gaps
- **Satisfactory students (10-14 marks):** Basic understanding, needs improvement
- **Needs improvement (<10 marks):** Review required

### Common Challenge Areas:
- BatchNorm placement (Convâ†’BNâ†’Activation is non-intuitive)
- Dropout after output layer (common mistake)
- Appropriate data augmentation (vertical flip for CIFAR-10)
- Transfer learning strategy (when to freeze/unfreeze)

---

## ğŸ”„ Future Improvements (Optional)

### Potential Enhancements:
- Add 10-mark questions for comprehensive assessment
- Create additional practice sets (Set C, D)
- Include more calculation-heavy questions
- Add code-based debugging questions
- Create video solutions for SAQs
- Build online quiz version

### Feedback Collection:
- Student difficulty ratings
- Time taken per question
- Most confused topics
- Suggestions for clarity improvements

---

## ğŸ“ Support & Questions

**For Clarifications:**
- Review question bank comments
- Check answer key explanations
- Refer to marking schemes
- Consult grading rubric

**For Disputes:**
- Provide complete student answer
- Reference marking scheme
- Justify partial marks awarded
- Document grading decisions

---

## ğŸ¯ Alignment with Course Outcomes

### CO-3: Implement deep learning for image processing applications
**Covered in:**
- Module 3 questions (image processing techniques)
- Feature extraction comparison
- Segmentation techniques
- Edge detection methods

### CO-4: Design and implement CNN architectures and transfer learning
**Covered in:**
- Module 4 questions (CNN components)
- BatchNorm placement
- Dropout strategy
- Data augmentation
- Transfer learning
- Famous architectures

---

## âœ… FINAL STATUS

**All FT2 Materials Complete:** âœ…
**Quality Checked:** âœ…
**Ready for Deployment:** âœ…
**Test Date:** November 14, 2025

**Created:** October 30, 2025
**Last Updated:** October 30, 2025
**Version:** 1.0 - Final Release

---

**Total Question Bank:** 40 MCQs + 7 SAQs = 47 questions
**Test Papers:** 2 sets (A, B)
**Answer Keys:** Complete with rubrics
**Documentation:** Comprehensive

**Next Steps:**
1. âœ… Review all materials
2. âœ… Confirm test duration
3. âœ… Print test papers
4. âœ… Conduct test on Nov 14
5. âœ… Grade using answer keys
6. âœ… Provide student feedback

---

**END OF FT2 SUMMARY**
