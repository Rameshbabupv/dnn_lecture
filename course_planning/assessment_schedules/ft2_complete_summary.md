# FT2 (Formative Test 2) - Complete Materials Summary

**Course:** 21CSE558T - Deep Neural Network Architectures
**Test Date:** November 14, 2025
**Coverage:** Modules 3-4 (Image Processing & CNNs)
**Total Marks:** 25 marks
**Status:** ✅ ALL MATERIALS COMPLETE

---

## 📦 Complete Materials Created

### 1. **Question Banks**

#### **MCQ Bank (40 questions)** ✅
**File:** `ft2_mcq_bank_40_questions.md`

**Distribution:**
- Module 3 (Image Processing): 20 MCQs
  - Image Representation: 3
  - Image Enhancement: 3
  - Noise Removal: 2
  - Edge Detection: 3
  - Segmentation: 3
  - Feature Extraction: 4
  - OpenCV Operations: 2

- Module 4 (CNNs & Transfer Learning): 20 MCQs
  - Convolution Operation: 3
  - Pooling Layers: 3
  - Batch Normalization: 2
  - Dropout: 2
  - Data Augmentation: 2
  - Famous Architectures: 4
  - Transfer Learning: 4

**Key Features:**
- ✅ NO overlap with FT1 (Modules 1-2)
- ✅ CNN-specific applications (not general concepts)
- ✅ Balanced 20-20 distribution
- ✅ All questions have answers and explanations
- ✅ Includes Transfer Learning topics

---

#### **SAQ Bank (7 questions, 5 marks each)** ✅
**File:** `ft2_saq_bank_7_questions.md`

**Distribution:**
- Module 3: 3 SAQs
  - Q1: Feature Extraction Comparison (Traditional vs Deep Learning)
  - Q2: Segmentation Techniques (Thresholding vs Region-based)
  - Q3: Edge Detection Selection (Sobel vs Canny)

- Module 4: 4 SAQs
  - Q4: Batch Normalization Placement (Conv→BN→ReLU vs Conv→ReLU→BN)
  - Q5: Dropout Placement Strategy (Progressive rates, NEVER after output)
  - Q6: Data Augmentation for CIFAR-10 (Appropriate augmentations)
  - Q7: Transfer Learning Strategy (VGG16 for small dataset)

**Key Features:**
- ✅ Scenario-based explanations (like FT1 format)
- ✅ Conceptual focus, light calculations
- ✅ NO code debugging questions
- ✅ CNN-specific applications
- ✅ Complete answers with marking schemes

---

### 2. **Test Papers**

#### **Set A** ✅
**File:** `ft2_set_a.md`

**Part A (10 MCQs):**
- Module 3: Q1-Q5 (Image channels, noise removal, Canny, Otsu's, LBP)
- Module 4: Q6-Q10 (Convolution, Max pooling, Dropout placement, LeNet-5, Transfer learning)

**Part B (3 SAQs):**
- Q11: Feature extraction comparison (Module 3)
- Q12: BatchNorm placement (Module 4)
- Q13: Transfer learning strategy (Module 4)

**Total:** 25 marks (10 + 15)

---

#### **Set B** ✅
**File:** `ft2_set_b.md`

**Part A (10 MCQs):**
- Module 3: Q1-Q5 (Pixel values, histogram, Laplacian, watershed, OpenCV)
- Module 4: Q6-Q10 (Padding, GlobalAvgPool, BatchNorm, AlexNet, Freezing)

**Part B (3 SAQs):**
- Q11: Segmentation comparison (Module 3)
- Q12: Dropout placement strategy (Module 4)
- Q13: Data augmentation (Module 4)

**Total:** 25 marks (10 + 15)

---

### 3. **Answer Keys & Grading** ✅
**File:** `ft2_answer_keys.md`

**Contents:**
- ✅ Complete answer key for Set A (Part A + Part B)
- ✅ Complete answer key for Set B (Part A + Part B)
- ✅ Detailed explanations for all MCQs
- ✅ Full expected answers for all SAQs
- ✅ Marking schemes for each SAQ (breakdown)
- ✅ Grading rubric (5-mark scale)
- ✅ Common mistakes guide for graders

---

## 📊 FT2 Format Summary

### Structure (Both Sets A and B)
```
Part A: Multiple Choice Questions
  - 10 questions × 1 mark = 10 marks
  - 5 from Module 3 + 5 from Module 4
  - All questions mandatory

Part B: Short Answer Questions
  - 3 questions × 5 marks = 15 marks
  - 1-2 from Module 3 + 1-2 from Module 4
  - All questions mandatory

Total: 25 marks
```

### Tabular Format (Like FT1)
- ✅ Table with columns: Q.No | Question | Marks | BL | CO | PO | PI Code
- ✅ Complete CO-PO-PI mapping
- ✅ Bloom's Taxonomy levels indicated

---

## 🎯 Key Differentiators from FT1

### What's DIFFERENT (NO overlap):

**FT1 Covered (Modules 1-2):**
- ❌ Perceptron, XOR, linear separability
- ❌ TensorFlow basics, tensors
- ❌ Activation functions (general)
- ❌ Loss functions
- ❌ Backpropagation
- ❌ Gradient descent (general)
- ❌ Optimizers (Adam, SGD, etc.)
- ❌ L1/L2 regularization (general)
- ❌ Dropout (general concept)
- ❌ Batch Normalization (general concept)

**FT2 Covers (Modules 3-4):**
- ✅ Image Processing (channels, enhancement, noise, edges, segmentation, features, OpenCV)
- ✅ CNNs (convolution, pooling, architecture design)
- ✅ **CNN-SPECIFIC BatchNorm** (placement: Conv→BN→Activation)
- ✅ **CNN-SPECIFIC Dropout** (progressive rates, placement strategy)
- ✅ **Image-SPECIFIC Augmentation** (rotation, flip, shift, zoom)
- ✅ Famous architectures (LeNet-5, AlexNet, VGG, ResNet)
- ✅ Transfer Learning (freezing, fine-tuning, pre-trained models)

---

## ✅ Quality Checklist

### Content Coverage:
- [x] Module 3 adequately covered (20 MCQs + 3 SAQs)
- [x] Module 4 adequately covered (20 MCQs + 4 SAQs)
- [x] NO overlap with FT1 topics
- [x] CNN-specific focus (not general ML concepts)
- [x] Transfer Learning included
- [x] Balanced distribution across topics

### Format Requirements:
- [x] Tabular format with CO-PO-PI mapping
- [x] Bloom's Taxonomy levels indicated
- [x] Clear instructions for students
- [x] Proper marking schemes
- [x] 25 marks total (10 + 15)

### Question Quality:
- [x] Conceptual focus (light calculations)
- [x] NO code-based debugging questions
- [x] Scenario-based SAQs (like FT1)
- [x] Clear, unambiguous wording
- [x] Appropriate difficulty distribution

### Answer Keys:
- [x] All MCQ answers provided
- [x] All SAQ answers provided
- [x] Detailed explanations included
- [x] Marking schemes with breakdown
- [x] Grading rubric (0-5 marks)

---

## 📁 File Organization

```
course_planning/assessment_schedules/
├── ft2_mcq_bank_40_questions.md      (40 MCQs with answers)
├── ft2_saq_bank_7_questions.md       (7 SAQs with full answers)
├── ft2_set_a.md                      (Test paper Set A)
├── ft2_set_b.md                      (Test paper Set B)
├── ft2_answer_keys.md                (Complete answer keys + rubric)
└── ft2_complete_summary.md           (This file)
```

**Total Files:** 6
**Total Size:** ~65KB
**Status:** ✅ Complete and ready for deployment

---

## 🎓 Usage Instructions

### For Instructors:

**Before Test Day:**
1. Review both Set A and Set B
2. Choose which set to use (or use both for different batches)
3. Print test papers (one set per student)
4. Keep answer keys confidential
5. Brief TAs on grading rubric

**On Test Day:**
1. Distribute test papers
2. Announce duration (TBD - please confirm)
3. Clarify any format questions
4. Collect completed papers

**After Test:**
1. Use answer keys for grading
2. Apply grading rubric consistently
3. Provide feedback to students
4. Analyze performance statistics

---

### For Students:

**Preparation:**
1. Review Modules 3-4 lecture notes
2. Focus on Week 11 content (CNN regularization techniques)
3. Practice convolution parameter calculations (light)
4. Understand BatchNorm placement (Conv→BN→Activation)
5. Know dropout placement strategy (progressive rates)
6. Study data augmentation appropriateness
7. Understand transfer learning concepts

**During Test:**
1. Read all questions carefully
2. Part A: Choose ONE answer per MCQ
3. Part B: Write complete explanations with reasoning
4. Manage time: ~40% for Part A, ~60% for Part B
5. Review answers before submission

---

## 📈 Expected Performance

### Target Accuracy:
- **Excellent students (20-25 marks):** Deep understanding of CNNs and image processing
- **Good students (15-19 marks):** Solid grasp of concepts, minor gaps
- **Satisfactory students (10-14 marks):** Basic understanding, needs improvement
- **Needs improvement (<10 marks):** Review required

### Common Challenge Areas:
- BatchNorm placement (Conv→BN→Activation is non-intuitive)
- Dropout after output layer (common mistake)
- Appropriate data augmentation (vertical flip for CIFAR-10)
- Transfer learning strategy (when to freeze/unfreeze)

---

## 🔄 Future Improvements (Optional)

### Potential Enhancements:
- Add 10-mark questions for comprehensive assessment
- Create additional practice sets (Set C, D)
- Include more calculation-heavy questions
- Add code-based debugging questions
- Create video solutions for SAQs
- Build online quiz version

### Feedback Collection:
- Student difficulty ratings
- Time taken per question
- Most confused topics
- Suggestions for clarity improvements

---

## 📞 Support & Questions

**For Clarifications:**
- Review question bank comments
- Check answer key explanations
- Refer to marking schemes
- Consult grading rubric

**For Disputes:**
- Provide complete student answer
- Reference marking scheme
- Justify partial marks awarded
- Document grading decisions

---

## 🎯 Alignment with Course Outcomes

### CO-3: Implement deep learning for image processing applications
**Covered in:**
- Module 3 questions (image processing techniques)
- Feature extraction comparison
- Segmentation techniques
- Edge detection methods

### CO-4: Design and implement CNN architectures and transfer learning
**Covered in:**
- Module 4 questions (CNN components)
- BatchNorm placement
- Dropout strategy
- Data augmentation
- Transfer learning
- Famous architectures

---

## ✅ FINAL STATUS

**All FT2 Materials Complete:** ✅
**Quality Checked:** ✅
**Ready for Deployment:** ✅
**Test Date:** November 14, 2025

**Created:** October 30, 2025
**Last Updated:** October 30, 2025
**Version:** 1.0 - Final Release

---

**Total Question Bank:** 40 MCQs + 7 SAQs = 47 questions
**Test Papers:** 2 sets (A, B)
**Answer Keys:** Complete with rubrics
**Documentation:** Comprehensive

**Next Steps:**
1. ✅ Review all materials
2. ✅ Confirm test duration
3. ✅ Print test papers
4. ✅ Conduct test on Nov 14
5. ✅ Grade using answer keys
6. ✅ Provide student feedback

---

**END OF FT2 SUMMARY**
