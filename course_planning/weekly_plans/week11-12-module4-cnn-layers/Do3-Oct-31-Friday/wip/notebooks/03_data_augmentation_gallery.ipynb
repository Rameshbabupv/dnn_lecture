{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 03 - Data Augmentation Gallery\n",
    "\n",
    "**Course:** 21CSE558T - Deep Neural Network Architectures  \n",
    "**Module 4:** CNNs (Week 2 of 3)  \n",
    "**Date:** October 31, 2025  \n",
    "**Duration:** 45-60 minutes\n",
    "\n",
    "---\n",
    "\n",
    "## Learning Objectives\n",
    "\n",
    "By the end of this notebook, you will be able to:\n",
    "1. Apply geometric and photometric augmentation techniques\n",
    "2. Understand domain-appropriate augmentation selection\n",
    "3. Visualize augmentation effects on real images\n",
    "4. Create custom augmentation pipelines\n",
    "5. Compare training with/without augmentation\n",
    "\n",
    "---\n",
    "\n",
    "## Story: Character: Arun's Photography Studio\n",
    "\n",
    "**Character: Arun** runs a wildlife photography training school. He teaches students to recognize animals from photos taken in various conditions:\n",
    "- Different angles (rotation)\n",
    "- Different distances (zoom)\n",
    "- Different lighting (brightness)\n",
    "- Different weather (contrast, color)\n",
    "\n",
    "Character: Arun discovered that students trained on **diverse photos** perform better in real safaris than those trained on **perfect studio photos only**.\n",
    "\n",
    "**This is exactly what data augmentation does for CNNs!**\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator, load_img, img_to_array\n",
    "from tensorflow.keras.datasets import cifar10\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import (\n",
    "    Conv2D, BatchNormalization, Activation,\n",
    "    MaxPooling2D, GlobalAveragePooling2D,\n",
    "    Dropout, Dense\n",
    ")\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "print(f\"TensorFlow version: {tf.__version__}\")\n",
    "print(f\"NumPy version: {np.__version__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1: Geometric Augmentation Gallery\n",
    "\n",
    "**Geometric transformations** change the spatial properties of images:\n",
    "- Rotation\n",
    "- Horizontal/Vertical Flip\n",
    "- Width/Height Shift\n",
    "- Zoom\n",
    "- Shear\n",
    "\n",
    "### Analogy: Character: Priya Takes Photos of Her Dog\n",
    "\n",
    "**Character: Priya** wants to train a model to recognize her dog. She takes photos from:\n",
    "- Different angles ‚Üí **Rotation augmentation**\n",
    "- Left and right sides ‚Üí **Horizontal flip**\n",
    "- Near and far ‚Üí **Zoom augmentation**\n",
    "- While the dog moves ‚Üí **Shift augmentation**\n",
    "\n",
    "This creates a **robust** model that recognizes the dog regardless of position!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load a sample image from CIFAR-10\n",
    "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
    "\n",
    "# CIFAR-10 class names\n",
    "class_names = ['airplane', 'automobile', 'bird', 'cat', 'deer', \n",
    "               'dog', 'frog', 'horse', 'ship', 'truck']\n",
    "\n",
    "# Select a sample image (let's pick a dog)\n",
    "sample_idx = np.where(y_train == 5)[0][0]  # Class 5 = dog\n",
    "sample_image = x_train[sample_idx]\n",
    "sample_label = class_names[y_train[sample_idx][0]]\n",
    "\n",
    "print(f\"Sample image: {sample_label}\")\n",
    "print(f\"Image shape: {sample_image.shape}\")\n",
    "\n",
    "plt.figure(figsize=(4, 4))\n",
    "plt.imshow(sample_image)\n",
    "plt.title(f\"Original: {sample_label}\")\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Geometric Augmentation Gallery\n",
    "def show_geometric_augmentations(image):\n",
    "    \"\"\"\n",
    "    Display various geometric augmentations.\n",
    "    \n",
    "    Character: Arun's different camera angles!\n",
    "    \"\"\"\n",
    "    # Prepare image for generator (needs batch dimension)\n",
    "    img_expanded = np.expand_dims(image, axis=0)\n",
    "    \n",
    "    # Define different augmentation strategies\n",
    "    augmentations = {\n",
    "        'Rotation (¬±20¬∞)': ImageDataGenerator(rotation_range=20),\n",
    "        'Horizontal Flip': ImageDataGenerator(horizontal_flip=True),\n",
    "        'Vertical Flip': ImageDataGenerator(vertical_flip=True),\n",
    "        'Width Shift (¬±20%)': ImageDataGenerator(width_shift_range=0.2),\n",
    "        'Height Shift (¬±20%)': ImageDataGenerator(height_shift_range=0.2),\n",
    "        'Zoom (80-120%)': ImageDataGenerator(zoom_range=0.2),\n",
    "        'Shear (20¬∞)': ImageDataGenerator(shear_range=20),\n",
    "        'Combined': ImageDataGenerator(\n",
    "            rotation_range=15,\n",
    "            width_shift_range=0.1,\n",
    "            height_shift_range=0.1,\n",
    "            horizontal_flip=True,\n",
    "            zoom_range=0.1\n",
    "        )\n",
    "    }\n",
    "    \n",
    "    # Create gallery\n",
    "    fig, axes = plt.subplots(3, 3, figsize=(12, 12))\n",
    "    axes = axes.flatten()\n",
    "    \n",
    "    # Show original\n",
    "    axes[0].imshow(image.astype('uint8'))\n",
    "    axes[0].set_title('Original', fontsize=14, fontweight='bold')\n",
    "    axes[0].axis('off')\n",
    "    \n",
    "    # Show augmentations\n",
    "    for idx, (name, datagen) in enumerate(augmentations.items(), 1):\n",
    "        # Generate one augmented image\n",
    "        aug_iter = datagen.flow(img_expanded, batch_size=1)\n",
    "        aug_image = next(aug_iter)[0].astype('uint8')\n",
    "        \n",
    "        axes[idx].imshow(aug_image)\n",
    "        axes[idx].set_title(name, fontsize=12)\n",
    "        axes[idx].axis('off')\n",
    "    \n",
    "    plt.suptitle(\"Geometric Augmentation Gallery\\nCharacter: Arun's Different Camera Angles\", \n",
    "                 fontsize=16, fontweight='bold', y=0.995)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "show_geometric_augmentations(sample_image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2: Photometric Augmentation Gallery\n",
    "\n",
    "**Photometric transformations** change the pixel intensities:\n",
    "- Brightness adjustment\n",
    "- Contrast adjustment\n",
    "- Saturation adjustment\n",
    "- Hue shift\n",
    "- Channel shift\n",
    "\n",
    "### Analogy: Character: Lakshmi's Weather Conditions\n",
    "\n",
    "**Character: Lakshmi** is a drone photographer who captures landscapes in:\n",
    "- Bright sunlight ‚Üí **High brightness**\n",
    "- Cloudy weather ‚Üí **Low brightness**\n",
    "- Morning golden hour ‚Üí **Warm colors**\n",
    "- Evening blue hour ‚Üí **Cool colors**\n",
    "\n",
    "Models trained on **diverse lighting conditions** work better in real-world scenarios!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Photometric Augmentation Gallery\n",
    "def show_photometric_augmentations(image):\n",
    "    \"\"\"\n",
    "    Display various photometric augmentations.\n",
    "    \n",
    "    Character: Lakshmi's different weather/lighting conditions!\n",
    "    \"\"\"\n",
    "    # Prepare image\n",
    "    img_expanded = np.expand_dims(image, axis=0)\n",
    "    \n",
    "    # Define photometric augmentations\n",
    "    augmentations = {\n",
    "        'Brightness (+30%)': ImageDataGenerator(brightness_range=[1.0, 1.3]),\n",
    "        'Brightness (-30%)': ImageDataGenerator(brightness_range=[0.7, 1.0]),\n",
    "        'Channel Shift (R)': ImageDataGenerator(channel_shift_range=50.0),\n",
    "        'Combined Photometric': ImageDataGenerator(\n",
    "            brightness_range=[0.8, 1.2],\n",
    "            channel_shift_range=30.0\n",
    "        )\n",
    "    }\n",
    "    \n",
    "    # Additional manual augmentations\n",
    "    def adjust_contrast(img, factor):\n",
    "        \"\"\"Adjust image contrast.\"\"\"\n",
    "        mean = np.mean(img)\n",
    "        return np.clip((img - mean) * factor + mean, 0, 255).astype('uint8')\n",
    "    \n",
    "    def adjust_saturation(img, factor):\n",
    "        \"\"\"Adjust image saturation.\"\"\"\n",
    "        hsv = tf.image.rgb_to_hsv(img / 255.0)\n",
    "        hsv = tf.concat([\n",
    "            hsv[:, :, 0:1],\n",
    "            hsv[:, :, 1:2] * factor,\n",
    "            hsv[:, :, 2:3]\n",
    "        ], axis=-1)\n",
    "        rgb = tf.image.hsv_to_rgb(hsv)\n",
    "        return (rgb.numpy() * 255).astype('uint8')\n",
    "    \n",
    "    # Create gallery\n",
    "    fig, axes = plt.subplots(2, 4, figsize=(16, 8))\n",
    "    axes = axes.flatten()\n",
    "    \n",
    "    # Show original\n",
    "    axes[0].imshow(image.astype('uint8'))\n",
    "    axes[0].set_title('Original', fontsize=14, fontweight='bold')\n",
    "    axes[0].axis('off')\n",
    "    \n",
    "    # Show ImageDataGenerator augmentations\n",
    "    for idx, (name, datagen) in enumerate(augmentations.items(), 1):\n",
    "        aug_iter = datagen.flow(img_expanded, batch_size=1)\n",
    "        aug_image = next(aug_iter)[0].astype('uint8')\n",
    "        \n",
    "        axes[idx].imshow(aug_image)\n",
    "        axes[idx].set_title(name, fontsize=12)\n",
    "        axes[idx].axis('off')\n",
    "    \n",
    "    # Show manual augmentations\n",
    "    axes[5].imshow(adjust_contrast(image.astype('float32'), 1.5))\n",
    "    axes[5].set_title('Contrast (+50%)', fontsize=12)\n",
    "    axes[5].axis('off')\n",
    "    \n",
    "    axes[6].imshow(adjust_contrast(image.astype('float32'), 0.5))\n",
    "    axes[6].set_title('Contrast (-50%)', fontsize=12)\n",
    "    axes[6].axis('off')\n",
    "    \n",
    "    axes[7].imshow(adjust_saturation(image.astype('float32'), 1.8))\n",
    "    axes[7].set_title('Saturation (+80%)', fontsize=12)\n",
    "    axes[7].axis('off')\n",
    "    \n",
    "    plt.suptitle(\"Photometric Augmentation Gallery\\nCharacter: Lakshmi's Different Lighting Conditions\", \n",
    "                 fontsize=16, fontweight='bold', y=0.98)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "show_photometric_augmentations(sample_image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 3: Domain-Appropriate Augmentation\n",
    "\n",
    "**CRITICAL CONCEPT:** Not all augmentations are appropriate for all domains!\n",
    "\n",
    "### Examples:\n",
    "\n",
    "| Domain | Good Augmentations ‚úÖ | Bad Augmentations ‚ùå |\n",
    "|--------|----------------------|----------------------|\n",
    "| **Cats/Dogs** | Rotation ¬±15¬∞, Flip horizontal, Zoom, Brightness | Vertical flip, Rotation ¬±180¬∞ |\n",
    "| **Handwritten Digits** | Rotation ¬±10¬∞, Shift, Zoom | Flips (6‚Üí9 problem!), Heavy rotation |\n",
    "| **Medical X-rays** | Shift, Zoom, Brightness | Flips (left‚â†right organs!), Heavy rotation |\n",
    "| **Satellite Images** | All rotations, All flips | (Almost everything works) |\n",
    "| **Road Signs** | Slight rotation ¬±5¬∞, Brightness | Flips (make invalid signs!), Heavy rotation |\n",
    "\n",
    "### Story: Character: Vikram's Mistake\n",
    "\n",
    "**Character: Vikram** trained a digit recognizer with vertical flips. His model learned:\n",
    "- 6 = 9 (upside down)\n",
    "- b = q (flipped)\n",
    "- d = p (flipped)\n",
    "\n",
    "**Test accuracy dropped from 95% to 60%!**\n",
    "\n",
    "**Lesson:** Always consider domain constraints before augmentation!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare domain-appropriate vs inappropriate augmentation\n",
    "def compare_augmentation_strategies(image, label):\n",
    "    \"\"\"\n",
    "    Compare appropriate vs inappropriate augmentation.\n",
    "    \n",
    "    Character: Vikram learns from his mistakes!\n",
    "    \"\"\"\n",
    "    img_expanded = np.expand_dims(image, axis=0)\n",
    "    \n",
    "    # Appropriate for natural images (cats, dogs, etc.)\n",
    "    appropriate_datagen = ImageDataGenerator(\n",
    "        rotation_range=15,\n",
    "        width_shift_range=0.1,\n",
    "        height_shift_range=0.1,\n",
    "        horizontal_flip=True,\n",
    "        zoom_range=0.1,\n",
    "        brightness_range=[0.8, 1.2]\n",
    "    )\n",
    "    \n",
    "    # Inappropriate (too aggressive)\n",
    "    inappropriate_datagen = ImageDataGenerator(\n",
    "        rotation_range=180,  # Too much!\n",
    "        width_shift_range=0.5,  # Too much!\n",
    "        height_shift_range=0.5,  # Too much!\n",
    "        horizontal_flip=True,\n",
    "        vertical_flip=True,  # Dogs don't walk upside down!\n",
    "        zoom_range=0.8,  # Too much!\n",
    "        brightness_range=[0.2, 2.0]  # Too extreme!\n",
    "    )\n",
    "    \n",
    "    # Generate samples\n",
    "    fig, axes = plt.subplots(2, 5, figsize=(18, 8))\n",
    "    \n",
    "    # Appropriate augmentations\n",
    "    axes[0, 0].imshow(image.astype('uint8'))\n",
    "    axes[0, 0].set_title('Original', fontsize=12, fontweight='bold')\n",
    "    axes[0, 0].axis('off')\n",
    "    \n",
    "    app_iter = appropriate_datagen.flow(img_expanded, batch_size=1)\n",
    "    for i in range(1, 5):\n",
    "        aug_image = next(app_iter)[0].astype('uint8')\n",
    "        axes[0, i].imshow(aug_image)\n",
    "        axes[0, i].set_title(f'‚úÖ Appropriate #{i}', fontsize=12, color='green')\n",
    "        axes[0, i].axis('off')\n",
    "    \n",
    "    # Inappropriate augmentations\n",
    "    axes[1, 0].imshow(image.astype('uint8'))\n",
    "    axes[1, 0].set_title('Original', fontsize=12, fontweight='bold')\n",
    "    axes[1, 0].axis('off')\n",
    "    \n",
    "    inapp_iter = inappropriate_datagen.flow(img_expanded, batch_size=1)\n",
    "    for i in range(1, 5):\n",
    "        aug_image = next(inapp_iter)[0].astype('uint8')\n",
    "        axes[1, i].imshow(aug_image)\n",
    "        axes[1, i].set_title(f'‚ùå Too Aggressive #{i}', fontsize=12, color='red')\n",
    "        axes[1, i].axis('off')\n",
    "    \n",
    "    plt.suptitle(f\"Domain-Appropriate Augmentation Comparison: {label}\\nCharacter: Vikram's Lesson\", \n",
    "                 fontsize=16, fontweight='bold')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "compare_augmentation_strategies(sample_image, sample_label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 4: Training Comparison - With vs Without Augmentation\n",
    "\n",
    "**The ultimate test:** Does augmentation actually improve performance?\n",
    "\n",
    "Let's train two small CNNs on CIFAR-10:\n",
    "1. **Without augmentation** (baseline)\n",
    "2. **With augmentation** (improved)\n",
    "\n",
    "**Prediction:**\n",
    "- Without: High train acc (95%), Low test acc (65%) ‚Üí **Overfitting**\n",
    "- With: Medium train acc (85%), High test acc (82%) ‚Üí **Generalization**\n",
    "\n",
    "### Story: Character: Ananya's Two Students\n",
    "\n",
    "**Character: Ananya** is a driving instructor with two students:\n",
    "- **Student Rohan:** Practices only on sunny days, perfect roads\n",
    "- **Student Meera:** Practices in rain, night, traffic, different roads\n",
    "\n",
    "**Driving test day (rainy!):**\n",
    "- Rohan: Nervous, makes mistakes (overfitted to perfect conditions)\n",
    "- Meera: Confident, passes easily (generalized to all conditions)\n",
    "\n",
    "**This is data augmentation!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare small dataset for quick training\n",
    "# Use only 5000 training samples for faster demonstration\n",
    "(x_train_full, y_train_full), (x_test_full, y_test_full) = cifar10.load_data()\n",
    "\n",
    "# Take subset\n",
    "x_train_small = x_train_full[:5000].astype('float32') / 255.0\n",
    "y_train_small = tf.keras.utils.to_categorical(y_train_full[:5000], 10)\n",
    "x_test_small = x_test_full[:1000].astype('float32') / 255.0\n",
    "y_test_small = tf.keras.utils.to_categorical(y_test_full[:1000], 10)\n",
    "\n",
    "print(f\"Training samples: {x_train_small.shape[0]}\")\n",
    "print(f\"Test samples: {x_test_small.shape[0]}\")\n",
    "print(\"\\nNote: Using small dataset for quick demonstration!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a simple CNN model\n",
    "def create_cnn():\n",
    "    \"\"\"\n",
    "    Create a simple modern CNN.\n",
    "    \n",
    "    Following Week 11 best practices:\n",
    "    - Conv ‚Üí BN ‚Üí ReLU pattern\n",
    "    - Global Average Pooling\n",
    "    - Dropout for regularization\n",
    "    \"\"\"\n",
    "    model = Sequential([\n",
    "        # Block 1: 32 filters\n",
    "        Conv2D(32, (3,3), padding='same', input_shape=(32, 32, 3)),\n",
    "        BatchNormalization(),\n",
    "        Activation('relu'),\n",
    "        Conv2D(32, (3,3), padding='same'),\n",
    "        BatchNormalization(),\n",
    "        Activation('relu'),\n",
    "        MaxPooling2D((2,2)),\n",
    "        Dropout(0.2),\n",
    "        \n",
    "        # Block 2: 64 filters\n",
    "        Conv2D(64, (3,3), padding='same'),\n",
    "        BatchNormalization(),\n",
    "        Activation('relu'),\n",
    "        Conv2D(64, (3,3), padding='same'),\n",
    "        BatchNormalization(),\n",
    "        Activation('relu'),\n",
    "        MaxPooling2D((2,2)),\n",
    "        Dropout(0.3),\n",
    "        \n",
    "        # Block 3: 128 filters\n",
    "        Conv2D(128, (3,3), padding='same'),\n",
    "        BatchNormalization(),\n",
    "        Activation('relu'),\n",
    "        GlobalAveragePooling2D(),\n",
    "        \n",
    "        # Output\n",
    "        Dropout(0.5),\n",
    "        Dense(10, activation='softmax')\n",
    "    ])\n",
    "    \n",
    "    model.compile(\n",
    "        optimizer='adam',\n",
    "        loss='categorical_crossentropy',\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "    \n",
    "    return model\n",
    "\n",
    "# Create both models\n",
    "model_no_aug = create_cnn()\n",
    "model_with_aug = create_cnn()\n",
    "\n",
    "print(\"Model architecture (same for both):\")\n",
    "model_no_aug.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train Model 1: WITHOUT augmentation\n",
    "print(\"=\" * 60)\n",
    "print(\"Training Model 1: WITHOUT Data Augmentation\")\n",
    "print(\"(Character: Rohan - practices only on sunny days)\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "history_no_aug = model_no_aug.fit(\n",
    "    x_train_small, y_train_small,\n",
    "    validation_data=(x_test_small, y_test_small),\n",
    "    epochs=20,\n",
    "    batch_size=64,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "print(\"\\n‚úÖ Training without augmentation complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train Model 2: WITH augmentation\n",
    "print(\"=\" * 60)\n",
    "print(\"Training Model 2: WITH Data Augmentation\")\n",
    "print(\"(Character: Meera - practices in all conditions)\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Create augmentation generator\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rotation_range=15,\n",
    "    width_shift_range=0.1,\n",
    "    height_shift_range=0.1,\n",
    "    horizontal_flip=True,\n",
    "    zoom_range=0.1\n",
    ")\n",
    "\n",
    "# Flow training data\n",
    "train_generator = train_datagen.flow(\n",
    "    x_train_small, y_train_small,\n",
    "    batch_size=64\n",
    ")\n",
    "\n",
    "history_with_aug = model_with_aug.fit(\n",
    "    train_generator,\n",
    "    validation_data=(x_test_small, y_test_small),\n",
    "    epochs=20,\n",
    "    steps_per_epoch=len(x_train_small) // 64,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "print(\"\\n‚úÖ Training with augmentation complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare training curves\n",
    "def plot_comparison(history1, history2):\n",
    "    \"\"\"\n",
    "    Compare training histories.\n",
    "    \n",
    "    Character: Ananya compares her two students' progress!\n",
    "    \"\"\"\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(16, 6))\n",
    "    \n",
    "    # Accuracy comparison\n",
    "    axes[0].plot(history1.history['accuracy'], 'b-', label='Train (No Aug)', linewidth=2)\n",
    "    axes[0].plot(history1.history['val_accuracy'], 'b--', label='Val (No Aug)', linewidth=2)\n",
    "    axes[0].plot(history2.history['accuracy'], 'g-', label='Train (With Aug)', linewidth=2)\n",
    "    axes[0].plot(history2.history['val_accuracy'], 'g--', label='Val (With Aug)', linewidth=2)\n",
    "    axes[0].set_xlabel('Epoch', fontsize=12)\n",
    "    axes[0].set_ylabel('Accuracy', fontsize=12)\n",
    "    axes[0].set_title('Accuracy Comparison', fontsize=14, fontweight='bold')\n",
    "    axes[0].legend(fontsize=11)\n",
    "    axes[0].grid(True, alpha=0.3)\n",
    "    \n",
    "    # Loss comparison\n",
    "    axes[1].plot(history1.history['loss'], 'b-', label='Train (No Aug)', linewidth=2)\n",
    "    axes[1].plot(history1.history['val_loss'], 'b--', label='Val (No Aug)', linewidth=2)\n",
    "    axes[1].plot(history2.history['loss'], 'g-', label='Train (With Aug)', linewidth=2)\n",
    "    axes[1].plot(history2.history['val_loss'], 'g--', label='Val (With Aug)', linewidth=2)\n",
    "    axes[1].set_xlabel('Epoch', fontsize=12)\n",
    "    axes[1].set_ylabel('Loss', fontsize=12)\n",
    "    axes[1].set_title('Loss Comparison', fontsize=14, fontweight='bold')\n",
    "    axes[1].legend(fontsize=11)\n",
    "    axes[1].grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.suptitle(\"Training Comparison: With vs Without Augmentation\\nCharacter: Ananya's Students\", \n",
    "                 fontsize=16, fontweight='bold')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "plot_comparison(history_no_aug, history_with_aug)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Final results comparison\n",
    "print(\"=\" * 70)\n",
    "print(\"FINAL RESULTS COMPARISON\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# Get final epoch results\n",
    "no_aug_train_acc = history_no_aug.history['accuracy'][-1]\n",
    "no_aug_val_acc = history_no_aug.history['val_accuracy'][-1]\n",
    "no_aug_gap = no_aug_train_acc - no_aug_val_acc\n",
    "\n",
    "with_aug_train_acc = history_with_aug.history['accuracy'][-1]\n",
    "with_aug_val_acc = history_with_aug.history['val_accuracy'][-1]\n",
    "with_aug_gap = with_aug_train_acc - with_aug_val_acc\n",
    "\n",
    "print(\"\\nüìä WITHOUT Data Augmentation (Character: Rohan):\")\n",
    "print(f\"   Train Accuracy: {no_aug_train_acc:.1%}\")\n",
    "print(f\"   Val Accuracy:   {no_aug_val_acc:.1%}\")\n",
    "print(f\"   Gap:            {no_aug_gap:.1%} ‚ö†Ô∏è  (Overfitting!)\")\n",
    "\n",
    "print(\"\\nüìä WITH Data Augmentation (Character: Meera):\")\n",
    "print(f\"   Train Accuracy: {with_aug_train_acc:.1%}\")\n",
    "print(f\"   Val Accuracy:   {with_aug_val_acc:.1%}\")\n",
    "print(f\"   Gap:            {with_aug_gap:.1%} ‚úÖ (Good generalization!)\")\n",
    "\n",
    "print(\"\\nüéØ IMPROVEMENT:\")\n",
    "print(f\"   Val Accuracy:   +{(with_aug_val_acc - no_aug_val_acc):.1%}\")\n",
    "print(f\"   Overfitting:    {(no_aug_gap / with_aug_gap):.1f}√ó less\")\n",
    "\n",
    "print(\"\\nüí° KEY INSIGHT:\")\n",
    "print(\"   Data augmentation trades a bit of training accuracy\")\n",
    "print(\"   for MUCH BETTER generalization to unseen data!\")\n",
    "print(\"=\"*70)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 5: Custom Augmentation Pipeline\n",
    "\n",
    "**Advanced Topic:** Creating custom augmentation pipelines for specific domains.\n",
    "\n",
    "### Example: Wildlife Camera Trap Images\n",
    "\n",
    "**Character: Rohini** analyzes camera trap images. Her requirements:\n",
    "1. Animals appear at any angle ‚Üí **Rotation ¬±30¬∞**\n",
    "2. Day and night captures ‚Üí **Brightness 50-150%**\n",
    "3. Animals may be far or near ‚Üí **Zoom 80-120%**\n",
    "4. Camera on left or right of trail ‚Üí **Horizontal flip**\n",
    "5. But: Animals always right-side up ‚Üí **NO vertical flip**\n",
    "6. But: Camera fixed position ‚Üí **Minimal shift**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom augmentation pipeline for wildlife\n",
    "wildlife_augmentation = ImageDataGenerator(\n",
    "    rotation_range=30,           # Animals at any angle\n",
    "    width_shift_range=0.05,      # Minimal shift (fixed camera)\n",
    "    height_shift_range=0.05,     # Minimal shift (fixed camera)\n",
    "    horizontal_flip=True,        # Left or right of trail\n",
    "    vertical_flip=False,         # Animals don't walk upside down!\n",
    "    zoom_range=0.2,              # Far or near\n",
    "    brightness_range=[0.5, 1.5], # Day and night\n",
    "    fill_mode='constant',        # Black padding\n",
    "    cval=0                       # Black color\n",
    ")\n",
    "\n",
    "print(\"Custom Wildlife Augmentation Pipeline:\")\n",
    "print(\"Character: Rohini's domain-specific requirements\\n\")\n",
    "\n",
    "# Show examples\n",
    "img_expanded = np.expand_dims(sample_image, axis=0)\n",
    "wildlife_iter = wildlife_augmentation.flow(img_expanded, batch_size=1)\n",
    "\n",
    "fig, axes = plt.subplots(2, 4, figsize=(16, 8))\n",
    "axes = axes.flatten()\n",
    "\n",
    "axes[0].imshow(sample_image.astype('uint8'))\n",
    "axes[0].set_title('Original', fontsize=12, fontweight='bold')\n",
    "axes[0].axis('off')\n",
    "\n",
    "for i in range(1, 8):\n",
    "    aug_image = next(wildlife_iter)[0].astype('uint8')\n",
    "    axes[i].imshow(aug_image)\n",
    "    axes[i].set_title(f'Wildlife Aug #{i}', fontsize=12)\n",
    "    axes[i].axis('off')\n",
    "\n",
    "plt.suptitle(\"Custom Wildlife Augmentation Pipeline\\nCharacter: Rohini's Domain-Specific Strategy\", \n",
    "             fontsize=16, fontweight='bold')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 6: Practice Exercises\n",
    "\n",
    "**Apply what you learned!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"PRACTICE EXERCISES\")\n",
    "print(\"=\" * 70)\n",
    "print()\n",
    "print(\"Exercise 1: Medical X-ray Augmentation\")\n",
    "print(\"-\" * 70)\n",
    "print(\"Design an augmentation pipeline for chest X-rays.\")\n",
    "print(\"Constraints:\")\n",
    "print(\"  - Left lung ‚â† Right lung (NO horizontal flip!)\")\n",
    "print(\"  - Patients are upright (NO vertical flip!)\")\n",
    "print(\"  - Slight positioning variations OK\")\n",
    "print(\"  - Different X-ray machine intensities\")\n",
    "print()\n",
    "print(\"TODO: Complete the code below:\")\n",
    "print()\n",
    "\n",
    "# YOUR CODE HERE\n",
    "medical_augmentation = ImageDataGenerator(\n",
    "    # Add your augmentation parameters\n",
    ")\n",
    "\n",
    "print()\n",
    "print(\"Exercise 2: Traffic Sign Recognition\")\n",
    "print(\"-\" * 70)\n",
    "print(\"Design augmentation for traffic sign classification.\")\n",
    "print(\"Constraints:\")\n",
    "print(\"  - Signs must remain readable\")\n",
    "print(\"  - Slight angles OK (camera not perfectly aligned)\")\n",
    "print(\"  - Different weather lighting\")\n",
    "print(\"  - NO flips (would create invalid signs!)\")\n",
    "print()\n",
    "print(\"TODO: Complete the code below:\")\n",
    "print()\n",
    "\n",
    "# YOUR CODE HERE\n",
    "traffic_sign_augmentation = ImageDataGenerator(\n",
    "    # Add your augmentation parameters\n",
    ")\n",
    "\n",
    "print()\n",
    "print(\"Exercise 3: Satellite Image Classification\")\n",
    "print(\"-\" * 70)\n",
    "print(\"Design augmentation for land use classification from satellites.\")\n",
    "print(\"Constraints:\")\n",
    "print(\"  - All rotations valid (no 'up' direction in space)\")\n",
    "print(\"  - All flips valid\")\n",
    "print(\"  - Seasonal color variations\")\n",
    "print(\"  - Cloud shadows (brightness variation)\")\n",
    "print()\n",
    "print(\"TODO: Complete the code below:\")\n",
    "print()\n",
    "\n",
    "# YOUR CODE HERE\n",
    "satellite_augmentation = ImageDataGenerator(\n",
    "    # Add your augmentation parameters\n",
    ")\n",
    "\n",
    "print()\n",
    "print(\"=\" * 70)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary: Key Takeaways\n",
    "\n",
    "### 1. What is Data Augmentation?\n",
    "**Creating synthetic training variations** to improve generalization.\n",
    "\n",
    "### 2. Types of Augmentation\n",
    "- **Geometric:** Rotation, flip, shift, zoom, shear\n",
    "- **Photometric:** Brightness, contrast, saturation, hue\n",
    "\n",
    "### 3. Domain Appropriateness is CRITICAL\n",
    "- Cats/Dogs: Most augmentations OK\n",
    "- Digits: NO flips (6‚Üí9 problem)\n",
    "- Medical: NO flips (anatomy matters)\n",
    "- Satellites: ALL augmentations OK\n",
    "\n",
    "### 4. Training Benefits\n",
    "- Reduces overfitting\n",
    "- Improves test accuracy\n",
    "- Creates robust models\n",
    "- Trades train accuracy for generalization\n",
    "\n",
    "### 5. Implementation in Keras\n",
    "```python\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rotation_range=15,\n",
    "    width_shift_range=0.1,\n",
    "    height_shift_range=0.1,\n",
    "    horizontal_flip=True,\n",
    "    zoom_range=0.1,\n",
    "    brightness_range=[0.8, 1.2]\n",
    ")\n",
    "```\n",
    "\n",
    "### 6. Golden Rules\n",
    "- ‚úÖ DO augment training data\n",
    "- ‚ùå DON'T augment validation/test data\n",
    "- ‚úÖ DO consider domain constraints\n",
    "- ‚ùå DON'T use all augmentations blindly\n",
    "- ‚úÖ DO experiment and validate\n",
    "\n",
    "### 7. Character Lessons\n",
    "- **Character: Arun:** Diverse training beats perfect studio shots\n",
    "- **Character: Lakshmi:** Weather variations create robustness\n",
    "- **Character: Vikram:** Domain constraints matter (6‚â†9!)\n",
    "- **Character: Ananya:** Practice in varied conditions = generalization\n",
    "- **Character: Rohini:** Custom pipelines for specific domains\n",
    "\n",
    "---\n",
    "\n",
    "## Next Steps\n",
    "\n",
    "1. Complete practice exercises above\n",
    "2. Read quick reference cheat sheet\n",
    "3. Complete architecture design worksheet\n",
    "4. Review Notebook 04 (regularization comparison)\n",
    "5. Prepare for Tutorial T11 (Monday, Nov 3)\n",
    "\n",
    "---\n",
    "\n",
    "**üéØ Learning Objective Check:**\n",
    "- ‚úÖ Can apply geometric and photometric augmentation\n",
    "- ‚úÖ Understand domain-appropriate selection\n",
    "- ‚úÖ Visualized augmentation effects\n",
    "- ‚úÖ Created custom augmentation pipelines\n",
    "- ‚úÖ Compared training with/without augmentation\n",
    "\n",
    "**Congratulations! You've mastered data augmentation techniques!** üéâ"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
