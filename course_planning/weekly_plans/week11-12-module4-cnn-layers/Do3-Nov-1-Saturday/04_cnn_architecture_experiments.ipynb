{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notebook 4: CNN Architecture Experiments ğŸ”¬\n",
    "\n",
    "**Course:** 21CSE558T - Deep Neural Network Architectures  \n",
    "**Module 4:** CNNs - Practical Session  \n",
    "**Type:** HOMEWORK ASSIGNMENT  \n",
    "**Due:** Before Monday, November 3, 2025 class  \n",
    "**Submission:** Upload completed notebook to Google Colab/Classroom\n",
    "\n",
    "---\n",
    "\n",
    "## ğŸ¯ Learning Objectives\n",
    "\n",
    "By completing this assignment, you will:\n",
    "\n",
    "1. âœ… Understand how different hyperparameters affect CNN performance\n",
    "2. âœ… Experiment systematically with architecture changes\n",
    "3. âœ… Analyze trade-offs: accuracy vs. speed vs. parameters\n",
    "4. âœ… Develop intuition for CNN design\n",
    "5. âœ… Document your findings scientifically\n",
    "\n",
    "---\n",
    "\n",
    "## ğŸ“‹ Assignment Structure\n",
    "\n",
    "You will complete **5 experiments**:\n",
    "\n",
    "1. **Experiment 1:** Effect of number of filters\n",
    "2. **Experiment 2:** Effect of kernel size\n",
    "3. **Experiment 3:** Effect of depth (number of layers)\n",
    "4. **Experiment 4:** Effect of pooling strategies\n",
    "5. **Experiment 5:** Your own custom architecture\n",
    "\n",
    "**For each experiment:**\n",
    "- Build and train the model\n",
    "- Record accuracy, parameters, training time\n",
    "- Answer reflection questions\n",
    "\n",
    "---\n",
    "\n",
    "## ğŸš€ Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.datasets import fashion_mnist\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import (\n",
    "    Conv2D, MaxPooling2D, AveragePooling2D, \n",
    "    Flatten, Dense, Dropout, BatchNormalization\n",
    ")\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "import time\n",
    "import pandas as pd\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "print(f\"âœ… TensorFlow version: {tf.__version__}\")\n",
    "print(f\"âœ… GPU available: {len(tf.config.list_physical_devices('GPU')) > 0}\")\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "tf.random.set_seed(42)\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load and Prepare Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Fashion-MNIST\n",
    "(x_train, y_train), (x_test, y_test) = fashion_mnist.load_data()\n",
    "\n",
    "# Preprocessing\n",
    "x_train = x_train.reshape(-1, 28, 28, 1).astype('float32') / 255.0\n",
    "x_test = x_test.reshape(-1, 28, 28, 1).astype('float32') / 255.0\n",
    "y_train_cat = to_categorical(y_train, 10)\n",
    "y_test_cat = to_categorical(y_test, 10)\n",
    "\n",
    "print(f\"âœ… Data loaded and preprocessed\")\n",
    "print(f\"Training samples: {x_train.shape[0]:,}\")\n",
    "print(f\"Test samples: {x_test.shape[0]:,}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helper Function: Train and Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_evaluate(model, model_name, epochs=5, verbose=0):\n",
    "    \"\"\"\n",
    "    Train model and return metrics\n",
    "    \"\"\"\n",
    "    # Compile\n",
    "    model.compile(optimizer='adam',\n",
    "                  loss='categorical_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "    \n",
    "    # Train\n",
    "    start_time = time.time()\n",
    "    history = model.fit(x_train, y_train_cat,\n",
    "                       batch_size=128,\n",
    "                       epochs=epochs,\n",
    "                       validation_split=0.1,\n",
    "                       verbose=verbose)\n",
    "    training_time = time.time() - start_time\n",
    "    \n",
    "    # Evaluate\n",
    "    test_loss, test_acc = model.evaluate(x_test, y_test_cat, verbose=0)\n",
    "    \n",
    "    # Get parameters\n",
    "    total_params = model.count_params()\n",
    "    \n",
    "    return {\n",
    "        'name': model_name,\n",
    "        'test_accuracy': test_acc,\n",
    "        'test_loss': test_loss,\n",
    "        'parameters': total_params,\n",
    "        'training_time': training_time,\n",
    "        'history': history\n",
    "    }\n",
    "\n",
    "# Results storage\n",
    "results = []\n",
    "\n",
    "print(\"âœ… Helper function defined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Experiment 1: Effect of Number of Filters ğŸ”¢\n",
    "\n",
    "**Hypothesis:** More filters â†’ Better accuracy (but more parameters)\n",
    "\n",
    "**Test:** Try 16, 32, 64, 128 filters in first conv layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"ğŸ§ª Experiment 1: Number of Filters\\n\" + \"=\"*50)\n",
    "\n",
    "filter_counts = [16, 32, 64, 128]\n",
    "\n",
    "for num_filters in filter_counts:\n",
    "    print(f\"\\nTraining with {num_filters} filters...\")\n",
    "    \n",
    "    model = Sequential([\n",
    "        Conv2D(num_filters, (3, 3), activation='relu', input_shape=(28, 28, 1)),\n",
    "        MaxPooling2D((2, 2)),\n",
    "        Conv2D(num_filters*2, (3, 3), activation='relu'),\n",
    "        MaxPooling2D((2, 2)),\n",
    "        Flatten(),\n",
    "        Dense(128, activation='relu'),\n",
    "        Dense(10, activation='softmax')\n",
    "    ], name=f'CNN_{num_filters}_filters')\n",
    "    \n",
    "    result = train_and_evaluate(model, f'{num_filters} filters', epochs=5)\n",
    "    results.append(result)\n",
    "    \n",
    "    print(f\"  Accuracy: {result['test_accuracy']:.2%}\")\n",
    "    print(f\"  Parameters: {result['parameters']:,}\")\n",
    "    print(f\"  Time: {result['training_time']:.1f}s\")\n",
    "\n",
    "print(\"\\nâœ… Experiment 1 Complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ğŸ“ Reflection Questions (Experiment 1)\n",
    "\n",
    "**Answer these in the markdown cell below:**\n",
    "\n",
    "1. Which configuration gave the best accuracy?\n",
    "2. How does parameter count change with more filters?\n",
    "3. Is there a point where more filters don't help?\n",
    "4. What's the trade-off between accuracy and training time?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### âœï¸ YOUR ANSWERS HERE:\n",
    "\n",
    "1. Best accuracy: [Write your answer]\n",
    "\n",
    "2. Parameter count: [Write your answer]\n",
    "\n",
    "3. Diminishing returns: [Write your answer]\n",
    "\n",
    "4. Trade-offs: [Write your answer]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Experiment 2: Effect of Kernel Size ğŸ“\n",
    "\n",
    "**Hypothesis:** Larger kernels â†’ Larger receptive field but more parameters\n",
    "\n",
    "**Test:** Try kernel sizes 3Ã—3, 5Ã—5, 7Ã—7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"ğŸ§ª Experiment 2: Kernel Size\\n\" + \"=\"*50)\n",
    "\n",
    "kernel_sizes = [3, 5, 7]\n",
    "\n",
    "for k_size in kernel_sizes:\n",
    "    print(f\"\\nTraining with {k_size}Ã—{k_size} kernels...\")\n",
    "    \n",
    "    model = Sequential([\n",
    "        Conv2D(32, (k_size, k_size), activation='relu', input_shape=(28, 28, 1)),\n",
    "        MaxPooling2D((2, 2)),\n",
    "        Conv2D(64, (k_size, k_size), activation='relu'),\n",
    "        MaxPooling2D((2, 2)),\n",
    "        Flatten(),\n",
    "        Dense(128, activation='relu'),\n",
    "        Dense(10, activation='softmax')\n",
    "    ], name=f'CNN_kernel_{k_size}x{k_size}')\n",
    "    \n",
    "    result = train_and_evaluate(model, f'{k_size}Ã—{k_size} kernel', epochs=5)\n",
    "    results.append(result)\n",
    "    \n",
    "    print(f\"  Accuracy: {result['test_accuracy']:.2%}\")\n",
    "    print(f\"  Parameters: {result['parameters']:,}\")\n",
    "    print(f\"  Time: {result['training_time']:.1f}s\")\n",
    "\n",
    "print(\"\\nâœ… Experiment 2 Complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ğŸ“ Reflection Questions (Experiment 2)\n",
    "\n",
    "1. Which kernel size performed best?\n",
    "2. Why might larger kernels not always be better?\n",
    "3. How does output size change with kernel size?\n",
    "4. Modern CNNs mostly use 3Ã—3 kernels. Based on your results, why?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### âœï¸ YOUR ANSWERS HERE:\n",
    "\n",
    "1. Best kernel size: [Write your answer]\n",
    "\n",
    "2. Why not larger: [Write your answer]\n",
    "\n",
    "3. Output size impact: [Write your answer]\n",
    "\n",
    "4. Why 3Ã—3 is popular: [Write your answer]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Experiment 3: Effect of Network Depth ğŸ—ï¸\n",
    "\n",
    "**Hypothesis:** Deeper networks â†’ Better accuracy (hierarchical features)\n",
    "\n",
    "**Test:** Try 2, 3, 4 convolutional blocks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"ğŸ§ª Experiment 3: Network Depth\\n\" + \"=\"*50)\n",
    "\n",
    "# 2 Conv blocks (baseline)\n",
    "print(\"\\nTraining with 2 conv blocks...\")\n",
    "model_2blocks = Sequential([\n",
    "    Conv2D(32, (3, 3), activation='relu', input_shape=(28, 28, 1)),\n",
    "    MaxPooling2D((2, 2)),\n",
    "    Conv2D(64, (3, 3), activation='relu'),\n",
    "    MaxPooling2D((2, 2)),\n",
    "    Flatten(),\n",
    "    Dense(128, activation='relu'),\n",
    "    Dense(10, activation='softmax')\n",
    "], name='CNN_2blocks')\n",
    "\n",
    "result = train_and_evaluate(model_2blocks, '2 Conv Blocks', epochs=5)\n",
    "results.append(result)\n",
    "print(f\"  Accuracy: {result['test_accuracy']:.2%}\")\n",
    "print(f\"  Parameters: {result['parameters']:,}\")\n",
    "\n",
    "# 3 Conv blocks\n",
    "print(\"\\nTraining with 3 conv blocks...\")\n",
    "model_3blocks = Sequential([\n",
    "    Conv2D(32, (3, 3), activation='relu', input_shape=(28, 28, 1)),\n",
    "    MaxPooling2D((2, 2)),\n",
    "    Conv2D(64, (3, 3), activation='relu'),\n",
    "    MaxPooling2D((2, 2)),\n",
    "    Conv2D(128, (3, 3), activation='relu'),\n",
    "    Flatten(),\n",
    "    Dense(128, activation='relu'),\n",
    "    Dense(10, activation='softmax')\n",
    "], name='CNN_3blocks')\n",
    "\n",
    "result = train_and_evaluate(model_3blocks, '3 Conv Blocks', epochs=5)\n",
    "results.append(result)\n",
    "print(f\"  Accuracy: {result['test_accuracy']:.2%}\")\n",
    "print(f\"  Parameters: {result['parameters']:,}\")\n",
    "\n",
    "# 4 Conv blocks\n",
    "print(\"\\nTraining with 4 conv blocks...\")\n",
    "model_4blocks = Sequential([\n",
    "    Conv2D(32, (3, 3), activation='relu', padding='same', input_shape=(28, 28, 1)),\n",
    "    Conv2D(32, (3, 3), activation='relu'),\n",
    "    MaxPooling2D((2, 2)),\n",
    "    Conv2D(64, (3, 3), activation='relu', padding='same'),\n",
    "    Conv2D(64, (3, 3), activation='relu'),\n",
    "    MaxPooling2D((2, 2)),\n",
    "    Flatten(),\n",
    "    Dense(128, activation='relu'),\n",
    "    Dense(10, activation='softmax')\n",
    "], name='CNN_4blocks')\n",
    "\n",
    "result = train_and_evaluate(model_4blocks, '4 Conv Blocks', epochs=5)\n",
    "results.append(result)\n",
    "print(f\"  Accuracy: {result['test_accuracy']:.2%}\")\n",
    "print(f\"  Parameters: {result['parameters']:,}\")\n",
    "\n",
    "print(\"\\nâœ… Experiment 3 Complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ğŸ“ Reflection Questions (Experiment 3)\n",
    "\n",
    "1. Does deeper always mean better?\n",
    "2. What happens to training time as depth increases?\n",
    "3. For Fashion-MNIST (28Ã—28 images), what's a reasonable depth limit?\n",
    "4. What problems might very deep networks face? (Hint: think about gradients)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### âœï¸ YOUR ANSWERS HERE:\n",
    "\n",
    "1. Deeper = better?: [Write your answer]\n",
    "\n",
    "2. Training time: [Write your answer]\n",
    "\n",
    "3. Reasonable depth: [Write your answer]\n",
    "\n",
    "4. Deep network problems: [Write your answer]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Experiment 4: Pooling Strategies ğŸŠ\n",
    "\n",
    "**Hypothesis:** Different pooling methods have different effects\n",
    "\n",
    "**Test:** MaxPooling vs AveragePooling vs No Pooling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"ğŸ§ª Experiment 4: Pooling Strategies\\n\" + \"=\"*50)\n",
    "\n",
    "# MaxPooling (standard)\n",
    "print(\"\\nTraining with MaxPooling...\")\n",
    "model_max = Sequential([\n",
    "    Conv2D(32, (3, 3), activation='relu', input_shape=(28, 28, 1)),\n",
    "    MaxPooling2D((2, 2)),\n",
    "    Conv2D(64, (3, 3), activation='relu'),\n",
    "    MaxPooling2D((2, 2)),\n",
    "    Flatten(),\n",
    "    Dense(128, activation='relu'),\n",
    "    Dense(10, activation='softmax')\n",
    "], name='CNN_MaxPool')\n",
    "\n",
    "result = train_and_evaluate(model_max, 'MaxPooling', epochs=5)\n",
    "results.append(result)\n",
    "print(f\"  Accuracy: {result['test_accuracy']:.2%}\")\n",
    "\n",
    "# AveragePooling\n",
    "print(\"\\nTraining with AveragePooling...\")\n",
    "model_avg = Sequential([\n",
    "    Conv2D(32, (3, 3), activation='relu', input_shape=(28, 28, 1)),\n",
    "    AveragePooling2D((2, 2)),\n",
    "    Conv2D(64, (3, 3), activation='relu'),\n",
    "    AveragePooling2D((2, 2)),\n",
    "    Flatten(),\n",
    "    Dense(128, activation='relu'),\n",
    "    Dense(10, activation='softmax')\n",
    "], name='CNN_AvgPool')\n",
    "\n",
    "result = train_and_evaluate(model_avg, 'AveragePooling', epochs=5)\n",
    "results.append(result)\n",
    "print(f\"  Accuracy: {result['test_accuracy']:.2%}\")\n",
    "\n",
    "# Strided Convolution (no explicit pooling)\n",
    "print(\"\\nTraining with Strided Conv (no pooling)...\")\n",
    "model_stride = Sequential([\n",
    "    Conv2D(32, (3, 3), activation='relu', input_shape=(28, 28, 1)),\n",
    "    Conv2D(32, (3, 3), strides=2, activation='relu'),  # Stride=2 for downsampling\n",
    "    Conv2D(64, (3, 3), activation='relu'),\n",
    "    Conv2D(64, (3, 3), strides=2, activation='relu'),\n",
    "    Flatten(),\n",
    "    Dense(128, activation='relu'),\n",
    "    Dense(10, activation='softmax')\n",
    "], name='CNN_StridedConv')\n",
    "\n",
    "result = train_and_evaluate(model_stride, 'Strided Conv (No Pooling)', epochs=5)\n",
    "results.append(result)\n",
    "print(f\"  Accuracy: {result['test_accuracy']:.2%}\")\n",
    "\n",
    "print(\"\\nâœ… Experiment 4 Complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ğŸ“ Reflection Questions (Experiment 4)\n",
    "\n",
    "1. Which pooling method performed best? Why?\n",
    "2. What's the difference between MaxPooling and AveragePooling?\n",
    "3. Can strided convolutions replace pooling? What are pros/cons?\n",
    "4. When would you choose AveragePooling over MaxPooling?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### âœï¸ YOUR ANSWERS HERE:\n",
    "\n",
    "1. Best pooling: [Write your answer]\n",
    "\n",
    "2. Max vs Average: [Write your answer]\n",
    "\n",
    "3. Strided conv: [Write your answer]\n",
    "\n",
    "4. When to use Average: [Write your answer]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Experiment 5: Your Custom Architecture! ğŸ¨\n",
    "\n",
    "**Challenge:** Design your own CNN to achieve the **highest accuracy** possible!\n",
    "\n",
    "**Rules:**\n",
    "- Must train in under 10 epochs\n",
    "- Can use any layers learned so far\n",
    "- Bonus: Try to beat 92% accuracy\n",
    "\n",
    "**Tips:**\n",
    "- Combine best practices from experiments 1-4\n",
    "- Consider dropout for regularization\n",
    "- Try batch normalization\n",
    "- Experiment with padding='same' to preserve size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"ğŸ§ª Experiment 5: Your Custom Architecture\\n\" + \"=\"*50)\n",
    "\n",
    "# BUILD YOUR MODEL HERE!\n",
    "# Use what you learned from experiments 1-4\n",
    "\n",
    "my_custom_model = Sequential([\n",
    "    # YOUR ARCHITECTURE HERE!\n",
    "    # Example structure (modify this):\n",
    "    \n",
    "    Conv2D(32, (3, 3), activation='relu', padding='same', input_shape=(28, 28, 1)),\n",
    "    Conv2D(32, (3, 3), activation='relu'),\n",
    "    MaxPooling2D((2, 2)),\n",
    "    Dropout(0.25),\n",
    "    \n",
    "    Conv2D(64, (3, 3), activation='relu', padding='same'),\n",
    "    Conv2D(64, (3, 3), activation='relu'),\n",
    "    MaxPooling2D((2, 2)),\n",
    "    Dropout(0.25),\n",
    "    \n",
    "    Flatten(),\n",
    "    Dense(256, activation='relu'),\n",
    "    Dropout(0.5),\n",
    "    Dense(10, activation='softmax')\n",
    "    \n",
    "    # Add more layers, change filters, try BatchNormalization, etc.\n",
    "    \n",
    "], name='MyCustomCNN')\n",
    "\n",
    "print(\"\\nTraining your custom architecture...\\n\")\n",
    "result = train_and_evaluate(my_custom_model, 'My Custom CNN', epochs=10, verbose=1)\n",
    "results.append(result)\n",
    "\n",
    "print(f\"\\nğŸ¯ Your Results:\")\n",
    "print(f\"  Accuracy: {result['test_accuracy']:.2%}\")\n",
    "print(f\"  Parameters: {result['parameters']:,}\")\n",
    "print(f\"  Training Time: {result['training_time']:.1f}s\")\n",
    "\n",
    "if result['test_accuracy'] > 0.92:\n",
    "    print(\"\\nğŸ† EXCELLENT! You beat 92% accuracy!\")\n",
    "elif result['test_accuracy'] > 0.90:\n",
    "    print(\"\\nğŸ‘ GOOD! You achieved >90% accuracy!\")\n",
    "else:\n",
    "    print(\"\\nğŸ’ª Keep experimenting to improve accuracy!\")\n",
    "\n",
    "print(\"\\nâœ… Experiment 5 Complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ğŸ“ Reflection Questions (Experiment 5)\n",
    "\n",
    "1. Describe your architecture design choices. Why did you choose this configuration?\n",
    "2. What accuracy did you achieve? How does it compare to the baseline?\n",
    "3. What techniques helped most? (More filters? Depth? Dropout? Batch norm?)\n",
    "4. If you had unlimited compute, what would you try next?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### âœï¸ YOUR ANSWERS HERE:\n",
    "\n",
    "1. Design choices: [Write your answer - explain your architecture]\n",
    "\n",
    "2. Accuracy achieved: [Write your answer]\n",
    "\n",
    "3. Most helpful techniques: [Write your answer]\n",
    "\n",
    "4. Future experiments: [Write your answer]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## ğŸ“Š Results Summary and Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create results dataframe\n",
    "df_results = pd.DataFrame([\n",
    "    {\n",
    "        'Configuration': r['name'],\n",
    "        'Accuracy (%)': f\"{r['test_accuracy']*100:.2f}\",\n",
    "        'Parameters': f\"{r['parameters']:,}\",\n",
    "        'Time (s)': f\"{r['training_time']:.1f}\"\n",
    "    }\n",
    "    for r in results\n",
    "])\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"ALL EXPERIMENTS SUMMARY\")\n",
    "print(\"=\"*80)\n",
    "print(df_results.to_string(index=False))\n",
    "print(\"=\"*80)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract data for plotting\n",
    "names = [r['name'] for r in results]\n",
    "accuracies = [r['test_accuracy'] * 100 for r in results]\n",
    "params = [r['parameters'] / 1000 for r in results]  # In thousands\n",
    "times = [r['training_time'] for r in results]\n",
    "\n",
    "# Create visualizations\n",
    "fig, axes = plt.subplots(1, 3, figsize=(18, 5))\n",
    "\n",
    "# Accuracy comparison\n",
    "axes[0].barh(range(len(names)), accuracies, color='steelblue', alpha=0.8)\n",
    "axes[0].set_yticks(range(len(names)))\n",
    "axes[0].set_yticklabels(names, fontsize=9)\n",
    "axes[0].set_xlabel('Test Accuracy (%)', fontsize=11)\n",
    "axes[0].set_title('Accuracy Comparison', fontsize=13, fontweight='bold')\n",
    "axes[0].set_xlim([85, 95])\n",
    "axes[0].grid(True, alpha=0.3, axis='x')\n",
    "\n",
    "# Parameters comparison\n",
    "axes[1].barh(range(len(names)), params, color='coral', alpha=0.8)\n",
    "axes[1].set_yticks(range(len(names)))\n",
    "axes[1].set_yticklabels(names, fontsize=9)\n",
    "axes[1].set_xlabel('Parameters (thousands)', fontsize=11)\n",
    "axes[1].set_title('Model Size Comparison', fontsize=13, fontweight='bold')\n",
    "axes[1].grid(True, alpha=0.3, axis='x')\n",
    "\n",
    "# Training time comparison\n",
    "axes[2].barh(range(len(names)), times, color='lightgreen', alpha=0.8)\n",
    "axes[2].set_yticks(range(len(names)))\n",
    "axes[2].set_yticklabels(names, fontsize=9)\n",
    "axes[2].set_xlabel('Training Time (seconds)', fontsize=11)\n",
    "axes[2].set_title('Training Time Comparison', fontsize=13, fontweight='bold')\n",
    "axes[2].grid(True, alpha=0.3, axis='x')\n",
    "\n",
    "plt.suptitle('CNN Architecture Experiments - Complete Comparison', \n",
    "            fontsize=16, fontweight='bold')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Accuracy vs Parameters Trade-off"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scatter plot: Accuracy vs Parameters\n",
    "plt.figure(figsize=(12, 7))\n",
    "plt.scatter(params, accuracies, s=200, alpha=0.6, c=range(len(results)), cmap='viridis')\n",
    "\n",
    "# Annotate points\n",
    "for i, name in enumerate(names):\n",
    "    plt.annotate(name, (params[i], accuracies[i]), \n",
    "                fontsize=9, ha='right', va='bottom',\n",
    "                xytext=(-5, 5), textcoords='offset points')\n",
    "\n",
    "plt.xlabel('Parameters (thousands)', fontsize=13, fontweight='bold')\n",
    "plt.ylabel('Test Accuracy (%)', fontsize=13, fontweight='bold')\n",
    "plt.title('Accuracy vs Model Size Trade-off', fontsize=16, fontweight='bold')\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nğŸ’¡ Insight: The best models balance accuracy and efficiency!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## ğŸ“ Final Reflection\n",
    "\n",
    "### Answer these overall questions:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### âœï¸ FINAL REFLECTION:\n",
    "\n",
    "**1. What was the most surprising finding from your experiments?**\n",
    "\n",
    "[Write your answer]\n",
    "\n",
    "**2. If you were building a CNN for a production app (limited resources), which configuration would you choose and why?**\n",
    "\n",
    "[Write your answer]\n",
    "\n",
    "**3. What are 3 key principles you learned about CNN architecture design?**\n",
    "\n",
    "1. [Write principle 1]\n",
    "2. [Write principle 2]\n",
    "3. [Write principle 3]\n",
    "\n",
    "**4. What questions do you still have about CNNs?**\n",
    "\n",
    "[Write your questions]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## ğŸ“¤ Submission Checklist\n",
    "\n",
    "Before submitting, ensure:\n",
    "\n",
    "- [ ] All 5 experiments completed\n",
    "- [ ] All reflection questions answered\n",
    "- [ ] Custom architecture (Experiment 5) achieves >88% accuracy\n",
    "- [ ] Results visualizations generated\n",
    "- [ ] Final reflection completed\n",
    "- [ ] Notebook runs without errors (Cell â†’ Run All)\n",
    "- [ ] Uploaded to Google Colab/Classroom\n",
    "\n",
    "---\n",
    "\n",
    "## ğŸ† Grading Rubric (20 points)\n",
    "\n",
    "| Component | Points |\n",
    "|-----------|--------|\n",
    "| Experiment 1 completed + reflections | 3 |\n",
    "| Experiment 2 completed + reflections | 3 |\n",
    "| Experiment 3 completed + reflections | 3 |\n",
    "| Experiment 4 completed + reflections | 3 |\n",
    "| Experiment 5 custom architecture | 4 |\n",
    "| Final reflection quality | 2 |\n",
    "| Code runs without errors | 2 |\n",
    "| **Bonus: Accuracy >92%** | +2 |\n",
    "\n",
    "---\n",
    "\n",
    "**Great work! You've systematically explored CNN architectures! ğŸ‰**\n",
    "\n",
    "**Next class:** We'll learn about batch normalization, dropout, and data augmentation to push accuracy even higher!\n",
    "\n",
    "---\n",
    "\n",
    "*â±ï¸ Time to complete: ~2-3 hours*  \n",
    "*ğŸ’ª Difficulty: Intermediate*  \n",
    "*ğŸ“ Learning value: Very High*"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
