{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notebook 6: Data Augmentation\n",
    "\n",
    "**Course:** 21CSE558T - Deep Neural Network Architectures  \n",
    "**Module 4:** CNNs - Practical Session  \n",
    "**Date:** Monday, November 3, 2025  \n",
    "**Duration:** 30 minutes  \n",
    "**Objective:** Use data augmentation to improve model generalization and accuracy\n",
    "\n",
    "---\n",
    "\n",
    "## The Data Problem\n",
    "\n",
    "**Scenario:** You have only 1,000 images but need 10,000 for good accuracy.\n",
    "\n",
    "**Traditional solution:** Collect more data (expensive, time-consuming)\n",
    "\n",
    "**Smart solution:** **Data Augmentation** - Create new training samples from existing ones!\n",
    "\n",
    "---\n",
    "\n",
    "## What is Data Augmentation?\n",
    "\n",
    "**Definition:** Apply random transformations to training images:\n",
    "- Rotation\n",
    "- Shifting\n",
    "- Flipping\n",
    "- Zooming\n",
    "- Brightness changes\n",
    "\n",
    "**Result:** Same image becomes many different versions → More training data!\n",
    "\n",
    "**Key:** Only augment **training** data, not test data!\n",
    "\n",
    "---\n",
    "\n",
    "## Benefits:\n",
    "\n",
    "1. ✅ **Reduces overfitting** - Model sees more variations\n",
    "2. ✅ **Improves generalization** - Better on unseen data\n",
    "3. ✅ **Makes model robust** - Invariant to small changes\n",
    "4. ✅ **No cost** - Free data from existing images!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.datasets import fashion_mnist\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import (\n",
    "    Conv2D, MaxPooling2D, GlobalAveragePooling2D,\n",
    "    Dense, Dropout, BatchNormalization\n",
    ")\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "print(f\"✅ TensorFlow version: {tf.__version__}\")\n",
    "\n",
    "# Set seed\n",
    "tf.random.set_seed(42)\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 1: Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Fashion-MNIST\n",
    "(x_train, y_train), (x_test, y_test) = fashion_mnist.load_data()\n",
    "\n",
    "class_names = ['T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat',\n",
    "               'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle boot']\n",
    "\n",
    "# Preprocessing\n",
    "x_train = x_train.reshape(-1, 28, 28, 1).astype('float32') / 255.0\n",
    "x_test = x_test.reshape(-1, 28, 28, 1).astype('float32') / 255.0\n",
    "y_train_cat = to_categorical(y_train, 10)\n",
    "y_test_cat = to_categorical(y_test, 10)\n",
    "\n",
    "print(f\"✅ Data loaded: {x_train.shape[0]:,} training samples\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 2: Visualize Augmentation Techniques\n",
    "\n",
    "Let's see what each augmentation does!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select one sample image\n",
    "sample_img = x_train[0]\n",
    "sample_label = class_names[y_train[0]]\n",
    "\n",
    "# Prepare for augmentation (need batch dimension)\n",
    "img_batch = sample_img.reshape((1, 28, 28, 1))\n",
    "\n",
    "print(f\"Original image: {sample_label}\")\n",
    "print(f\"Shape: {sample_img.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Augmentation 1: Rotation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rotation augmentation\n",
    "rotation_gen = ImageDataGenerator(rotation_range=30)  # ±30 degrees\n",
    "\n",
    "fig, axes = plt.subplots(2, 5, figsize=(15, 6))\n",
    "\n",
    "# Original\n",
    "axes[0, 0].imshow(sample_img.reshape(28, 28), cmap='gray')\n",
    "axes[0, 0].set_title('Original', fontsize=12, fontweight='bold')\n",
    "axes[0, 0].axis('off')\n",
    "\n",
    "# Generate rotated versions\n",
    "aug_iter = rotation_gen.flow(img_batch, batch_size=1)\n",
    "for i in range(9):\n",
    "    row = (i + 1) // 5\n",
    "    col = (i + 1) % 5\n",
    "    aug_img = next(aug_iter)[0]\n",
    "    axes[row, col].imshow(aug_img.reshape(28, 28), cmap='gray')\n",
    "    axes[row, col].set_title(f'Rotated {i+1}', fontsize=10)\n",
    "    axes[row, col].axis('off')\n",
    "\n",
    "plt.suptitle(f'Rotation Augmentation (±30°) - {sample_label}', fontsize=16, fontweight='bold')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"💡 Each training iteration shows the model a different rotation!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Augmentation 2: Shifting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shifting augmentation\n",
    "shift_gen = ImageDataGenerator(\n",
    "    width_shift_range=0.2,   # Shift horizontally by ±20%\n",
    "    height_shift_range=0.2   # Shift vertically by ±20%\n",
    ")\n",
    "\n",
    "fig, axes = plt.subplots(2, 5, figsize=(15, 6))\n",
    "\n",
    "axes[0, 0].imshow(sample_img.reshape(28, 28), cmap='gray')\n",
    "axes[0, 0].set_title('Original', fontsize=12, fontweight='bold')\n",
    "axes[0, 0].axis('off')\n",
    "\n",
    "aug_iter = shift_gen.flow(img_batch, batch_size=1)\n",
    "for i in range(9):\n",
    "    row = (i + 1) // 5\n",
    "    col = (i + 1) % 5\n",
    "    aug_img = next(aug_iter)[0]\n",
    "    axes[row, col].imshow(aug_img.reshape(28, 28), cmap='gray')\n",
    "    axes[row, col].set_title(f'Shifted {i+1}', fontsize=10)\n",
    "    axes[row, col].axis('off')\n",
    "\n",
    "plt.suptitle(f'Translation/Shifting Augmentation - {sample_label}', fontsize=16, fontweight='bold')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"💡 Object can appear at different positions in the image!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Augmentation 3: Zooming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Zoom augmentation\n",
    "zoom_gen = ImageDataGenerator(zoom_range=0.2)  # Zoom in/out by ±20%\n",
    "\n",
    "fig, axes = plt.subplots(2, 5, figsize=(15, 6))\n",
    "\n",
    "axes[0, 0].imshow(sample_img.reshape(28, 28), cmap='gray')\n",
    "axes[0, 0].set_title('Original', fontsize=12, fontweight='bold')\n",
    "axes[0, 0].axis('off')\n",
    "\n",
    "aug_iter = zoom_gen.flow(img_batch, batch_size=1)\n",
    "for i in range(9):\n",
    "    row = (i + 1) // 5\n",
    "    col = (i + 1) % 5\n",
    "    aug_img = next(aug_iter)[0]\n",
    "    axes[row, col].imshow(aug_img.reshape(28, 28), cmap='gray')\n",
    "    axes[row, col].set_title(f'Zoomed {i+1}', fontsize=10)\n",
    "    axes[row, col].axis('off')\n",
    "\n",
    "plt.suptitle(f'Zoom Augmentation - {sample_label}', fontsize=16, fontweight='bold')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"💡 Objects can appear at different scales!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Augmentation 4: Horizontal Flip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Flip augmentation\n",
    "flip_gen = ImageDataGenerator(horizontal_flip=True)\n",
    "\n",
    "fig, axes = plt.subplots(1, 3, figsize=(12, 4))\n",
    "\n",
    "# Original\n",
    "axes[0].imshow(sample_img.reshape(28, 28), cmap='gray')\n",
    "axes[0].set_title('Original', fontsize=13, fontweight='bold')\n",
    "axes[0].axis('off')\n",
    "\n",
    "# Flipped versions\n",
    "aug_iter = flip_gen.flow(img_batch, batch_size=1)\n",
    "for i in range(2):\n",
    "    aug_img = next(aug_iter)[0]\n",
    "    axes[i+1].imshow(aug_img.reshape(28, 28), cmap='gray')\n",
    "    axes[i+1].set_title(f'Flipped {i+1}', fontsize=13, fontweight='bold')\n",
    "    axes[i+1].axis('off')\n",
    "\n",
    "plt.suptitle(f'Horizontal Flip Augmentation - {sample_label}', fontsize=16, fontweight='bold')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"💡 Note: Not all classes should be flipped (e.g., text, digits)\")\n",
    "print(\"   For Fashion-MNIST, flipping makes sense for most items!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Augmentation 5: Combined Transformations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combined augmentation (realistic scenario)\n",
    "combined_gen = ImageDataGenerator(\n",
    "    rotation_range=20,\n",
    "    width_shift_range=0.15,\n",
    "    height_shift_range=0.15,\n",
    "    zoom_range=0.15,\n",
    "    horizontal_flip=True,\n",
    "    fill_mode='nearest'\n",
    ")\n",
    "\n",
    "fig, axes = plt.subplots(3, 5, figsize=(15, 9))\n",
    "\n",
    "# Original\n",
    "axes[0, 0].imshow(sample_img.reshape(28, 28), cmap='gray')\n",
    "axes[0, 0].set_title('ORIGINAL', fontsize=12, fontweight='bold', color='red')\n",
    "axes[0, 0].axis('off')\n",
    "\n",
    "# Generate 14 augmented versions\n",
    "aug_iter = combined_gen.flow(img_batch, batch_size=1)\n",
    "for i in range(14):\n",
    "    if i == 0:\n",
    "        row, col = 0, 1\n",
    "    else:\n",
    "        row = (i + 1) // 5\n",
    "        col = (i + 1) % 5\n",
    "    \n",
    "    aug_img = next(aug_iter)[0]\n",
    "    axes[row, col].imshow(aug_img.reshape(28, 28), cmap='gray')\n",
    "    axes[row, col].set_title(f'Augmented {i+1}', fontsize=10)\n",
    "    axes[row, col].axis('off')\n",
    "\n",
    "plt.suptitle(f'Combined Augmentation - {sample_label}\\n(Rotation + Shift + Zoom + Flip)', \n",
    "             fontsize=16, fontweight='bold')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"💡 One image → Infinite variations!\")\n",
    "print(\"💡 Model never sees exact same image twice during training!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 3: Train Without Augmentation (Baseline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build a good CNN model\n",
    "def build_model():\n",
    "    model = Sequential([\n",
    "        Conv2D(64, (3, 3), padding='same', input_shape=(28, 28, 1)),\n",
    "        BatchNormalization(),\n",
    "        tf.keras.layers.Activation('relu'),\n",
    "        Conv2D(64, (3, 3), padding='same'),\n",
    "        BatchNormalization(),\n",
    "        tf.keras.layers.Activation('relu'),\n",
    "        MaxPooling2D((2, 2)),\n",
    "        Dropout(0.25),\n",
    "        \n",
    "        Conv2D(128, (3, 3), padding='same'),\n",
    "        BatchNormalization(),\n",
    "        tf.keras.layers.Activation('relu'),\n",
    "        Conv2D(128, (3, 3), padding='same'),\n",
    "        BatchNormalization(),\n",
    "        tf.keras.layers.Activation('relu'),\n",
    "        MaxPooling2D((2, 2)),\n",
    "        Dropout(0.25),\n",
    "        \n",
    "        GlobalAveragePooling2D(),\n",
    "        Dense(256),\n",
    "        BatchNormalization(),\n",
    "        tf.keras.layers.Activation('relu'),\n",
    "        Dropout(0.5),\n",
    "        Dense(10, activation='softmax')\n",
    "    ])\n",
    "    return model\n",
    "\n",
    "# Build baseline model\n",
    "baseline_model = build_model()\n",
    "baseline_model.compile(optimizer='adam',\n",
    "                       loss='categorical_crossentropy',\n",
    "                       metrics=['accuracy'])\n",
    "\n",
    "print(\"✅ Baseline model built\")\n",
    "print(f\"Parameters: {baseline_model.count_params():,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train WITHOUT augmentation\n",
    "print(\"🚀 Training WITHOUT augmentation...\\n\")\n",
    "\n",
    "baseline_history = baseline_model.fit(\n",
    "    x_train, y_train_cat,\n",
    "    batch_size=128,\n",
    "    epochs=20,\n",
    "    validation_split=0.1,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "baseline_test_loss, baseline_test_acc = baseline_model.evaluate(x_test, y_test_cat, verbose=0)\n",
    "print(f\"\\n📊 Baseline Test Accuracy: {baseline_test_acc:.2%}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 4: Train WITH Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create augmentation generator\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rotation_range=15,\n",
    "    width_shift_range=0.1,\n",
    "    height_shift_range=0.1,\n",
    "    zoom_range=0.1,\n",
    "    horizontal_flip=True,\n",
    "    fill_mode='nearest'\n",
    ")\n",
    "\n",
    "# NO augmentation for validation/test (only normalize)\n",
    "val_datagen = ImageDataGenerator()  # No augmentation!\n",
    "\n",
    "print(\"✅ Data augmentation generators created\")\n",
    "print(\"\\n📋 Augmentation parameters:\")\n",
    "print(\"  • Rotation: ±15°\")\n",
    "print(\"  • Width shift: ±10%\")\n",
    "print(\"  • Height shift: ±10%\")\n",
    "print(\"  • Zoom: ±10%\")\n",
    "print(\"  • Horizontal flip: Yes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build new model for augmented training\n",
    "augmented_model = build_model()\n",
    "augmented_model.compile(optimizer='adam',\n",
    "                        loss='categorical_crossentropy',\n",
    "                        metrics=['accuracy'])\n",
    "\n",
    "# Split training data for validation\n",
    "split_idx = int(0.9 * len(x_train))\n",
    "x_train_split = x_train[:split_idx]\n",
    "y_train_split = y_train_cat[:split_idx]\n",
    "x_val_split = x_train[split_idx:]\n",
    "y_val_split = y_train_cat[split_idx:]\n",
    "\n",
    "print(f\"Training samples: {len(x_train_split):,}\")\n",
    "print(f\"Validation samples: {len(x_val_split):,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train WITH augmentation\n",
    "print(\"\\n🚀 Training WITH augmentation...\\n\")\n",
    "\n",
    "# Create generators\n",
    "train_generator = train_datagen.flow(x_train_split, y_train_split, batch_size=128)\n",
    "val_generator = val_datagen.flow(x_val_split, y_val_split, batch_size=128)\n",
    "\n",
    "augmented_history = augmented_model.fit(\n",
    "    train_generator,\n",
    "    steps_per_epoch=len(x_train_split) // 128,\n",
    "    epochs=20,\n",
    "    validation_data=val_generator,\n",
    "    validation_steps=len(x_val_split) // 128,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "augmented_test_loss, augmented_test_acc = augmented_model.evaluate(x_test, y_test_cat, verbose=0)\n",
    "print(f\"\\n📊 Augmented Model Test Accuracy: {augmented_test_acc:.2%}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 5: Compare Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comparison plots\n",
    "fig, axes = plt.subplots(1, 2, figsize=(16, 5))\n",
    "\n",
    "# Accuracy comparison\n",
    "axes[0].plot(baseline_history.history['accuracy'], 'b-', label='Train (No Aug)', linewidth=2)\n",
    "axes[0].plot(baseline_history.history['val_accuracy'], 'b--', label='Val (No Aug)', linewidth=2)\n",
    "axes[0].plot(augmented_history.history['accuracy'], 'g-', label='Train (With Aug)', linewidth=2)\n",
    "axes[0].plot(augmented_history.history['val_accuracy'], 'g--', label='Val (With Aug)', linewidth=2)\n",
    "axes[0].set_xlabel('Epoch', fontsize=12)\n",
    "axes[0].set_ylabel('Accuracy', fontsize=12)\n",
    "axes[0].set_title('Accuracy: With vs Without Augmentation', fontsize=14, fontweight='bold')\n",
    "axes[0].legend(fontsize=10)\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "\n",
    "# Loss comparison\n",
    "axes[1].plot(baseline_history.history['loss'], 'b-', label='Train (No Aug)', linewidth=2)\n",
    "axes[1].plot(baseline_history.history['val_loss'], 'b--', label='Val (No Aug)', linewidth=2)\n",
    "axes[1].plot(augmented_history.history['loss'], 'g-', label='Train (With Aug)', linewidth=2)\n",
    "axes[1].plot(augmented_history.history['val_loss'], 'g--', label='Val (With Aug)', linewidth=2)\n",
    "axes[1].set_xlabel('Epoch', fontsize=12)\n",
    "axes[1].set_ylabel('Loss', fontsize=12)\n",
    "axes[1].set_title('Loss: With vs Without Augmentation', fontsize=14, fontweight='bold')\n",
    "axes[1].legend(fontsize=10)\n",
    "axes[1].grid(True, alpha=0.3)\n",
    "\n",
    "plt.suptitle('Data Augmentation Impact', fontsize=16, fontweight='bold')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Final comparison\n",
    "import pandas as pd\n",
    "\n",
    "comparison_data = {\n",
    "    'Model': ['Without Augmentation', 'With Augmentation'],\n",
    "    'Test Accuracy': [f\"{baseline_test_acc:.2%}\", f\"{augmented_test_acc:.2%}\"],\n",
    "    'Test Loss': [f\"{baseline_test_loss:.4f}\", f\"{augmented_test_loss:.4f}\"],\n",
    "    'Final Train Acc': [\n",
    "        f\"{baseline_history.history['accuracy'][-1]:.2%}\",\n",
    "        f\"{augmented_history.history['accuracy'][-1]:.2%}\"\n",
    "    ],\n",
    "    'Final Val Acc': [\n",
    "        f\"{baseline_history.history['val_accuracy'][-1]:.2%}\",\n",
    "        f\"{augmented_history.history['val_accuracy'][-1]:.2%}\"\n",
    "    ],\n",
    "    'Overfitting Gap': [\n",
    "        f\"{baseline_history.history['accuracy'][-1] - baseline_history.history['val_accuracy'][-1]:.2%}\",\n",
    "        f\"{augmented_history.history['accuracy'][-1] - augmented_history.history['val_accuracy'][-1]:.2%}\"\n",
    "    ]\n",
    "}\n",
    "\n",
    "df_comparison = pd.DataFrame(comparison_data)\n",
    "\n",
    "print(\"\\n\" + \"=\"*90)\n",
    "print(\"DATA AUGMENTATION - FINAL COMPARISON\")\n",
    "print(\"=\"*90)\n",
    "print(df_comparison.to_string(index=False))\n",
    "print(\"=\"*90)\n",
    "\n",
    "# Calculate improvement\n",
    "improvement = augmented_test_acc - baseline_test_acc\n",
    "print(f\"\\n🎯 Test Accuracy Improvement: {improvement:+.2%}\")\n",
    "\n",
    "if improvement > 0:\n",
    "    print(\"\\n✅ SUCCESS! Augmentation improved test accuracy!\")\n",
    "    print(\"✅ Overfitting gap reduced\")\n",
    "    print(\"✅ Model generalizes better to unseen data\")\n",
    "else:\n",
    "    print(\"\\n⚠️ Note: Augmentation helps most when you have limited data\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 6: When to Use Which Augmentation?\n",
    "\n",
    "Not all augmentations work for all datasets!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create visualization of good vs bad augmentations\n",
    "fig, axes = plt.subplots(3, 4, figsize=(16, 12))\n",
    "\n",
    "# Select different types of images\n",
    "indices = [0, 1, 2]  # T-shirt, Trouser, Pullover\n",
    "aug_types = [\n",
    "    ('Original', None),\n",
    "    ('Rotation ✅', ImageDataGenerator(rotation_range=30)),\n",
    "    ('Shift ✅', ImageDataGenerator(width_shift_range=0.2, height_shift_range=0.2)),\n",
    "    ('Flip ✅', ImageDataGenerator(horizontal_flip=True))\n",
    "]\n",
    "\n",
    "for i, idx in enumerate(indices):\n",
    "    img = x_train[idx:idx+1]\n",
    "    label = class_names[y_train[idx]]\n",
    "    \n",
    "    for j, (aug_name, aug_gen) in enumerate(aug_types):\n",
    "        if aug_gen is None:\n",
    "            axes[i, j].imshow(img[0].reshape(28, 28), cmap='gray')\n",
    "        else:\n",
    "            aug_img = next(aug_gen.flow(img, batch_size=1))[0]\n",
    "            axes[i, j].imshow(aug_img.reshape(28, 28), cmap='gray')\n",
    "        \n",
    "        if i == 0:\n",
    "            axes[i, j].set_title(aug_name, fontsize=12, fontweight='bold')\n",
    "        \n",
    "        if j == 0:\n",
    "            axes[i, j].set_ylabel(label, fontsize=11, fontweight='bold')\n",
    "        \n",
    "        axes[i, j].axis('off')\n",
    "\n",
    "plt.suptitle('Data Augmentation Examples on Fashion-MNIST', fontsize=16, fontweight='bold')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\n📋 Augmentation Guidelines:\")\n",
    "print(\"\\n✅ GOOD for Fashion-MNIST:\")\n",
    "print(\"  • Rotation (±15-20°) - clothes can be at angles\")\n",
    "print(\"  • Shifting (±10-15%) - items not always centered\")\n",
    "print(\"  • Zoom (±10-15%) - different sizes\")\n",
    "print(\"  • Horizontal flip - most items symmetric\")\n",
    "print(\"\\n❌ BAD for Fashion-MNIST:\")\n",
    "print(\"  • Vertical flip - upside-down clothes don't make sense\")\n",
    "print(\"  • Extreme rotation (±45°+) - unrealistic\")\n",
    "print(\"  • Color jitter - already grayscale\")\n",
    "\n",
    "print(\"\\n📋 For other datasets:\")\n",
    "print(\"\\n• MNIST Digits:\")\n",
    "print(\"  ✅ Small rotation (±10°)\")\n",
    "print(\"  ✅ Small shift\")\n",
    "print(\"  ❌ NO flipping (6 becomes 9!)\")\n",
    "print(\"\\n• Natural Images (cats, dogs):\")\n",
    "print(\"  ✅ All transformations\")\n",
    "print(\"  ✅ Brightness, contrast changes\")\n",
    "print(\"  ✅ Color jitter\")\n",
    "print(\"\\n• Medical Images (X-rays):\")\n",
    "print(\"  ⚠️ Careful with augmentation\")\n",
    "print(\"  ✅ Small rotation, shift\")\n",
    "print(\"  ❌ Usually NO flip (left/right matters)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Summary: Key Takeaways 🎯\n",
    "\n",
    "### What is Data Augmentation?\n",
    "\n",
    "- **Transform training images** on-the-fly\n",
    "- **Infinite variations** from limited data\n",
    "- **Only apply to training** (not validation/test)\n",
    "- **Free regularization** - no additional data collection\n",
    "\n",
    "### Common Augmentation Techniques:\n",
    "\n",
    "1. **✅ Rotation** - Rotate image by random angle\n",
    "2. **✅ Translation** - Shift horizontally/vertically\n",
    "3. **✅ Zoom** - Scale in/out\n",
    "4. **✅ Flip** - Horizontal/vertical mirroring\n",
    "5. **✅ Brightness** - Adjust lighting (for color images)\n",
    "6. **✅ Contrast** - Change contrast (for color images)\n",
    "\n",
    "### ImageDataGenerator Parameters:\n",
    "\n",
    "```python\n",
    "ImageDataGenerator(\n",
    "    rotation_range=20,        # ±20 degrees\n",
    "    width_shift_range=0.1,    # ±10% width\n",
    "    height_shift_range=0.1,   # ±10% height\n",
    "    zoom_range=0.1,           # ±10% zoom\n",
    "    horizontal_flip=True,     # 50% chance flip\n",
    "    fill_mode='nearest'       # How to fill new pixels\n",
    ")\n",
    "```\n",
    "\n",
    "### Benefits:\n",
    "\n",
    "1. **✅ Reduces overfitting** - More diverse training data\n",
    "2. **✅ Improves test accuracy** - Better generalization\n",
    "3. **✅ Makes model robust** - Invariant to transformations\n",
    "4. **✅ No cost** - Generated from existing data\n",
    "\n",
    "### Best Practices:\n",
    "\n",
    "- **Start conservative** - Small augmentation values\n",
    "- **Check visualizations** - Ensure augmented images make sense\n",
    "- **Domain-specific** - Different datasets need different augmentations\n",
    "- **Monitor validation** - Too much augmentation can hurt\n",
    "- **Combine with other regularization** - Dropout, BatchNorm, etc.\n",
    "\n",
    "### When to Use:\n",
    "\n",
    "| Scenario | Augmentation Benefit |\n",
    "|----------|---------------------|\n",
    "| Small dataset (<10K images) | ⭐⭐⭐⭐⭐ Very High |\n",
    "| Medium dataset (10K-100K) | ⭐⭐⭐⭐ High |\n",
    "| Large dataset (>100K) | ⭐⭐⭐ Moderate |\n",
    "| Overfitting observed | ⭐⭐⭐⭐⭐ Very High |\n",
    "| Balanced classes | ⭐⭐⭐⭐ High |\n",
    "| Imbalanced classes | ⭐⭐⭐⭐⭐ Very High |\n",
    "\n",
    "---\n",
    "\n",
    "## Practice Exercises 📝\n",
    "\n",
    "1. **Experiment:** Try extreme augmentation (rotation=45, zoom=0.5). What happens?\n",
    "\n",
    "2. **Challenge:** Augment only the minority classes (imbalanced dataset simulation)\n",
    "\n",
    "3. **Analysis:** How many training epochs do you need with vs without augmentation?\n",
    "\n",
    "4. **Custom:** Create your own augmentation pipeline for a specific use case\n",
    "\n",
    "---\n",
    "\n",
    "## Next: Notebook 7 - Final Challenge! 🏆\n",
    "\n",
    "**Coming up:** Combine everything you learned to build the best possible CNN!\n",
    "\n",
    "---\n",
    "\n",
    "*⏱️ Time spent: ~30 minutes*  \n",
    "*💪 Difficulty: Intermediate*  \n",
    "*🎓 Mastery: Data augmentation techniques*"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
