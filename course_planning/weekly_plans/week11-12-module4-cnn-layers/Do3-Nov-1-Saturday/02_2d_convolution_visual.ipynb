{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notebook 2: 2D Convolution on Images\n",
    "\n",
    "**Course:** 21CSE558T - Deep Neural Network Architectures  \n",
    "**Module 4:** CNNs - Practical Session  \n",
    "**Date:** Saturday, November 1, 2025  \n",
    "**Duration:** 30 minutes  \n",
    "**Objective:** Understand 2D convolution with visual demonstrations on real images\n",
    "\n",
    "---\n",
    "\n",
    "## From 1D to 2D\n",
    "\n",
    "**1D Convolution:**  \n",
    "```\n",
    "Signal: [1, 2, 3, 4, 5]\n",
    "Kernel: [a, b, c]\n",
    "```\n",
    "\n",
    "**2D Convolution:**  \n",
    "```\n",
    "Image:  [[1, 2, 3],      Kernel:  [[a, b],\n",
    "         [4, 5, 6],                [c, d]]\n",
    "         [7, 8, 9]]\n",
    "```\n",
    "\n",
    "**Same idea:** Slide a window, multiply & sum!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from tensorflow.keras.datasets import fashion_mnist\n",
    "import cv2\n",
    "from scipy import signal\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set style\n",
    "sns.set_style(\"white\")\n",
    "plt.rcParams['figure.figsize'] = (14, 6)\n",
    "\n",
    "print(\"‚úÖ Libraries loaded successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 1: Load Fashion-MNIST Dataset\n",
    "\n",
    "**Fashion-MNIST:**\n",
    "- 70,000 grayscale images\n",
    "- 28√ó28 pixels\n",
    "- 10 classes: T-shirt, Trouser, Pullover, Dress, Coat, Sandal, Shirt, Sneaker, Bag, Ankle boot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Fashion-MNIST\n",
    "(x_train, y_train), (x_test, y_test) = fashion_mnist.load_data()\n",
    "\n",
    "# Class names\n",
    "class_names = ['T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat',\n",
    "               'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle boot']\n",
    "\n",
    "print(f\"Training samples: {x_train.shape[0]}\")\n",
    "print(f\"Test samples: {x_test.shape[0]}\")\n",
    "print(f\"Image shape: {x_train.shape[1:]}\")\n",
    "\n",
    "# Visualize samples\n",
    "fig, axes = plt.subplots(2, 5, figsize=(15, 6))\n",
    "for i, ax in enumerate(axes.flat):\n",
    "    ax.imshow(x_train[i], cmap='gray')\n",
    "    ax.set_title(f'{class_names[y_train[i]]}', fontsize=11)\n",
    "    ax.axis('off')\n",
    "plt.suptitle('Fashion-MNIST Sample Images', fontsize=16, fontweight='bold')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 2: 2D Convolution from Scratch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv2d_simple(image, kernel, stride=1, padding=0):\n",
    "    \"\"\"\n",
    "    2D convolution from scratch\n",
    "    \n",
    "    Args:\n",
    "        image: Input 2D array (H x W)\n",
    "        kernel: 2D filter (Kh x Kw)\n",
    "        stride: Step size\n",
    "        padding: Padding size\n",
    "    \n",
    "    Returns:\n",
    "        output: Convolved image\n",
    "    \"\"\"\n",
    "    # Add padding\n",
    "    if padding > 0:\n",
    "        image = np.pad(image, ((padding, padding), (padding, padding)), mode='constant')\n",
    "    \n",
    "    # Get dimensions\n",
    "    H, W = image.shape\n",
    "    Kh, Kw = kernel.shape\n",
    "    \n",
    "    # Calculate output size\n",
    "    out_h = (H - Kh) // stride + 1\n",
    "    out_w = (W - Kw) // stride + 1\n",
    "    output = np.zeros((out_h, out_w))\n",
    "    \n",
    "    # Perform convolution\n",
    "    for i in range(out_h):\n",
    "        for j in range(out_w):\n",
    "            # Extract region\n",
    "            h_start = i * stride\n",
    "            w_start = j * stride\n",
    "            region = image[h_start:h_start+Kh, w_start:w_start+Kw]\n",
    "            \n",
    "            # Element-wise multiplication and sum\n",
    "            output[i, j] = np.sum(region * kernel)\n",
    "    \n",
    "    return output\n",
    "\n",
    "print(\"‚úÖ 2D Convolution function defined!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 3: Classic Image Kernels\n",
    "\n",
    "Let's apply famous kernels to see what they detect!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select one image (a sneaker)\n",
    "sample_img = x_train[7].astype('float32')\n",
    "\n",
    "# Define classic kernels\n",
    "kernels = {\n",
    "    'Identity': np.array([[0, 0, 0],\n",
    "                          [0, 1, 0],\n",
    "                          [0, 0, 0]]),\n",
    "    \n",
    "    'Blur': np.ones((3, 3)) / 9,\n",
    "    \n",
    "    'Sharpen': np.array([[0, -1, 0],\n",
    "                         [-1, 5, -1],\n",
    "                         [0, -1, 0]]),\n",
    "    \n",
    "    'Edge (Horizontal)': np.array([[-1, -1, -1],\n",
    "                                   [0, 0, 0],\n",
    "                                   [1, 1, 1]]),\n",
    "    \n",
    "    'Edge (Vertical)': np.array([[-1, 0, 1],\n",
    "                                 [-1, 0, 1],\n",
    "                                 [-1, 0, 1]]),\n",
    "    \n",
    "    'Sobel X': np.array([[-1, 0, 1],\n",
    "                         [-2, 0, 2],\n",
    "                         [-1, 0, 1]]),\n",
    "    \n",
    "    'Sobel Y': np.array([[-1, -2, -1],\n",
    "                         [0, 0, 0],\n",
    "                         [1, 2, 1]]),\n",
    "    \n",
    "    'Emboss': np.array([[-2, -1, 0],\n",
    "                        [-1, 1, 1],\n",
    "                        [0, 1, 2]])\n",
    "}\n",
    "\n",
    "# Apply all kernels\n",
    "fig, axes = plt.subplots(3, 3, figsize=(15, 15))\n",
    "\n",
    "# Original image\n",
    "axes[0, 0].imshow(sample_img, cmap='gray')\n",
    "axes[0, 0].set_title('Original Image', fontsize=14, fontweight='bold')\n",
    "axes[0, 0].axis('off')\n",
    "\n",
    "# Apply each kernel\n",
    "for idx, (name, kernel) in enumerate(kernels.items(), 1):\n",
    "    row = idx // 3\n",
    "    col = idx % 3\n",
    "    \n",
    "    # Convolve\n",
    "    output = conv2d_simple(sample_img, kernel)\n",
    "    \n",
    "    # Display\n",
    "    axes[row, col].imshow(output, cmap='gray')\n",
    "    axes[row, col].set_title(f'{name}', fontsize=12, fontweight='bold')\n",
    "    axes[row, col].axis('off')\n",
    "\n",
    "plt.suptitle('Effect of Different 2D Kernels on Fashion-MNIST Image', fontsize=16, fontweight='bold')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nüîç Observations:\")\n",
    "print(\"‚úÖ Identity: No change (kernel is [0,0,0; 0,1,0; 0,0,0])\")\n",
    "print(\"‚úÖ Blur: Image softened (averaging neighbors)\")\n",
    "print(\"‚úÖ Sharpen: Enhanced edges and details\")\n",
    "print(\"‚úÖ Edge kernels: Detect edges in specific directions\")\n",
    "print(\"‚úÖ Sobel: Strong edge detection (weighted)\")\n",
    "print(\"‚úÖ Emboss: Creates 3D-like effect\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 4: Visualize Multiple Feature Maps\n",
    "\n",
    "**In CNNs:** Each convolutional layer has **multiple kernels** (filters).  \n",
    "**Result:** Multiple feature maps showing different patterns!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select a dress image\n",
    "dress_img = x_train[3].astype('float32')\n",
    "\n",
    "# Multiple kernels (simulating first conv layer)\n",
    "feature_kernels = {\n",
    "    'Vertical Edges': np.array([[-1, 0, 1],\n",
    "                                [-2, 0, 2],\n",
    "                                [-1, 0, 1]]),\n",
    "    \n",
    "    'Horizontal Edges': np.array([[-1, -2, -1],\n",
    "                                  [0, 0, 0],\n",
    "                                  [1, 2, 1]]),\n",
    "    \n",
    "    'Diagonal \\\\': np.array([[0, 1, 2],\n",
    "                             [-1, 0, 1],\n",
    "                             [-2, -1, 0]]),\n",
    "    \n",
    "    'Diagonal /': np.array([[2, 1, 0],\n",
    "                            [1, 0, -1],\n",
    "                            [0, -1, -2]]),\n",
    "    \n",
    "    'Corner': np.array([[1, -2, 1],\n",
    "                        [-2, 4, -2],\n",
    "                        [1, -2, 1]]),\n",
    "    \n",
    "    'High-pass': np.array([[-1, -1, -1],\n",
    "                           [-1, 8, -1],\n",
    "                           [-1, -1, -1]])\n",
    "}\n",
    "\n",
    "# Apply all kernels\n",
    "fig, axes = plt.subplots(2, 4, figsize=(16, 8))\n",
    "\n",
    "# Original\n",
    "axes[0, 0].imshow(dress_img, cmap='gray')\n",
    "axes[0, 0].set_title('Original Image\\n(Dress)', fontsize=13, fontweight='bold')\n",
    "axes[0, 0].axis('off')\n",
    "\n",
    "# Show kernel\n",
    "axes[0, 1].axis('off')\n",
    "axes[0, 1].text(0.5, 0.5, 'Feature Maps ‚Üí\\n\\n6 different filters\\ndetect 6 patterns',\n",
    "               ha='center', va='center', fontsize=14, fontweight='bold',\n",
    "               bbox=dict(boxstyle='round', facecolor='lightblue', alpha=0.7))\n",
    "\n",
    "# Empty cells\n",
    "axes[0, 2].axis('off')\n",
    "axes[0, 3].axis('off')\n",
    "\n",
    "# Apply kernels\n",
    "for idx, (name, kernel) in enumerate(feature_kernels.items()):\n",
    "    if idx < 2:\n",
    "        row, col = 1, idx\n",
    "    else:\n",
    "        row, col = 1, idx\n",
    "    \n",
    "    output = conv2d_simple(dress_img, kernel)\n",
    "    axes[row, col].imshow(output, cmap='RdBu_r')\n",
    "    axes[row, col].set_title(f'Filter {idx+1}: {name}', fontsize=11, fontweight='bold')\n",
    "    axes[row, col].axis('off')\n",
    "\n",
    "plt.suptitle('Multiple Feature Maps (Like CNN First Layer)', fontsize=16, fontweight='bold')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nüß† CNN Insight:\")\n",
    "print(\"In a CNN, the first convolutional layer might have 32 or 64 filters.\")\n",
    "print(\"Each filter learns to detect different patterns automatically!\")\n",
    "print(\"We don't design these filters - the network learns them during training.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 5: Effect of Kernel Size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Same image\n",
    "img = x_train[0].astype('float32')\n",
    "\n",
    "# Different kernel sizes (all blur/average)\n",
    "kernel_3x3 = np.ones((3, 3)) / 9\n",
    "kernel_5x5 = np.ones((5, 5)) / 25\n",
    "kernel_7x7 = np.ones((7, 7)) / 49\n",
    "kernel_11x11 = np.ones((11, 11)) / 121\n",
    "\n",
    "# Apply\n",
    "output_3 = conv2d_simple(img, kernel_3x3)\n",
    "output_5 = conv2d_simple(img, kernel_5x5)\n",
    "output_7 = conv2d_simple(img, kernel_7x7)\n",
    "output_11 = conv2d_simple(img, kernel_11x11)\n",
    "\n",
    "# Visualize\n",
    "fig, axes = plt.subplots(1, 5, figsize=(18, 4))\n",
    "\n",
    "axes[0].imshow(img, cmap='gray')\n",
    "axes[0].set_title('Original\\n28√ó28', fontsize=12, fontweight='bold')\n",
    "axes[0].axis('off')\n",
    "\n",
    "axes[1].imshow(output_3, cmap='gray')\n",
    "axes[1].set_title(f'3√ó3 Kernel\\nOutput: {output_3.shape}', fontsize=12, fontweight='bold')\n",
    "axes[1].axis('off')\n",
    "\n",
    "axes[2].imshow(output_5, cmap='gray')\n",
    "axes[2].set_title(f'5√ó5 Kernel\\nOutput: {output_5.shape}', fontsize=12, fontweight='bold')\n",
    "axes[2].axis('off')\n",
    "\n",
    "axes[3].imshow(output_7, cmap='gray')\n",
    "axes[3].set_title(f'7√ó7 Kernel\\nOutput: {output_7.shape}', fontsize=12, fontweight='bold')\n",
    "axes[3].axis('off')\n",
    "\n",
    "axes[4].imshow(output_11, cmap='gray')\n",
    "axes[4].set_title(f'11√ó11 Kernel\\nOutput: {output_11.shape}', fontsize=12, fontweight='bold')\n",
    "axes[4].axis('off')\n",
    "\n",
    "plt.suptitle('Effect of Kernel Size on Output', fontsize=16, fontweight='bold')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nüìê Output Size Formula (2D):\")\n",
    "print(f\"Output_H = (Input_H - Kernel_H) + 1\")\n",
    "print(f\"Output_W = (Input_W - Kernel_W) + 1\")\n",
    "print(f\"\\n3√ó3: ({img.shape[0]}, {img.shape[1]}) ‚Üí {output_3.shape}\")\n",
    "print(f\"5√ó5: ({img.shape[0]}, {img.shape[1]}) ‚Üí {output_5.shape}\")\n",
    "print(f\"7√ó7: ({img.shape[0]}, {img.shape[1]}) ‚Üí {output_7.shape}\")\n",
    "print(f\"11√ó11: ({img.shape[0]}, {img.shape[1]}) ‚Üí {output_11.shape}\")\n",
    "print(\"\\nüí° Larger kernel = More blur + Smaller output\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 6: Stride and Padding Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Small test image\n",
    "test_img = x_train[2][:14, :14].astype('float32')  # Crop to 14x14\n",
    "\n",
    "# Simple edge kernel\n",
    "edge_kernel = np.array([[-1, 0, 1],\n",
    "                        [-1, 0, 1],\n",
    "                        [-1, 0, 1]])\n",
    "\n",
    "# Different stride values\n",
    "output_s1 = conv2d_simple(test_img, edge_kernel, stride=1, padding=0)\n",
    "output_s2 = conv2d_simple(test_img, edge_kernel, stride=2, padding=0)\n",
    "\n",
    "# Different padding values\n",
    "output_p0 = conv2d_simple(test_img, edge_kernel, stride=1, padding=0)\n",
    "output_p1 = conv2d_simple(test_img, edge_kernel, stride=1, padding=1)\n",
    "output_p2 = conv2d_simple(test_img, edge_kernel, stride=1, padding=2)\n",
    "\n",
    "# Visualize stride\n",
    "fig, axes = plt.subplots(1, 3, figsize=(15, 5))\n",
    "\n",
    "axes[0].imshow(test_img, cmap='gray')\n",
    "axes[0].set_title(f'Original\\n{test_img.shape}', fontsize=13, fontweight='bold')\n",
    "axes[0].axis('off')\n",
    "\n",
    "axes[1].imshow(output_s1, cmap='RdBu_r')\n",
    "axes[1].set_title(f'Stride=1\\nOutput: {output_s1.shape}', fontsize=13, fontweight='bold')\n",
    "axes[1].axis('off')\n",
    "\n",
    "axes[2].imshow(output_s2, cmap='RdBu_r')\n",
    "axes[2].set_title(f'Stride=2\\nOutput: {output_s2.shape}', fontsize=13, fontweight='bold')\n",
    "axes[2].axis('off')\n",
    "\n",
    "plt.suptitle('Effect of Stride (Downsampling)', fontsize=16, fontweight='bold')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Visualize padding\n",
    "fig, axes = plt.subplots(1, 4, figsize=(16, 4))\n",
    "\n",
    "axes[0].imshow(test_img, cmap='gray')\n",
    "axes[0].set_title(f'Original\\n{test_img.shape}', fontsize=12, fontweight='bold')\n",
    "axes[0].axis('off')\n",
    "\n",
    "axes[1].imshow(output_p0, cmap='RdBu_r')\n",
    "axes[1].set_title(f'Padding=0\\n{output_p0.shape}', fontsize=12, fontweight='bold')\n",
    "axes[1].axis('off')\n",
    "\n",
    "axes[2].imshow(output_p1, cmap='RdBu_r')\n",
    "axes[2].set_title(f'Padding=1\\n{output_p1.shape}', fontsize=12, fontweight='bold')\n",
    "axes[2].axis('off')\n",
    "\n",
    "axes[3].imshow(output_p2, cmap='RdBu_r')\n",
    "axes[3].set_title(f'Padding=2\\n{output_p2.shape}', fontsize=12, fontweight='bold')\n",
    "axes[3].axis('off')\n",
    "\n",
    "plt.suptitle('Effect of Padding (Size Control)', fontsize=16, fontweight='bold')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nüìä Complete Formula:\")\n",
    "print(\"Output = (Input + 2*Padding - Kernel) / Stride + 1\")\n",
    "print(f\"\\nStride=1, Pad=0: ({test_img.shape[0]} + 0 - 3) / 1 + 1 = {output_p0.shape[0]}\")\n",
    "print(f\"Stride=1, Pad=1: ({test_img.shape[0]} + 2 - 3) / 1 + 1 = {output_p1.shape[0]} ‚Üê Same as input!\")\n",
    "print(f\"Stride=2, Pad=0: ({test_img.shape[0]} + 0 - 3) / 2 + 1 = {output_s2.shape[0]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 7: Interactive Experiment üß™"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR TURN! Create your own kernel\n",
    "\n",
    "# 1. Select an image (0-9)\n",
    "my_image_idx = 5  # ‚Üê Change this!\n",
    "my_image = x_train[my_image_idx].astype('float32')\n",
    "\n",
    "# 2. Create your custom 3x3 kernel\n",
    "my_kernel = np.array([[-1, -1, -1],\n",
    "                      [ 0,  0,  0],\n",
    "                      [ 1,  1,  1]])  # ‚Üê Change these values!\n",
    "\n",
    "# 3. Set parameters\n",
    "my_stride = 1   # ‚Üê Change this!\n",
    "my_padding = 0  # ‚Üê Change this!\n",
    "\n",
    "# Apply convolution\n",
    "my_output = conv2d_simple(my_image, my_kernel, stride=my_stride, padding=my_padding)\n",
    "\n",
    "# Visualize\n",
    "fig, axes = plt.subplots(1, 3, figsize=(15, 5))\n",
    "\n",
    "# Original\n",
    "axes[0].imshow(my_image, cmap='gray')\n",
    "axes[0].set_title(f'Your Image\\n{class_names[y_train[my_image_idx]]}\\n{my_image.shape}',\n",
    "                 fontsize=13, fontweight='bold')\n",
    "axes[0].axis('off')\n",
    "\n",
    "# Kernel visualization\n",
    "axes[1].imshow(my_kernel, cmap='RdBu_r', vmin=-2, vmax=2)\n",
    "axes[1].set_title('Your Kernel', fontsize=13, fontweight='bold')\n",
    "for i in range(3):\n",
    "    for j in range(3):\n",
    "        axes[1].text(j, i, f'{my_kernel[i,j]:.1f}',\n",
    "                    ha='center', va='center', fontsize=14, fontweight='bold')\n",
    "axes[1].set_xticks([])\n",
    "axes[1].set_yticks([])\n",
    "\n",
    "# Output\n",
    "axes[2].imshow(my_output, cmap='RdBu_r')\n",
    "axes[2].set_title(f'Your Output\\n{my_output.shape}', fontsize=13, fontweight='bold')\n",
    "axes[2].axis('off')\n",
    "\n",
    "plt.suptitle(f'Your Experiment (Stride={my_stride}, Padding={my_padding})', fontsize=16, fontweight='bold')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"\\nüìä Your Results:\")\n",
    "print(f\"Image: {class_names[y_train[my_image_idx]]}\")\n",
    "print(f\"Input shape: {my_image.shape}\")\n",
    "print(f\"Kernel size: {my_kernel.shape}\")\n",
    "print(f\"Stride: {my_stride}\")\n",
    "print(f\"Padding: {my_padding}\")\n",
    "print(f\"Output shape: {my_output.shape}\")\n",
    "print(f\"\\nFormula: ({my_image.shape[0]} + 2*{my_padding} - {my_kernel.shape[0]}) / {my_stride} + 1 = {my_output.shape[0]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Summary: Key Takeaways üéØ\n",
    "\n",
    "### What You Learned:\n",
    "\n",
    "1. **‚úÖ 2D convolution = sliding 2D kernel** over an image\n",
    "2. **‚úÖ Different kernels detect different patterns:**\n",
    "   - Blur kernels ‚Üí smooth images\n",
    "   - Edge kernels ‚Üí find boundaries\n",
    "   - Sharpen kernels ‚Üí enhance details\n",
    "\n",
    "3. **‚úÖ Multiple kernels = Multiple feature maps** (like CNN first layer)\n",
    "\n",
    "4. **‚úÖ Kernel size affects:**\n",
    "   - Receptive field (how much input affects one output)\n",
    "   - Output size (bigger kernel = smaller output)\n",
    "   - Computation (bigger = slower)\n",
    "\n",
    "5. **‚úÖ Stride controls downsampling**\n",
    "\n",
    "6. **‚úÖ Padding preserves spatial dimensions**\n",
    "\n",
    "7. **‚úÖ Output size formula (2D):**\n",
    "   ```\n",
    "   Output_H = (Input_H + 2*Padding - Kernel_H) / Stride + 1\n",
    "   Output_W = (Input_W + 2*Padding - Kernel_W) / Stride + 1\n",
    "   ```\n",
    "\n",
    "### CNN Connection:\n",
    "\n",
    "- In CNNs, we **don't design kernels** manually\n",
    "- The network **learns optimal kernels** during training\n",
    "- First layers learn simple patterns (edges)\n",
    "- Deeper layers learn complex patterns (shapes, objects)\n",
    "\n",
    "---\n",
    "\n",
    "## Practice Exercises üìù\n",
    "\n",
    "**Before Notebook 3:**\n",
    "\n",
    "1. Create a kernel that detects horizontal lines. Test on different Fashion-MNIST items.\n",
    "\n",
    "2. Apply 3 different kernels to the same image. Which one best highlights the object shape?\n",
    "\n",
    "3. Calculate: Input = 28√ó28, Kernel = 5√ó5, Stride = 2, Padding = 2. What's the output size?\n",
    "\n",
    "4. Challenge: Can you design a kernel that detects corners (intersection of edges)?\n",
    "\n",
    "---\n",
    "\n",
    "## Next: Notebook 3 - Building Your First CNN! üß†\n",
    "\n",
    "**You're ready!** Now we'll build a complete CNN using TensorFlow/Keras on Fashion-MNIST.\n",
    "\n",
    "---\n",
    "\n",
    "*‚è±Ô∏è Time spent: ~30 minutes*  \n",
    "*üí™ Difficulty: Beginner-Intermediate*  \n",
    "*üéì Mastery: 2D convolution & visualization*"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
