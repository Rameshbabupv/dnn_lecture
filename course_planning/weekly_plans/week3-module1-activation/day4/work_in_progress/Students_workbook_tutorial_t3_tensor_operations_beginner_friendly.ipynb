{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ğŸ“– Students Workbook: Understanding Neural Networks & Tensors\n",
    "## Week 3, Day 4 - Interactive Learning Session\n",
    "\n",
    "**ğŸ‘‹ Welcome to Your Interactive Learning Journey!**\n",
    "\n",
    "This workbook is designed for **live instruction** - your instructor will demonstrate each concept step-by-step, and you'll follow along by executing the code together.\n",
    "\n",
    "---\n",
    "\n",
    "## ğŸ“‹ Student Information\n",
    "**Please fill in your details:**\n",
    "\n",
    "| Field | Your Information |\n",
    "|-------|------------------|\n",
    "| **Student Name** | _________________________________ |\n",
    "| **Registration Number** | _________________________________ |\n",
    "| **Branch & Year** | _________________________________ |\n",
    "| **Date** | _________________________________ |\n",
    "\n",
    "---\n",
    "\n",
    "### ğŸ¯ Today's Learning Journey\n",
    "By the end of this session, you will understand:\n",
    "1. ğŸ”Œ **Activation Functions**: How neural \"switches\" work (like electronic circuits)\n",
    "2. ğŸ“ **Tensors**: Multi-dimensional data (like matrices you know)\n",
    "3. ğŸ§  **Neural Layers**: How information is processed and transformed\n",
    "4. ğŸ—ï¸ **Networks**: How layers connect to solve problems\n",
    "\n",
    "### ğŸ’¡ Learning Strategy for Today:\n",
    "- **Listen & Understand** â†’ **Watch Demonstration** â†’ **Execute Together** â†’ **Discuss Results**\n",
    "- Ask questions anytime!\n",
    "- Take notes in the provided spaces\n",
    "- Participate in discussions\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ› ï¸ Setup: Loading Our Tools\n",
    "\n",
    "First, we need to import the mathematical tools we'll use today. Think of this like opening your toolbox before starting a project.\n",
    "\n",
    "**What we're importing:**\n",
    "- `numpy`: For numerical computations (like MATLAB)\n",
    "- `matplotlib`: For creating plots and visualizations \n",
    "- `tensorflow`: For neural network operations\n",
    "\n",
    "**ğŸ¯ Watch as your instructor demonstrates:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your instructor will demonstrate importing libraries and setup here\n",
    "# Execute this cell when instructed\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### âœï¸ Your Notes:\n",
    "**Write down what each library does:**\n",
    "- numpy: ________________________________\n",
    "- matplotlib: ____________________________\n",
    "- tensorflow: ____________________________\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 1: Understanding Activation Functions ğŸ”Œ\n",
    "\n",
    "## ğŸ¤” What Are Activation Functions?\n",
    "\n",
    "Think of activation functions as **smart switches** that decide how much signal to let through:\n",
    "\n",
    "### ğŸ”§ **For ECE Students:**\n",
    "- Like **op-amps** with different characteristics\n",
    "- Like **diodes** that control current flow\n",
    "- Like **filters** that shape signal response\n",
    "\n",
    "### âš™ï¸ **For Mechanical Students:**\n",
    "- Like **control valves** that regulate flow\n",
    "- Like **pressure relief valves** with different opening characteristics\n",
    "- Like **dampers** with non-linear response\n",
    "\n",
    "### ğŸ¯ **Key Point:**\n",
    "Without activation functions, neural networks would just be linear equations (boring!). Activation functions add **non-linearity**, making networks capable of learning complex patterns.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ“ˆ The Sigmoid Function: A Soft Switch\n",
    "\n",
    "### ğŸ“š **Mathematical Formula:** \n",
    "Ïƒ(x) = 1/(1+e^(-x))\n",
    "\n",
    "### ğŸ” **Properties:**\n",
    "- **Input:** Any real number (-âˆ to +âˆ)\n",
    "- **Output:** Always between 0 and 1 (like a probability)\n",
    "- **Shape:** Smooth S-curve\n",
    "- **Behavior:**\n",
    "  - Large negative x â†’ output â‰ˆ 0 (switch OFF)\n",
    "  - x = 0 â†’ output = 0.5 (halfway)\n",
    "  - Large positive x â†’ output â‰ˆ 1 (switch ON)\n",
    "\n",
    "### ğŸ’­ **Discussion Point:**\n",
    "*Before we code this, what do you think the graph will look like? Draw a quick sketch below:*\n",
    "\n",
    "```\n",
    "Your sketch space:\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "```\n",
    "\n",
    "### ğŸ¯ **Your instructor will now demonstrate implementing the sigmoid function:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sigmoid function implementation will be demonstrated here\n",
    "# Follow along as your instructor codes this step-by-step\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ğŸ§ª Testing the Sigmoid Function\n",
    "\n",
    "Now let's test our sigmoid function with different input values to see how it behaves.\n",
    "\n",
    "**ğŸ¤” Prediction Exercise:** Before running the code, predict what the outputs will be:\n",
    "- sigmoid(-5) â‰ˆ ______\n",
    "- sigmoid(0) = ______\n",
    "- sigmoid(5) â‰ˆ ______\n",
    "\n",
    "**ğŸ¯ Watch as your instructor demonstrates testing:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing sigmoid function with various inputs\n",
    "# Your instructor will demonstrate this\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ğŸ“Š Visualizing the Sigmoid Function\n",
    "\n",
    "A picture is worth a thousand words! Let's plot the sigmoid function to see its S-shaped curve.\n",
    "\n",
    "**ğŸ¯ Your instructor will demonstrate creating the visualization:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sigmoid function visualization\n",
    "# Watch as your instructor creates the plot\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### âœï¸ Your Observations:\n",
    "**After seeing the sigmoid plot, write down:**\n",
    "1. What shape does the sigmoid function have? ________________________\n",
    "2. What happens at very large positive values? ________________________\n",
    "3. What happens at very large negative values? ________________________\n",
    "4. Where is the steepest part of the curve? ________________________\n",
    "\n",
    "### ğŸ’¡ **Key Insight:**\n",
    "The sigmoid function \"squashes\" any input to between 0 and 1, making it useful for probability-like outputs!\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## âš¡ The ReLU Function: A One-Way Valve\n",
    "\n",
    "### ğŸ“š **Mathematical Formula:** \n",
    "f(x) = max(0, x)\n",
    "\n",
    "### ğŸ” **Properties:**\n",
    "- **Input:** Any real number\n",
    "- **Output:** 0 for negative inputs, x for positive inputs\n",
    "- **Shape:** Like a hockey stick or ramp\n",
    "- **Behavior:**\n",
    "  - Negative x â†’ output = 0 (valve closed/diode off)\n",
    "  - Positive x â†’ output = x (valve open/diode on)\n",
    "\n",
    "### ğŸ”§ **Engineering Analogies:**\n",
    "- **ECE:** Perfect diode that blocks negative voltages\n",
    "- **Mechanical:** Check valve allowing flow in one direction only\n",
    "\n",
    "### ğŸ’­ **Discussion Point:**\n",
    "*How do you think this will look different from sigmoid?*\n",
    "\n",
    "### ğŸ¯ **Your instructor will demonstrate implementing ReLU:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ReLU function implementation\n",
    "# Follow along with your instructor\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ğŸ§ª Testing the ReLU Function\n",
    "\n",
    "**ğŸ¤” Prediction Exercise:** Before running, predict the outputs:\n",
    "- ReLU(-3) = ______\n",
    "- ReLU(0) = ______\n",
    "- ReLU(5) = ______\n",
    "\n",
    "**ğŸ¯ Watch the demonstration:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing ReLU function\n",
    "# Your instructor will demonstrate\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ğŸ“Š Comparing Sigmoid vs ReLU\n",
    "\n",
    "Let's visualize both functions side by side to understand their differences.\n",
    "\n",
    "**ğŸ¯ Watch as your instructor creates the comparison:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sigmoid vs ReLU comparison visualization\n",
    "# Your instructor will demonstrate this comparison\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### âœï¸ Your Comparison Notes:\n",
    "**Fill in the differences:**\n",
    "\n",
    "| Aspect | Sigmoid | ReLU |\n",
    "|--------|---------|------|\n",
    "| **Shape** | _____________ | _____________ |\n",
    "| **Output Range** | _____________ | _____________ |\n",
    "| **Negative Inputs** | _____________ | _____________ |\n",
    "| **Positive Inputs** | _____________ | _____________ |\n",
    "| **Smoothness** | _____________ | _____________ |\n",
    "\n",
    "### ğŸ¤” **Checkpoint Question:**\n",
    "*Which activation function would you choose for a switch-like behavior? Why?*\n",
    "\n",
    "**Your answer:** _________________________________\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ“ˆ Understanding Gradients (Derivatives)\n",
    "\n",
    "### ğŸ¤” **Why Do We Care About Gradients?**\n",
    "\n",
    "In neural networks, gradients tell us **\"how to adjust weights to improve performance.\"**\n",
    "\n",
    "### ğŸ”§ **Engineering Analogies:**\n",
    "- **ECE:** Like finding the slope of a transfer function to optimize circuit response\n",
    "- **Mechanical:** Like finding the rate of change in a control system to adjust parameters\n",
    "\n",
    "### âš ï¸ **The Gradient Problem:**\n",
    "Some activation functions have gradients that become:\n",
    "- **Very small** (vanishing gradient problem) â†’ slow learning\n",
    "- **Very large** (exploding gradient problem) â†’ unstable learning\n",
    "\n",
    "### ğŸ’¡ **Key Concept:**\n",
    "- **Large gradients** = fast learning\n",
    "- **Small gradients** = slow learning\n",
    "- **Zero gradients** = no learning (dead neurons)\n",
    "\n",
    "### ğŸ¯ **Your instructor will demonstrate gradient functions:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gradient function implementations\n",
    "# Your instructor will show you how to compute derivatives\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ğŸ“Š Visualizing the Vanishing Gradient Problem\n",
    "\n",
    "Let's see why ReLU is so popular - it doesn't suffer from vanishing gradients!\n",
    "\n",
    "**ğŸ¯ Watch the demonstration:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gradient visualization and comparison\n",
    "# Your instructor will show the vanishing gradient problem\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### âœï¸ Your Gradient Insights:\n",
    "**After seeing the gradient plots:**\n",
    "1. What happens to sigmoid gradients for large |x|? _____________________\n",
    "2. What is the maximum sigmoid gradient value? _____________________\n",
    "3. What is the ReLU gradient for positive x? _____________________\n",
    "4. Why is this important for learning? _____________________\n",
    "\n",
    "### ğŸ’¡ **Key Insight:**\n",
    "This is why ReLU is the most popular activation function - it maintains strong gradients for positive values!\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 2: Gentle Introduction to Tensors ğŸ“\n",
    "\n",
    "## ğŸ¤” What Are Tensors?\n",
    "\n",
    "**Don't let the fancy name scare you!** Tensors are just **multi-dimensional arrays** - like the matrices you already know, but they can have more dimensions.\n",
    "\n",
    "### ğŸ“š **You Already Know These:**\n",
    "- **Scalar (0D tensor):** Just a single number â†’ `5`\n",
    "- **Vector (1D tensor):** A list of numbers â†’ `[1, 2, 3]`  \n",
    "- **Matrix (2D tensor):** A rectangular array â†’ `[[1, 2], [3, 4]]`\n",
    "- **3D Tensor:** Like a stack of matrices â†’ think RGB color image\n",
    "\n",
    "### ğŸ”§ **Engineering Applications:**\n",
    "- **ECE:** Multi-dimensional signals (time, frequency, spatial)\n",
    "- **Mechanical:** Stress tensors, multi-parameter system states\n",
    "- **General:** Any data with multiple dimensions\n",
    "\n",
    "### ğŸ’­ **Discussion Point:**\n",
    "*Can you think of data in your field that has multiple dimensions?*\n",
    "\n",
    "**Your examples:** _________________________________\n",
    "\n",
    "### ğŸ¯ **Your instructor will demonstrate creating different tensor types:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating different types of tensors\n",
    "# Your instructor will show scalar, vector, matrix, and 3D tensor\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### âœï¸ Tensor Understanding:\n",
    "**Fill in what each tensor type represents:**\n",
    "\n",
    "| Tensor Type | Dimensions | Example Shape | Real-world Example |\n",
    "|-------------|------------|---------------|--------------------|\n",
    "| **Scalar** | 0D | () | _________________ |\n",
    "| **Vector** | 1D | (n,) | _________________ |\n",
    "| **Matrix** | 2D | (m,n) | _________________ |\n",
    "| **3D Tensor** | 3D | (x,y,z) | _________________ |\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ”„ Basic Tensor Operations\n",
    "\n",
    "Let's do some operations you'll recognize from linear algebra!\n",
    "\n",
    "### ğŸ“š **Matrix Multiplication Review:**\n",
    "Remember from your linear algebra class:\n",
    "- **Element-wise multiplication:** A âŠ™ B (like MATLAB `.*`)\n",
    "- **Matrix multiplication:** A Ã— B (like MATLAB `*`)\n",
    "\n",
    "### ğŸ’­ **Quick Review:**\n",
    "*For matrix multiplication AÃ—B, what must be true about the dimensions?*\n",
    "\n",
    "**Your answer:** _________________________________\n",
    "\n",
    "### ğŸ¯ **Your instructor will demonstrate matrix operations:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Matrix operations demonstration\n",
    "# Your instructor will show element-wise and matrix multiplication\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ğŸ“ Shape Manipulation\n",
    "\n",
    "Just like in MATLAB, we can reshape tensors while keeping the same number of elements.\n",
    "\n",
    "### ğŸ’¡ **Key Rule:**\n",
    "The **total number of elements must stay the same** when reshaping!\n",
    "\n",
    "### ğŸ¯ **Watch as your instructor demonstrates reshaping:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shape manipulation demonstration\n",
    "# Your instructor will show reshape, transpose, and flatten operations\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### âœï¸ Shape Manipulation Notes:\n",
    "**Fill in what each operation does:**\n",
    "\n",
    "| Operation | What it does | Example |\n",
    "|-----------|--------------|----------|\n",
    "| **Reshape** | _________________ | (2,3) â†’ (3,2) |\n",
    "| **Transpose** | _________________ | (2,3) â†’ (3,2) |\n",
    "| **Flatten** | _________________ | (2,3) â†’ (6,) |\n",
    "\n",
    "### ğŸ¤” **Checkpoint Question:**\n",
    "*What's the difference between reshape and transpose?*\n",
    "\n",
    "**Your answer:** _________________________________\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 3: Building a Simple Neural Layer ğŸ§ \n",
    "\n",
    "## ğŸ¤” What Is a Neural Layer?\n",
    "\n",
    "A neural layer is like a **transformation box** that processes information:\n",
    "\n",
    "### ğŸ”„ **The Process:**\n",
    "1. **Takes inputs** (numbers)\n",
    "2. **Multiplies by weights** (learned parameters)\n",
    "3. **Adds biases** (shifts/offsets)\n",
    "4. **Applies activation function** (adds non-linearity)\n",
    "\n",
    "### ğŸ“š **Mathematical Formula:** \n",
    "```\n",
    "output = activation(input Ã— weights + bias)\n",
    "```\n",
    "\n",
    "### ğŸ”§ **Engineering Analogies:**\n",
    "- **ECE:** Like an op-amp circuit with adjustable gain (weights) and offset (bias)\n",
    "- **Mechanical:** Like a control system with gain and reference point adjustment\n",
    "\n",
    "### ğŸ’­ **Discussion Point:**\n",
    "*In your field, what systems take inputs, apply some transformation, and produce outputs?*\n",
    "\n",
    "**Your examples:** _________________________________\n",
    "\n",
    "### ğŸ¯ **Your instructor will demonstrate building a neural layer step-by-step:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Building a simple neural layer step-by-step\n",
    "# Your instructor will show parameter initialization and forward pass\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### âœï¸ Neural Layer Understanding:\n",
    "**Fill in the components:**\n",
    "\n",
    "| Component | What it does | Size for 3â†’2 layer |\n",
    "|-----------|--------------|---------------------|\n",
    "| **Weights** | _________________ | _________________ |\n",
    "| **Bias** | _________________ | _________________ |\n",
    "| **Activation** | _________________ | _________________ |\n",
    "\n",
    "### ğŸ§ª Testing Our Layer\n",
    "\n",
    "Let's test our layer with different inputs to see how it transforms data.\n",
    "\n",
    "**ğŸ¤” Prediction Exercise:** What do you think will happen with these inputs?\n",
    "- All zeros: [0, 0, 0] â†’ ?\n",
    "- All ones: [1, 1, 1] â†’ ?\n",
    "- Mixed: [1, -1, 0.5] â†’ ?\n",
    "\n",
    "### ğŸ¯ **Watch the testing demonstration:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing the neural layer with different inputs\n",
    "# Your instructor will demonstrate various test cases\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ğŸ“Š Visualizing Layer Behavior\n",
    "\n",
    "Let's create a plot to see how our layer responds to different inputs.\n",
    "\n",
    "### ğŸ¯ **Watch the visualization demonstration:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualizing neural layer behavior\n",
    "# Your instructor will show input-output relationships\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### âœï¸ Layer Behavior Observations:\n",
    "**After seeing the visualization:**\n",
    "1. What happens without activation function? _____________________\n",
    "2. How does ReLU change the behavior? _____________________\n",
    "3. Why is non-linearity important? _____________________\n",
    "\n",
    "### ğŸ’¡ **Key Insight:**\n",
    "The non-linearity from activation functions is what gives neural networks their power to learn complex patterns!\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 4: Building a Simple Network ğŸ—ï¸\n",
    "\n",
    "## ğŸ¤” What Is a Neural Network?\n",
    "\n",
    "A neural network is simply **multiple layers connected together**:\n",
    "\n",
    "### ğŸ”— **The Connection:**\n",
    "- Output of Layer 1 â†’ Input of Layer 2\n",
    "- Output of Layer 2 â†’ Input of Layer 3\n",
    "- And so on...\n",
    "\n",
    "### ğŸ”§ **Engineering Analogies:**\n",
    "- **ECE:** Like a **multi-stage amplifier** or **signal processing pipeline**\n",
    "- **Mechanical:** Like a **multi-stage control system** with cascaded controllers\n",
    "\n",
    "### ğŸ“ **Our Network Architecture:**\n",
    "```\n",
    "Input (3) â†’ Hidden Layer (4) â†’ Output (2)\n",
    "```\n",
    "\n",
    "### ğŸ’­ **Discussion Point:**\n",
    "*Why might we want multiple layers instead of just one big layer?*\n",
    "\n",
    "**Your thoughts:** _________________________________\n",
    "\n",
    "### ğŸ¯ **Your instructor will demonstrate building a 2-layer network:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Building a 2-layer neural network\n",
    "# Your instructor will show layer connection and forward pass\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### âœï¸ Network Architecture Notes:\n",
    "**Fill in the network details:**\n",
    "\n",
    "| Layer | Input Size | Output Size | Activation | Purpose |\n",
    "|-------|------------|-------------|------------|----------|\n",
    "| **Layer 1** | _____ | _____ | _____ | _________________ |\n",
    "| **Layer 2** | _____ | _____ | _____ | _________________ |\n",
    "\n",
    "### ğŸ§ª Testing Our Complete Network\n",
    "\n",
    "Let's test our 2-layer network with various inputs to see how it transforms data through multiple stages.\n",
    "\n",
    "**ğŸ¤” Prediction Exercise:** How do you think the network will behave differently than a single layer?\n",
    "\n",
    "**Your prediction:** _________________________________\n",
    "\n",
    "### ğŸ¯ **Watch the network testing:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing the complete 2-layer network\n",
    "# Your instructor will demonstrate various test cases\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### âœï¸ Network Testing Observations:\n",
    "**Record your observations:**\n",
    "1. How do the outputs differ from single layer? _____________________\n",
    "2. What patterns do you notice? _____________________\n",
    "3. How does the hidden layer help? _____________________\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ğŸ¯ Understanding Check & Discussion\n",
    "\n",
    "## ğŸ’­ **Class Discussion Points:**\n",
    "\n",
    "### **Question 1:** *What does ReLU do?*\n",
    "**Class discussion notes:** _________________________________\n",
    "\n",
    "### **Question 2:** *What does Sigmoid do?*\n",
    "**Class discussion notes:** _________________________________\n",
    "\n",
    "### **Question 3:** *What's a neural layer?*\n",
    "**Class discussion notes:** _________________________________\n",
    "\n",
    "### **Question 4:** *What's a neural network?*\n",
    "**Class discussion notes:** _________________________________\n",
    "\n",
    "### **Question 5:** *Why do we need activation functions?*\n",
    "**Class discussion notes:** _________________________________\n",
    "\n",
    "## ğŸ§ª **Final Practical Test**\n",
    "\n",
    "Let's test our understanding with a final demonstration.\n",
    "\n",
    "### ğŸ¯ **Your instructor will demonstrate:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Final understanding check\n",
    "# Your instructor will run a comprehensive test of all concepts\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### âœï¸ Final Test Results:\n",
    "**Record what you observed:**\n",
    "- Network input: _________________________________\n",
    "- Network output: _________________________________\n",
    "- Your understanding: _________________________________\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ğŸŒŸ Session Summary & Reflection\n",
    "\n",
    "## âœ… **What We Accomplished Today:**\n",
    "\n",
    "### **Concepts Learned:**\n",
    "- [ ] **Activation Functions**: Understand sigmoid and ReLU as smart switches\n",
    "- [ ] **Tensors**: Work with multi-dimensional data (matrices and beyond)\n",
    "- [ ] **Neural Layers**: Build information processing units\n",
    "- [ ] **Networks**: Connect layers to solve complex problems\n",
    "\n",
    "### **Skills Developed:**\n",
    "- [ ] Implementing mathematical functions in Python\n",
    "- [ ] Creating visualizations to understand concepts\n",
    "- [ ] Manipulating tensor shapes and operations\n",
    "- [ ] Building and testing neural network components\n",
    "\n",
    "## ğŸ”— **Connection to Your Engineering Field:**\n",
    "\n",
    "### âœï¸ **Personal Reflection:**\n",
    "**Write how today's concepts connect to your field:**\n",
    "\n",
    "**For ECE Students:**\n",
    "- Activation functions are like: _________________________________\n",
    "- Neural layers are like: _________________________________\n",
    "- Networks are like: _________________________________\n",
    "\n",
    "**For Mechanical Students:**\n",
    "- Activation functions are like: _________________________________\n",
    "- Neural layers are like: _________________________________\n",
    "- Networks are like: _________________________________\n",
    "\n",
    "## ğŸš€ **Next Steps in Your Learning Journey:**\n",
    "\n",
    "### **Upcoming Topics:**\n",
    "1. **Module 2**: How networks learn (optimization algorithms)\n",
    "2. **Module 3**: Applying neural networks to images\n",
    "3. **Module 4**: Specialized networks for pattern recognition\n",
    "4. **Module 5**: Object detection and classification systems\n",
    "\n",
    "### **To Prepare for Next Class:**\n",
    "- [ ] Review today's concepts\n",
    "- [ ] Think about applications in your field\n",
    "- [ ] Practice with the concepts we learned\n",
    "- [ ] Come with questions about optimization\n",
    "\n",
    "## ğŸ’¡ **Key Takeaways:**\n",
    "\n",
    "### âœï¸ **Write your three most important insights:**\n",
    "1. _________________________________\n",
    "2. _________________________________\n",
    "3. _________________________________\n",
    "\n",
    "## ğŸ¤” **Questions for Next Time:**\n",
    "**Write any questions you want to explore:**\n",
    "- _________________________________\n",
    "- _________________________________\n",
    "- _________________________________\n",
    "\n",
    "---\n",
    "\n",
    "## ğŸŠ Congratulations!\n",
    "\n",
    "You've successfully completed your introduction to neural networks and tensor operations! \n",
    "\n",
    "**Remember:** Neural networks are not magic - they're engineered systems that can be understood, analyzed, and applied to solve real problems in your field.\n",
    "\n",
    "Keep this systematic, engineering approach as you continue learning. You're well-prepared for the more advanced topics ahead! ğŸš€\n",
    "\n",
    "### ğŸ“ **Instructor Notes Section:**\n",
    "```\n",
    "Space for instructor to add additional notes or assignments:\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python3",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
