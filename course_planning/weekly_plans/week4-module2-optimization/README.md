# Week 4 - Module 2: Optimization Techniques

## Overview

This week covers the mathematical foundations and practical implementation of optimization algorithms that make neural networks learn. Students will master gradient descent and its variants - the core engine behind all deep learning.

### Topics Covered

**Day 3 (Sep 5): Gradient Descent Theory**
- The optimization problem in neural networks
- Mathematical foundations of gradient descent
- Cost function landscapes and convergence
- Learning rate analysis and visualization

*CO Coverage:* CO-1 (neural network training), CO-2 (optimization understanding)  
*PO Mapping:* PO-1 Level 3 (engineering mathematics), PO-2 Level 2 (optimization analysis)

**Day 4 (Sep 8): Gradient Descent Variants**
- Batch Gradient Descent vs Stochastic Gradient Descent
- Mini-batch Gradient Descent implementation
- Performance comparison and trade-offs
- Hyperparameter tuning and best practices

*CO Coverage:* CO-1 (practical implementation), CO-2 (advanced training methods)  
*PO Mapping:* PO-1 Level 2 (applied mathematics), PO-2 Level 3 (algorithm analysis), PO-3 Level 2 (system optimization)

### Learning Outcomes
- Understand how neural networks optimize their parameters
- Implement all three gradient descent variants in Python
- Analyze convergence patterns and computational efficiency
- Select appropriate optimization methods for different scenarios

## Book References

### Primary References

**1. Goodfellow, Bengio & Courville - "Deep Learning" (MIT Press, 2017)**
- Chapter 4: Numerical Computation (pp. 78-98)
- Chapter 8: Optimization for Training Deep Models (pp. 265-310)

**2. Aggarwal - "Neural Networks and Deep Learning" (Springer, 2018)**
- Chapter 4: Optimization Methods (pp. 93-125)
- Chapter 1.4: Training Phase (pp. 15-22)

### Supplementary References

**3. Chollet - "Deep Learning with Python" (Manning, 2018)**
- Chapter 2.4: Training Loop (pp. 48-52)
- Chapter 4.4: Overfitting and Underfitting (pp. 108-116)

**4. Manaswi - "Deep Learning with Applications Using Python" (Apress, 2018)**
- Chapter 2: Fundamentals of Neural Networks (pp. 25-45)
- Chapter 3: Gradient-Based Learning (pp. 47-68)

### Key Concepts Bridge
- **Optimization Theory** → Goodfellow Ch. 4 & 8
- **Python Implementation** → Chollet Ch. 2 & Manaswi Ch. 2-3
- **Mathematical Depth** → Aggarwal Ch. 4