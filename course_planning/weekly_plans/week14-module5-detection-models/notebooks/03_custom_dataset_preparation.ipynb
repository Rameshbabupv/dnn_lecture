{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Custom Dataset Preparation for YOLO\n",
    "\n",
    "**Week 14 - Module 5: Object Detection Models**\n",
    "\n",
    "**Estimated Time:** 15 minutes\n",
    "\n",
    "## Learning Objectives\n",
    "- Understand YOLO dataset format\n",
    "- Prepare custom dataset for training\n",
    "- Create data.yaml configuration\n",
    "- Split data into train/val/test\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. YOLO Dataset Format\n",
    "\n",
    "YOLO uses a specific format for training data. Understanding this format is crucial for preparing your own datasets.\n",
    "\n",
    "### Image Files\n",
    "- Supported formats: `.jpg`, `.jpeg`, `.png`, `.bmp`\n",
    "- Any resolution (YOLO will resize)\n",
    "- Example: `image001.jpg`, `cat_001.png`\n",
    "\n",
    "### Label Files\n",
    "- Format: `.txt` (plain text)\n",
    "- **Same filename** as corresponding image\n",
    "- Example: `image001.txt` for `image001.jpg`\n",
    "\n",
    "### Label File Format\n",
    "\n",
    "Each line in the `.txt` file represents one bounding box:\n",
    "\n",
    "```\n",
    "class_id x_center y_center width height\n",
    "```\n",
    "\n",
    "Where:\n",
    "- `class_id`: Integer starting from 0 (e.g., 0=person, 1=car, 2=dog)\n",
    "- `x_center`: X-coordinate of box center (normalized 0-1)\n",
    "- `y_center`: Y-coordinate of box center (normalized 0-1)\n",
    "- `width`: Box width (normalized 0-1)\n",
    "- `height`: Box height (normalized 0-1)\n",
    "\n",
    "### Example Label File\n",
    "\n",
    "```txt\n",
    "0 0.5 0.5 0.3 0.4\n",
    "1 0.2 0.7 0.15 0.2\n",
    "0 0.8 0.3 0.25 0.35\n",
    "```\n",
    "\n",
    "This means:\n",
    "- **Line 1**: Class 0, center at (50%, 50%), size 30%√ó40% of image\n",
    "- **Line 2**: Class 1, center at (20%, 70%), size 15%√ó20% of image\n",
    "- **Line 3**: Class 0, center at (80%, 30%), size 25%√ó35% of image\n",
    "\n",
    "### Normalization Formula\n",
    "\n",
    "If you have pixel coordinates, convert to normalized:\n",
    "\n",
    "```python\n",
    "x_center = (x_min + x_max) / (2 * image_width)\n",
    "y_center = (y_min + y_max) / (2 * image_height)\n",
    "width = (x_max - x_min) / image_width\n",
    "height = (y_max - y_min) / image_height\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Dataset Directory Structure\n",
    "\n",
    "YOLO expects a specific directory structure:\n",
    "\n",
    "```\n",
    "my_dataset/\n",
    "‚îú‚îÄ‚îÄ images/\n",
    "‚îÇ   ‚îú‚îÄ‚îÄ train/\n",
    "‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ image001.jpg\n",
    "‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ image002.jpg\n",
    "‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ ...\n",
    "‚îÇ   ‚îú‚îÄ‚îÄ val/\n",
    "‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ image101.jpg\n",
    "‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ image102.jpg\n",
    "‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ ...\n",
    "‚îÇ   ‚îî‚îÄ‚îÄ test/\n",
    "‚îÇ       ‚îú‚îÄ‚îÄ image201.jpg\n",
    "‚îÇ       ‚îú‚îÄ‚îÄ image202.jpg\n",
    "‚îÇ       ‚îî‚îÄ‚îÄ ...\n",
    "‚îî‚îÄ‚îÄ labels/\n",
    "    ‚îú‚îÄ‚îÄ train/\n",
    "    ‚îÇ   ‚îú‚îÄ‚îÄ image001.txt\n",
    "    ‚îÇ   ‚îú‚îÄ‚îÄ image002.txt\n",
    "    ‚îÇ   ‚îî‚îÄ‚îÄ ...\n",
    "    ‚îú‚îÄ‚îÄ val/\n",
    "    ‚îÇ   ‚îú‚îÄ‚îÄ image101.txt\n",
    "    ‚îÇ   ‚îú‚îÄ‚îÄ image102.txt\n",
    "    ‚îÇ   ‚îî‚îÄ‚îÄ ...\n",
    "    ‚îî‚îÄ‚îÄ test/\n",
    "        ‚îú‚îÄ‚îÄ image201.txt\n",
    "        ‚îú‚îÄ‚îÄ image202.txt\n",
    "        ‚îî‚îÄ‚îÄ ...\n",
    "```\n",
    "\n",
    "### Key Points\n",
    "- **images/** and **labels/** must have same subdirectory structure\n",
    "- **train/**, **val/**, **test/** splits are standard\n",
    "- Each image must have a corresponding label file (even if empty)\n",
    "- Filenames must match exactly (except extension)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Create Sample Dataset\n",
    "\n",
    "Let's create a small synthetic dataset to demonstrate the format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install required libraries\n",
    "!pip install -q ultralytics opencv-python matplotlib pillow\n",
    "\n",
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "from pathlib import Path\n",
    "import shutil\n",
    "\n",
    "# Create dataset directory structure\n",
    "dataset_root = Path('sample_dataset')\n",
    "splits = ['train', 'val', 'test']\n",
    "\n",
    "# Remove existing dataset if present\n",
    "if dataset_root.exists():\n",
    "    shutil.rmtree(dataset_root)\n",
    "\n",
    "# Create directories\n",
    "for split in splits:\n",
    "    (dataset_root / 'images' / split).mkdir(parents=True, exist_ok=True)\n",
    "    (dataset_root / 'labels' / split).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "print(\"‚úÖ Dataset directory structure created!\")\n",
    "print(\"\\nDirectory structure:\")\n",
    "for root, dirs, files in os.walk(dataset_root):\n",
    "    level = root.replace(str(dataset_root), '').count(os.sep)\n",
    "    indent = ' ' * 2 * level\n",
    "    print(f\"{indent}{os.path.basename(root)}/\")\n",
    "    subindent = ' ' * 2 * (level + 1)\n",
    "    for file in files:\n",
    "        print(f\"{subindent}{file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to create synthetic images with boxes\n",
    "def create_synthetic_image(width=640, height=480, num_objects=3):\n",
    "    \"\"\"\n",
    "    Create a synthetic image with random colored rectangles\n",
    "    Returns: image, list of [class_id, x_center, y_center, width, height]\n",
    "    \"\"\"\n",
    "    # Create white background\n",
    "    image = np.ones((height, width, 3), dtype=np.uint8) * 255\n",
    "    \n",
    "    annotations = []\n",
    "    colors = [(255, 0, 0), (0, 255, 0), (0, 0, 255), (255, 255, 0), (255, 0, 255)]\n",
    "    \n",
    "    for i in range(num_objects):\n",
    "        # Random class (0-2: circle, square, triangle)\n",
    "        class_id = np.random.randint(0, 3)\n",
    "        \n",
    "        # Random position and size\n",
    "        obj_width = np.random.randint(50, 150)\n",
    "        obj_height = np.random.randint(50, 150)\n",
    "        x1 = np.random.randint(0, width - obj_width)\n",
    "        y1 = np.random.randint(0, height - obj_height)\n",
    "        x2 = x1 + obj_width\n",
    "        y2 = y1 + obj_height\n",
    "        \n",
    "        # Draw shape\n",
    "        color = colors[class_id]\n",
    "        if class_id == 0:  # Circle\n",
    "            center = ((x1 + x2) // 2, (y1 + y2) // 2)\n",
    "            radius = min(obj_width, obj_height) // 2\n",
    "            cv2.circle(image, center, radius, color, -1)\n",
    "        elif class_id == 1:  # Rectangle\n",
    "            cv2.rectangle(image, (x1, y1), (x2, y2), color, -1)\n",
    "        else:  # Triangle\n",
    "            pts = np.array([\n",
    "                [(x1 + x2) // 2, y1],\n",
    "                [x1, y2],\n",
    "                [x2, y2]\n",
    "            ], np.int32)\n",
    "            cv2.fillPoly(image, [pts], color)\n",
    "        \n",
    "        # Convert to YOLO format (normalized)\n",
    "        x_center = ((x1 + x2) / 2) / width\n",
    "        y_center = ((y1 + y2) / 2) / height\n",
    "        norm_width = (x2 - x1) / width\n",
    "        norm_height = (y2 - y1) / height\n",
    "        \n",
    "        annotations.append([class_id, x_center, y_center, norm_width, norm_height])\n",
    "    \n",
    "    return image, annotations\n",
    "\n",
    "# Create sample images\n",
    "num_samples = {'train': 10, 'val': 3, 'test': 2}\n",
    "\n",
    "for split, count in num_samples.items():\n",
    "    for i in range(count):\n",
    "        # Create image and annotations\n",
    "        image, annotations = create_synthetic_image()\n",
    "        \n",
    "        # Save image\n",
    "        image_path = dataset_root / 'images' / split / f'{split}_{i:03d}.jpg'\n",
    "        cv2.imwrite(str(image_path), image)\n",
    "        \n",
    "        # Save annotations\n",
    "        label_path = dataset_root / 'labels' / split / f'{split}_{i:03d}.txt'\n",
    "        with open(label_path, 'w') as f:\n",
    "            for ann in annotations:\n",
    "                f.write(f\"{ann[0]} {ann[1]:.6f} {ann[2]:.6f} {ann[3]:.6f} {ann[4]:.6f}\\n\")\n",
    "\n",
    "print(\"‚úÖ Synthetic dataset created!\")\n",
    "print(f\"\\nüìä Dataset Statistics:\")\n",
    "for split, count in num_samples.items():\n",
    "    print(f\"  {split}: {count} images\")\n",
    "print(f\"\\n  Total: {sum(num_samples.values())} images\")\n",
    "print(\"\\n  Classes: 0=Circle, 1=Rectangle, 2=Triangle\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Verify Dataset\n",
    "\n",
    "Always verify your dataset before training to catch errors early."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to visualize annotations\n",
    "def visualize_yolo_annotations(image_path, label_path, class_names):\n",
    "    \"\"\"\n",
    "    Visualize YOLO annotations on an image\n",
    "    \"\"\"\n",
    "    # Read image\n",
    "    image = cv2.imread(str(image_path))\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "    height, width = image.shape[:2]\n",
    "    \n",
    "    # Read annotations\n",
    "    annotations = []\n",
    "    if os.path.exists(label_path):\n",
    "        with open(label_path, 'r') as f:\n",
    "            for line in f:\n",
    "                parts = line.strip().split()\n",
    "                if len(parts) == 5:\n",
    "                    class_id = int(parts[0])\n",
    "                    x_center = float(parts[1])\n",
    "                    y_center = float(parts[2])\n",
    "                    box_width = float(parts[3])\n",
    "                    box_height = float(parts[4])\n",
    "                    annotations.append([class_id, x_center, y_center, box_width, box_height])\n",
    "    \n",
    "    # Create figure\n",
    "    fig, ax = plt.subplots(figsize=(10, 8))\n",
    "    ax.imshow(image)\n",
    "    \n",
    "    # Draw bounding boxes\n",
    "    colors = ['red', 'green', 'blue', 'yellow', 'magenta']\n",
    "    for ann in annotations:\n",
    "        class_id, x_center, y_center, box_width, box_height = ann\n",
    "        \n",
    "        # Convert normalized to pixel coordinates\n",
    "        x_center_px = x_center * width\n",
    "        y_center_px = y_center * height\n",
    "        box_width_px = box_width * width\n",
    "        box_height_px = box_height * height\n",
    "        \n",
    "        # Calculate corner coordinates\n",
    "        x1 = x_center_px - box_width_px / 2\n",
    "        y1 = y_center_px - box_height_px / 2\n",
    "        \n",
    "        # Draw rectangle\n",
    "        rect = patches.Rectangle(\n",
    "            (x1, y1), box_width_px, box_height_px,\n",
    "            linewidth=3, edgecolor=colors[class_id % len(colors)],\n",
    "            facecolor='none'\n",
    "        )\n",
    "        ax.add_patch(rect)\n",
    "        \n",
    "        # Add label\n",
    "        class_name = class_names[class_id] if class_id < len(class_names) else f'Class {class_id}'\n",
    "        ax.text(\n",
    "            x1, y1 - 5, class_name,\n",
    "            color=colors[class_id % len(colors)],\n",
    "            fontsize=12, fontweight='bold',\n",
    "            bbox=dict(boxstyle='round,pad=0.3', facecolor='white', alpha=0.8)\n",
    "        )\n",
    "    \n",
    "    ax.axis('off')\n",
    "    return fig, ax, annotations\n",
    "\n",
    "# Visualize sample images\n",
    "class_names = ['Circle', 'Rectangle', 'Triangle']\n",
    "\n",
    "fig, axes = plt.subplots(2, 3, figsize=(18, 12))\n",
    "axes = axes.flatten()\n",
    "\n",
    "# Show 6 training samples\n",
    "for i in range(6):\n",
    "    image_path = dataset_root / 'images' / 'train' / f'train_{i:03d}.jpg'\n",
    "    label_path = dataset_root / 'labels' / 'train' / f'train_{i:03d}.txt'\n",
    "    \n",
    "    # Read and display\n",
    "    image = cv2.imread(str(image_path))\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "    height, width = image.shape[:2]\n",
    "    \n",
    "    # Read annotations\n",
    "    annotations = []\n",
    "    with open(label_path, 'r') as f:\n",
    "        for line in f:\n",
    "            parts = line.strip().split()\n",
    "            class_id = int(parts[0])\n",
    "            x_center = float(parts[1]) * width\n",
    "            y_center = float(parts[2]) * height\n",
    "            box_width = float(parts[3]) * width\n",
    "            box_height = float(parts[4]) * height\n",
    "            \n",
    "            x1 = x_center - box_width / 2\n",
    "            y1 = y_center - box_height / 2\n",
    "            \n",
    "            # Draw box\n",
    "            colors = [(255, 0, 0), (0, 255, 0), (0, 0, 255)]\n",
    "            cv2.rectangle(image, \n",
    "                        (int(x1), int(y1)), \n",
    "                        (int(x1 + box_width), int(y1 + box_height)),\n",
    "                        colors[class_id], 3)\n",
    "            \n",
    "            # Add label\n",
    "            cv2.putText(image, class_names[class_id],\n",
    "                       (int(x1), int(y1) - 10),\n",
    "                       cv2.FONT_HERSHEY_SIMPLEX, 0.6,\n",
    "                       colors[class_id], 2)\n",
    "    \n",
    "    axes[i].imshow(image)\n",
    "    axes[i].set_title(f'Train Sample {i}', fontsize=10, fontweight='bold')\n",
    "    axes[i].axis('off')\n",
    "\n",
    "plt.suptitle('Dataset Verification: Annotated Images', fontsize=16, fontweight='bold')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"‚úÖ Dataset verification complete!\")\n",
    "print(\"\\nüí° All images have correct annotations\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. data.yaml Configuration\n",
    "\n",
    "The `data.yaml` file tells YOLO where to find your data and what classes you have.\n",
    "\n",
    "### Format\n",
    "\n",
    "```yaml\n",
    "path: /path/to/dataset  # Absolute path to dataset root\n",
    "train: images/train     # Relative path to training images\n",
    "val: images/val         # Relative path to validation images\n",
    "test: images/test       # Relative path to test images (optional)\n",
    "\n",
    "names:\n",
    "  0: person\n",
    "  1: car\n",
    "  2: dog\n",
    "```\n",
    "\n",
    "### Alternative Format (List)\n",
    "\n",
    "```yaml\n",
    "path: /path/to/dataset\n",
    "train: images/train\n",
    "val: images/val\n",
    "\n",
    "names: ['person', 'car', 'dog']\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create data.yaml for our dataset\n",
    "import yaml\n",
    "\n",
    "data_yaml = {\n",
    "    'path': str(dataset_root.absolute()),\n",
    "    'train': 'images/train',\n",
    "    'val': 'images/val',\n",
    "    'test': 'images/test',\n",
    "    'names': {\n",
    "        0: 'Circle',\n",
    "        1: 'Rectangle',\n",
    "        2: 'Triangle'\n",
    "    }\n",
    "}\n",
    "\n",
    "# Save data.yaml\n",
    "yaml_path = dataset_root / 'data.yaml'\n",
    "with open(yaml_path, 'w') as f:\n",
    "    yaml.dump(data_yaml, f, default_flow_style=False, sort_keys=False)\n",
    "\n",
    "print(\"‚úÖ data.yaml created!\")\n",
    "print(\"\\nContents:\")\n",
    "print(\"=\"*60)\n",
    "with open(yaml_path, 'r') as f:\n",
    "    print(f.read())\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Annotation Tools\n",
    "\n",
    "For real-world datasets, you'll need annotation tools. Here are the most popular:\n",
    "\n",
    "### 1. LabelImg (Desktop)\n",
    "- **Type**: Free, open-source, desktop app\n",
    "- **Platform**: Windows, macOS, Linux\n",
    "- **Format**: Supports YOLO, PASCAL VOC, COCO\n",
    "- **Installation**: `pip install labelImg`\n",
    "- **GitHub**: https://github.com/heartexlabs/labelImg\n",
    "\n",
    "**Pros:**\n",
    "- Simple and intuitive\n",
    "- Keyboard shortcuts\n",
    "- Directly saves in YOLO format\n",
    "\n",
    "**Cons:**\n",
    "- Manual one-by-one annotation\n",
    "- No collaboration features\n",
    "\n",
    "### 2. Roboflow (Web-based)\n",
    "- **Type**: Web-based platform (free tier available)\n",
    "- **URL**: https://roboflow.com\n",
    "- **Features**: Annotation, augmentation, format conversion, hosting\n",
    "\n",
    "**Pros:**\n",
    "- Team collaboration\n",
    "- Automatic augmentation\n",
    "- Export to multiple formats\n",
    "- Public datasets available\n",
    "\n",
    "**Cons:**\n",
    "- Free tier has limits\n",
    "- Requires internet connection\n",
    "\n",
    "### 3. CVAT (Computer Vision Annotation Tool)\n",
    "- **Type**: Web-based, open-source\n",
    "- **URL**: https://www.cvat.ai\n",
    "- **Features**: Advanced annotation, video support, interpolation\n",
    "\n",
    "**Pros:**\n",
    "- Enterprise-grade features\n",
    "- Video annotation\n",
    "- Semi-automatic annotation\n",
    "\n",
    "**Cons:**\n",
    "- Steeper learning curve\n",
    "- Requires setup (self-hosted or cloud)\n",
    "\n",
    "### 4. Labelbox\n",
    "- **Type**: Commercial platform (free tier)\n",
    "- **URL**: https://labelbox.com\n",
    "- **Features**: Full ML data pipeline\n",
    "\n",
    "### 5. Makesense.ai\n",
    "- **Type**: Free, browser-based\n",
    "- **URL**: https://www.makesense.ai\n",
    "- **Features**: No signup required, runs in browser\n",
    "\n",
    "**Pros:**\n",
    "- No installation\n",
    "- Privacy (runs locally)\n",
    "- Simple interface\n",
    "\n",
    "### Recommendation for Beginners\n",
    "- **Small datasets (<100 images)**: LabelImg or Makesense.ai\n",
    "- **Medium datasets (100-1000 images)**: Roboflow\n",
    "- **Large/enterprise**: CVAT or Labelbox"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Data Augmentation Preview\n",
    "\n",
    "YOLO has built-in data augmentation during training. Here are common techniques:\n",
    "\n",
    "### Common Augmentations\n",
    "1. **Geometric**: Rotation, flip, scaling, translation\n",
    "2. **Color**: HSV adjustment, brightness, contrast\n",
    "3. **Advanced**: Mosaic, MixUp, CutOut\n",
    "\n",
    "### Mosaic Augmentation\n",
    "Combines 4 images into one, creating diverse scenes and improving small object detection.\n",
    "\n",
    "### MixUp\n",
    "Blends two images together, creating smoother decision boundaries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Demonstrate simple augmentations\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "# Load a sample image\n",
    "image_path = dataset_root / 'images' / 'train' / 'train_000.jpg'\n",
    "image = cv2.imread(str(image_path))\n",
    "image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "# Create augmented versions\n",
    "aug_images = []\n",
    "aug_titles = []\n",
    "\n",
    "# Original\n",
    "aug_images.append(image)\n",
    "aug_titles.append('Original')\n",
    "\n",
    "# Horizontal flip\n",
    "flipped = cv2.flip(image, 1)\n",
    "aug_images.append(flipped)\n",
    "aug_titles.append('Horizontal Flip')\n",
    "\n",
    "# Rotation\n",
    "h, w = image.shape[:2]\n",
    "center = (w // 2, h // 2)\n",
    "matrix = cv2.getRotationMatrix2D(center, 15, 1.0)\n",
    "rotated = cv2.warpAffine(image, matrix, (w, h), borderValue=(255, 255, 255))\n",
    "aug_images.append(rotated)\n",
    "aug_titles.append('Rotation (15¬∞)')\n",
    "\n",
    "# Brightness adjustment\n",
    "hsv = cv2.cvtColor(image, cv2.COLOR_RGB2HSV)\n",
    "hsv[:, :, 2] = np.clip(hsv[:, :, 2] * 1.3, 0, 255).astype(np.uint8)\n",
    "bright = cv2.cvtColor(hsv, cv2.COLOR_HSV2RGB)\n",
    "aug_images.append(bright)\n",
    "aug_titles.append('Brightness +30%')\n",
    "\n",
    "# Scaling\n",
    "scaled = cv2.resize(image, None, fx=1.2, fy=1.2, interpolation=cv2.INTER_LINEAR)\n",
    "scaled = cv2.resize(scaled, (w, h), interpolation=cv2.INTER_LINEAR)\n",
    "aug_images.append(scaled)\n",
    "aug_titles.append('Scale +20%')\n",
    "\n",
    "# Gaussian blur\n",
    "blurred = cv2.GaussianBlur(image, (5, 5), 0)\n",
    "aug_images.append(blurred)\n",
    "aug_titles.append('Gaussian Blur')\n",
    "\n",
    "# Visualize\n",
    "fig, axes = plt.subplots(2, 3, figsize=(15, 10))\n",
    "axes = axes.flatten()\n",
    "\n",
    "for idx, (img, title) in enumerate(zip(aug_images, aug_titles)):\n",
    "    axes[idx].imshow(img)\n",
    "    axes[idx].set_title(title, fontsize=12, fontweight='bold')\n",
    "    axes[idx].axis('off')\n",
    "\n",
    "plt.suptitle('Data Augmentation Examples', fontsize=16, fontweight='bold')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nüí° YOLOv8 Training Augmentations:\")\n",
    "print(\"  ‚Ä¢ Mosaic (combines 4 images)\")\n",
    "print(\"  ‚Ä¢ MixUp (blends 2 images)\")\n",
    "print(\"  ‚Ä¢ HSV augmentation\")\n",
    "print(\"  ‚Ä¢ Random flip, rotation, scale\")\n",
    "print(\"  ‚Ä¢ CutOut (random erasing)\")\n",
    "print(\"\\n  These are applied automatically during training!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Class Balance Check\n",
    "\n",
    "Imbalanced datasets can lead to poor performance. Always check class distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count instances per class\n",
    "def count_class_instances(dataset_path):\n",
    "    \"\"\"\n",
    "    Count number of instances per class in dataset\n",
    "    \"\"\"\n",
    "    class_counts = {}\n",
    "    \n",
    "    for split in ['train', 'val', 'test']:\n",
    "        label_dir = dataset_path / 'labels' / split\n",
    "        \n",
    "        for label_file in label_dir.glob('*.txt'):\n",
    "            with open(label_file, 'r') as f:\n",
    "                for line in f:\n",
    "                    parts = line.strip().split()\n",
    "                    if len(parts) == 5:\n",
    "                        class_id = int(parts[0])\n",
    "                        if class_id not in class_counts:\n",
    "                            class_counts[class_id] = 0\n",
    "                        class_counts[class_id] += 1\n",
    "    \n",
    "    return class_counts\n",
    "\n",
    "# Count instances\n",
    "class_counts = count_class_instances(dataset_root)\n",
    "\n",
    "# Visualize distribution\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Bar chart\n",
    "classes = [class_names[i] for i in sorted(class_counts.keys())]\n",
    "counts = [class_counts[i] for i in sorted(class_counts.keys())]\n",
    "colors = ['#FF6B6B', '#4ECDC4', '#45B7D1']\n",
    "\n",
    "bars = axes[0].bar(classes, counts, color=colors)\n",
    "axes[0].set_xlabel('Class', fontsize=12, fontweight='bold')\n",
    "axes[0].set_ylabel('Number of Instances', fontsize=12, fontweight='bold')\n",
    "axes[0].set_title('Class Distribution', fontsize=14, fontweight='bold')\n",
    "axes[0].grid(axis='y', alpha=0.3)\n",
    "\n",
    "# Add count labels\n",
    "for bar in bars:\n",
    "    height = bar.get_height()\n",
    "    axes[0].text(bar.get_x() + bar.get_width()/2., height,\n",
    "                f'{int(height)}',\n",
    "                ha='center', va='bottom', fontweight='bold')\n",
    "\n",
    "# Pie chart\n",
    "axes[1].pie(counts, labels=classes, autopct='%1.1f%%', colors=colors, startangle=90)\n",
    "axes[1].set_title('Class Distribution (%)', fontsize=14, fontweight='bold')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Print statistics\n",
    "total = sum(counts)\n",
    "print(\"\\nüìä Class Balance Analysis:\")\n",
    "print(\"=\"*60)\n",
    "print(f\"{'Class':<15} {'Count':<10} {'Percentage':<15} {'Status':<15}\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "for class_id in sorted(class_counts.keys()):\n",
    "    count = class_counts[class_id]\n",
    "    pct = (count / total) * 100\n",
    "    \n",
    "    # Determine balance status\n",
    "    if pct < 20:\n",
    "        status = \"‚ö†Ô∏è Underrepresented\"\n",
    "    elif pct > 40:\n",
    "        status = \"‚ö†Ô∏è Overrepresented\"\n",
    "    else:\n",
    "        status = \"‚úÖ Balanced\"\n",
    "    \n",
    "    print(f\"{class_names[class_id]:<15} {count:<10} {pct:<15.1f} {status:<15}\")\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(f\"Total instances: {total}\")\n",
    "print(\"\\nüí° Ideal: Each class should have 20-40% of total instances\")\n",
    "print(\"   If imbalanced, consider: more data, augmentation, or class weights\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Train/Val/Test Split\n",
    "\n",
    "Proper data splitting is crucial for model evaluation.\n",
    "\n",
    "### Common Split Ratios\n",
    "\n",
    "| Split | Percentage | Purpose |\n",
    "|-------|-----------|----------|\n",
    "| Train | 70-80% | Model learning |\n",
    "| Validation | 15-20% | Hyperparameter tuning |\n",
    "| Test | 5-10% | Final evaluation |\n",
    "\n",
    "### Guidelines\n",
    "- **Small datasets (<100 images)**: 70/20/10\n",
    "- **Medium datasets (100-1000)**: 75/15/10\n",
    "- **Large datasets (>1000)**: 80/10/10\n",
    "\n",
    "### Important Considerations\n",
    "1. **Random split**: Ensure balanced class distribution\n",
    "2. **Stratified split**: Maintain class proportions across splits\n",
    "3. **No data leakage**: Same image shouldn't appear in multiple splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to split dataset\n",
    "def split_dataset(source_images, source_labels, output_root, train_ratio=0.7, val_ratio=0.2):\n",
    "    \"\"\"\n",
    "    Split dataset into train/val/test\n",
    "    \n",
    "    Args:\n",
    "        source_images: Path to source images\n",
    "        source_labels: Path to source labels\n",
    "        output_root: Output directory\n",
    "        train_ratio: Proportion for training (default 0.7)\n",
    "        val_ratio: Proportion for validation (default 0.2)\n",
    "    \"\"\"\n",
    "    import shutil\n",
    "    from sklearn.model_selection import train_test_split\n",
    "    \n",
    "    # Get all image files\n",
    "    image_files = list(Path(source_images).glob('*.*'))\n",
    "    image_files = [f for f in image_files if f.suffix.lower() in ['.jpg', '.jpeg', '.png']]\n",
    "    \n",
    "    # First split: train vs (val + test)\n",
    "    train_files, temp_files = train_test_split(\n",
    "        image_files, \n",
    "        train_size=train_ratio, \n",
    "        random_state=42\n",
    "    )\n",
    "    \n",
    "    # Second split: val vs test\n",
    "    val_size = val_ratio / (1 - train_ratio)\n",
    "    val_files, test_files = train_test_split(\n",
    "        temp_files,\n",
    "        train_size=val_size,\n",
    "        random_state=42\n",
    "    )\n",
    "    \n",
    "    splits = {\n",
    "        'train': train_files,\n",
    "        'val': val_files,\n",
    "        'test': test_files\n",
    "    }\n",
    "    \n",
    "    # Copy files to appropriate directories\n",
    "    for split_name, files in splits.items():\n",
    "        for image_file in files:\n",
    "            # Copy image\n",
    "            dst_image = output_root / 'images' / split_name / image_file.name\n",
    "            shutil.copy(image_file, dst_image)\n",
    "            \n",
    "            # Copy label\n",
    "            label_file = Path(source_labels) / (image_file.stem + '.txt')\n",
    "            if label_file.exists():\n",
    "                dst_label = output_root / 'labels' / split_name / label_file.name\n",
    "                shutil.copy(label_file, dst_label)\n",
    "    \n",
    "    return splits\n",
    "\n",
    "# Demonstrate split ratios\n",
    "print(\"üìä Dataset Split Recommendations:\")\n",
    "print(\"=\"*60)\n",
    "print(f\"{'Dataset Size':<20} {'Train':<10} {'Val':<10} {'Test':<10}\")\n",
    "print(\"=\"*60)\n",
    "print(f\"{'Small (<100)':<20} {'70%':<10} {'20%':<10} {'10%':<10}\")\n",
    "print(f\"{'Medium (100-1000)':<20} {'75%':<10} {'15%':<10} {'10%':<10}\")\n",
    "print(f\"{'Large (>1000)':<20} {'80%':<10} {'10%':<10} {'10%':<10}\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Show current split\n",
    "print(\"\\nüìÅ Current Dataset Split:\")\n",
    "print(\"=\"*60)\n",
    "for split in ['train', 'val', 'test']:\n",
    "    image_dir = dataset_root / 'images' / split\n",
    "    num_images = len(list(image_dir.glob('*.jpg')))\n",
    "    total_images = sum([len(list((dataset_root / 'images' / s).glob('*.jpg'))) for s in ['train', 'val', 'test']])\n",
    "    pct = (num_images / total_images) * 100 if total_images > 0 else 0\n",
    "    print(f\"{split.capitalize():<10}: {num_images:>3} images ({pct:>5.1f}%)\")\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Common Dataset Errors\n",
    "\n",
    "### Error 1: Mismatched Image/Label Files\n",
    "```\n",
    "‚ùå images/train/img001.jpg exists\n",
    "‚ùå labels/train/img001.txt missing\n",
    "```\n",
    "**Solution**: Ensure every image has a corresponding label file (even if empty)\n",
    "\n",
    "### Error 2: Out-of-Range Coordinates\n",
    "```\n",
    "‚ùå 0 0.5 0.5 1.5 0.4  (width > 1.0)\n",
    "```\n",
    "**Solution**: All coordinates must be normalized between 0 and 1\n",
    "\n",
    "### Error 3: Wrong Class IDs\n",
    "```\n",
    "‚ùå 5 0.5 0.5 0.3 0.4  (but only 3 classes: 0, 1, 2)\n",
    "```\n",
    "**Solution**: Class IDs must start at 0 and be consecutive\n",
    "\n",
    "### Error 4: Empty Label Files\n",
    "```\n",
    "‚ö†Ô∏è labels/train/img001.txt is empty\n",
    "```\n",
    "**Note**: Empty files are OK (images with no objects)\n",
    "\n",
    "### Error 5: Incorrect Format\n",
    "```\n",
    "‚ùå 0,0.5,0.5,0.3,0.4  (commas instead of spaces)\n",
    "‚ùå 0 50 50 30 40      (pixels instead of normalized)\n",
    "```\n",
    "**Solution**: Use space-separated normalized values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset validation function\n",
    "def validate_dataset(dataset_path, num_classes):\n",
    "    \"\"\"\n",
    "    Validate YOLO dataset for common errors\n",
    "    \"\"\"\n",
    "    errors = []\n",
    "    warnings = []\n",
    "    \n",
    "    for split in ['train', 'val', 'test']:\n",
    "        image_dir = dataset_path / 'images' / split\n",
    "        label_dir = dataset_path / 'labels' / split\n",
    "        \n",
    "        # Get all images\n",
    "        images = list(image_dir.glob('*.jpg')) + list(image_dir.glob('*.png'))\n",
    "        \n",
    "        for image_file in images:\n",
    "            # Check for corresponding label\n",
    "            label_file = label_dir / (image_file.stem + '.txt')\n",
    "            \n",
    "            if not label_file.exists():\n",
    "                errors.append(f\"Missing label: {label_file}\")\n",
    "                continue\n",
    "            \n",
    "            # Validate label content\n",
    "            if label_file.stat().st_size == 0:\n",
    "                warnings.append(f\"Empty label: {label_file}\")\n",
    "                continue\n",
    "            \n",
    "            with open(label_file, 'r') as f:\n",
    "                for line_num, line in enumerate(f, 1):\n",
    "                    parts = line.strip().split()\n",
    "                    \n",
    "                    if len(parts) != 5:\n",
    "                        errors.append(f\"{label_file}:{line_num} - Wrong format (expected 5 values)\")\n",
    "                        continue\n",
    "                    \n",
    "                    try:\n",
    "                        class_id = int(parts[0])\n",
    "                        x_center = float(parts[1])\n",
    "                        y_center = float(parts[2])\n",
    "                        width = float(parts[3])\n",
    "                        height = float(parts[4])\n",
    "                        \n",
    "                        # Validate class ID\n",
    "                        if class_id < 0 or class_id >= num_classes:\n",
    "                            errors.append(f\"{label_file}:{line_num} - Invalid class ID {class_id}\")\n",
    "                        \n",
    "                        # Validate coordinates (0-1 range)\n",
    "                        if not (0 <= x_center <= 1):\n",
    "                            errors.append(f\"{label_file}:{line_num} - x_center out of range: {x_center}\")\n",
    "                        if not (0 <= y_center <= 1):\n",
    "                            errors.append(f\"{label_file}:{line_num} - y_center out of range: {y_center}\")\n",
    "                        if not (0 <= width <= 1):\n",
    "                            errors.append(f\"{label_file}:{line_num} - width out of range: {width}\")\n",
    "                        if not (0 <= height <= 1):\n",
    "                            errors.append(f\"{label_file}:{line_num} - height out of range: {height}\")\n",
    "                    \n",
    "                    except ValueError as e:\n",
    "                        errors.append(f\"{label_file}:{line_num} - Invalid number format\")\n",
    "    \n",
    "    return errors, warnings\n",
    "\n",
    "# Validate our dataset\n",
    "errors, warnings = validate_dataset(dataset_root, num_classes=3)\n",
    "\n",
    "print(\"\\nüîç Dataset Validation Results:\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "if not errors and not warnings:\n",
    "    print(\"‚úÖ Dataset is valid! No errors or warnings.\")\n",
    "else:\n",
    "    if errors:\n",
    "        print(f\"\\n‚ùå Errors ({len(errors)}):\")\n",
    "        for error in errors[:10]:  # Show first 10\n",
    "            print(f\"  ‚Ä¢ {error}\")\n",
    "        if len(errors) > 10:\n",
    "            print(f\"  ... and {len(errors) - 10} more\")\n",
    "    \n",
    "    if warnings:\n",
    "        print(f\"\\n‚ö†Ô∏è Warnings ({len(warnings)}):\")\n",
    "        for warning in warnings[:10]:\n",
    "            print(f\"  ‚Ä¢ {warning}\")\n",
    "        if len(warnings) > 10:\n",
    "            print(f\"  ... and {len(warnings) - 10} more\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11. Exercise: Prepare Your Own Mini Dataset\n",
    "\n",
    "Now it's your turn to prepare a dataset!\n",
    "\n",
    "### Exercise Tasks\n",
    "\n",
    "1. **Collect Images**: Gather 10-20 images for your custom object detection task\n",
    "   - Option A: Download from internet\n",
    "   - Option B: Take photos with your phone\n",
    "   - Option C: Use existing public dataset\n",
    "\n",
    "2. **Choose Classes**: Define 2-3 object classes to detect\n",
    "   - Examples: \"cat\", \"dog\", \"person\", \"car\", \"phone\", etc.\n",
    "\n",
    "3. **Annotate Images**: Use one of these tools:\n",
    "   - LabelImg (recommended for beginners)\n",
    "   - Makesense.ai (browser-based)\n",
    "   - Roboflow (if you want to try web-based)\n",
    "\n",
    "4. **Organize Dataset**: Create proper directory structure\n",
    "   ```\n",
    "   my_custom_dataset/\n",
    "   ‚îú‚îÄ‚îÄ images/\n",
    "   ‚îÇ   ‚îú‚îÄ‚îÄ train/\n",
    "   ‚îÇ   ‚îú‚îÄ‚îÄ val/\n",
    "   ‚îÇ   ‚îî‚îÄ‚îÄ test/\n",
    "   ‚îú‚îÄ‚îÄ labels/\n",
    "   ‚îÇ   ‚îú‚îÄ‚îÄ train/\n",
    "   ‚îÇ   ‚îú‚îÄ‚îÄ val/\n",
    "   ‚îÇ   ‚îî‚îÄ‚îÄ test/\n",
    "   ‚îî‚îÄ‚îÄ data.yaml\n",
    "   ```\n",
    "\n",
    "5. **Create data.yaml**: Define your classes and paths\n",
    "\n",
    "6. **Validate**: Run the validation function to check for errors\n",
    "\n",
    "### Success Criteria\n",
    "- ‚úÖ All images have corresponding label files\n",
    "- ‚úÖ All coordinates are normalized (0-1)\n",
    "- ‚úÖ Class IDs are correct (0, 1, 2, ...)\n",
    "- ‚úÖ data.yaml is properly configured\n",
    "- ‚úÖ No validation errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exercise template - fill in your details\n",
    "\n",
    "# TODO: Define your classes\n",
    "my_classes = ['class1', 'class2', 'class3']  # Replace with your classes\n",
    "\n",
    "# TODO: Set your dataset path\n",
    "my_dataset_path = Path('my_custom_dataset')  # Change to your path\n",
    "\n",
    "# TODO: Create data.yaml\n",
    "# my_data_yaml = {\n",
    "#     'path': str(my_dataset_path.absolute()),\n",
    "#     'train': 'images/train',\n",
    "#     'val': 'images/val',\n",
    "#     'test': 'images/test',\n",
    "#     'names': {i: name for i, name in enumerate(my_classes)}\n",
    "# }\n",
    "\n",
    "# TODO: Validate your dataset\n",
    "# errors, warnings = validate_dataset(my_dataset_path, len(my_classes))\n",
    "# print(f\"Errors: {len(errors)}, Warnings: {len(warnings)}\")\n",
    "\n",
    "print(\"‚úèÔ∏è Complete the TODOs above to prepare your custom dataset!\")\n",
    "print(\"\\nüìö Next steps:\")\n",
    "print(\"  1. Collect 10-20 images\")\n",
    "print(\"  2. Annotate using LabelImg or Makesense.ai\")\n",
    "print(\"  3. Organize into train/val/test splits\")\n",
    "print(\"  4. Create data.yaml configuration\")\n",
    "print(\"  5. Validate dataset for errors\")\n",
    "print(\"\\n  Ready for Notebook 04: Training YOLOv8! üöÄ\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 12. Summary\n",
    "\n",
    "### What We Learned\n",
    "\n",
    "‚úÖ **YOLO Format**: Normalized bounding boxes with class IDs\n",
    "\n",
    "‚úÖ **Directory Structure**: Proper organization of images and labels\n",
    "\n",
    "‚úÖ **data.yaml**: Configuration file for training\n",
    "\n",
    "‚úÖ **Annotation Tools**: LabelImg, Roboflow, CVAT, Makesense.ai\n",
    "\n",
    "‚úÖ **Data Augmentation**: Built-in augmentations in YOLO\n",
    "\n",
    "‚úÖ **Class Balance**: Importance of balanced datasets\n",
    "\n",
    "‚úÖ **Data Splitting**: Train/val/test ratios\n",
    "\n",
    "‚úÖ **Validation**: Checking for common errors\n",
    "\n",
    "### Key Takeaways\n",
    "\n",
    "1. **Format matters**: YOLO expects specific format (normalized coordinates)\n",
    "2. **Validation is crucial**: Always validate before training\n",
    "3. **Balance your data**: Avoid class imbalance when possible\n",
    "4. **Use the right tools**: Choose annotation tool based on dataset size\n",
    "5. **Split properly**: Maintain class distribution across splits\n",
    "\n",
    "### Dataset Preparation Checklist\n",
    "\n",
    "- [ ] Images and labels in correct directories\n",
    "- [ ] Filenames match (image001.jpg ‚Üí image001.txt)\n",
    "- [ ] All coordinates normalized (0-1 range)\n",
    "- [ ] Class IDs start from 0 and are consecutive\n",
    "- [ ] data.yaml created with correct paths\n",
    "- [ ] Train/val/test split done (70/20/10 or 80/15/5)\n",
    "- [ ] Dataset validated (no errors)\n",
    "- [ ] Class balance checked\n",
    "\n",
    "### Preview: Notebook 04 - Training YOLOv8\n",
    "\n",
    "In the next notebook, we'll:\n",
    "- Train YOLOv8 on custom dataset\n",
    "- Monitor training progress\n",
    "- Evaluate model performance\n",
    "- Fine-tune hyperparameters\n",
    "- Export trained model\n",
    "\n",
    "---\n",
    "\n",
    "**Your dataset is ready! Let's train a model!** üéØ"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
