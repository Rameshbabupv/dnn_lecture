{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notebook 04: YOLOv8 Training on Custom Dataset\n",
    "\n",
    "**Week 14 - Module 5: Object Detection Models**  \n",
    "**Tutorial T14: Fine-tuning YOLO for Custom Detection Tasks**\n",
    "\n",
    "## Learning Objectives\n",
    "- Train YOLOv8 on custom dataset\n",
    "- Understand training parameters (epochs, batch size, learning rate)\n",
    "- Monitor training with TensorBoard\n",
    "- Evaluate trained model performance\n",
    "- Export models for deployment\n",
    "\n",
    "**Estimated Time:** 25 minutes  \n",
    "**Prerequisites:** Completed Notebook 03 (Dataset Preparation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prerequisites Check\n",
    "\n",
    "### Required Resources:\n",
    "- ‚úÖ Dataset from Notebook 03 (annotated images in YOLO format)\n",
    "- ‚úÖ GPU recommended (CUDA-enabled)\n",
    "- ‚úÖ ~500MB disk space for model weights\n",
    "- ‚úÖ Estimated training time: 10-15 minutes on GPU, 60+ minutes on CPU\n",
    "\n",
    "### What You'll Learn:\n",
    "1. How to configure training parameters\n",
    "2. Monitor training progress in real-time\n",
    "3. Evaluate model performance metrics\n",
    "4. Fine-tune hyperparameters for better results\n",
    "5. Export models for production deployment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup: Install Ultralytics YOLO and check GPU availability\n",
    "!pip install -q ultralytics tensorboard\n",
    "\n",
    "from ultralytics import YOLO\n",
    "import torch\n",
    "import os\n",
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from IPython.display import Image, display\n",
    "\n",
    "# Check CUDA availability\n",
    "print(f\"PyTorch version: {torch.__version__}\")\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"GPU Device: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"GPU Memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.2f} GB\")\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è Training will use CPU (slower)\")\n",
    "\n",
    "# Set working directory\n",
    "os.chdir('/Users/rameshbabu/data/projects/srm/lectures/Deep_Neural_Network_Architectures/course_planning/weekly_plans/week14-module5-detection-models/notebooks')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Load Pre-trained YOLOv8 Model\n",
    "\n",
    "We'll start with a pre-trained YOLOv8 model and fine-tune it on our custom dataset.\n",
    "\n",
    "### YOLOv8 Model Variants:\n",
    "- **YOLOv8n** (nano): 6MB, fastest, 3.2M parameters - **Recommended for learning**\n",
    "- **YOLOv8s** (small): 22MB, 11.2M parameters\n",
    "- **YOLOv8m** (medium): 52MB, 25.9M parameters\n",
    "- **YOLOv8l** (large): 87MB, 43.7M parameters\n",
    "- **YOLOv8x** (extra large): 136MB, 68.2M parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load pre-trained YOLOv8 nano model (fastest for training)\n",
    "model = YOLO('yolov8n.pt')\n",
    "\n",
    "print(\"\\nüì¶ Model loaded successfully!\")\n",
    "print(f\"Model type: {model.model.__class__.__name__}\")\n",
    "print(f\"Model task: {model.task}\")\n",
    "print(f\"Pre-trained on: COCO dataset (80 classes)\")\n",
    "\n",
    "# Display model summary\n",
    "model.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Dataset Configuration\n",
    "\n",
    "We'll use a sample dataset for demonstration. You can replace this with your own dataset from Notebook 03.\n",
    "\n",
    "### Dataset Structure (YOLO format):\n",
    "```\n",
    "dataset/\n",
    "‚îú‚îÄ‚îÄ data.yaml          # Dataset configuration\n",
    "‚îú‚îÄ‚îÄ train/\n",
    "‚îÇ   ‚îú‚îÄ‚îÄ images/        # Training images\n",
    "‚îÇ   ‚îî‚îÄ‚îÄ labels/        # Training labels (.txt)\n",
    "‚îî‚îÄ‚îÄ val/\n",
    "    ‚îú‚îÄ‚îÄ images/        # Validation images\n",
    "    ‚îî‚îÄ‚îÄ labels/        # Validation labels (.txt)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Option 1: Download sample hardhat detection dataset\n",
    "# This is a small dataset for quick training demonstration\n",
    "\n",
    "!pip install -q roboflow\n",
    "\n",
    "from roboflow import Roboflow\n",
    "\n",
    "# Download sample dataset (hardhat detection)\n",
    "# You can skip this if you have your own dataset\n",
    "print(\"üì• Downloading sample dataset...\")\n",
    "rf = Roboflow(api_key=\"YOUR_API_KEY\")  # Get free API key from roboflow.com\n",
    "\n",
    "# Alternative: Create a simple toy dataset for demonstration\n",
    "# We'll create a minimal dataset configuration\n",
    "\n",
    "dataset_path = Path('sample_dataset')\n",
    "dataset_path.mkdir(exist_ok=True)\n",
    "\n",
    "# Create data.yaml configuration file\n",
    "data_yaml = f\"\"\"\n",
    "# Dataset configuration for YOLOv8 training\n",
    "path: {dataset_path.absolute()}  # Dataset root directory\n",
    "train: train/images  # Train images (relative to 'path')\n",
    "val: val/images      # Validation images (relative to 'path')\n",
    "\n",
    "# Classes\n",
    "names:\n",
    "  0: person\n",
    "  1: hardhat\n",
    "  2: no-hardhat\n",
    "\"\"\"\n",
    "\n",
    "with open(dataset_path / 'data.yaml', 'w') as f:\n",
    "    f.write(data_yaml)\n",
    "\n",
    "print(\"‚úÖ Dataset configuration created!\")\n",
    "print(f\"Dataset path: {dataset_path.absolute()}\")\n",
    "print(\"\\nüìù data.yaml contents:\")\n",
    "print(data_yaml)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Training Parameters Explained\n",
    "\n",
    "### Key Training Parameters:\n",
    "\n",
    "| Parameter | Default | Description | Tuning Tips |\n",
    "|-----------|---------|-------------|-------------|\n",
    "| `epochs` | 100 | Training iterations | Start with 50, increase if underfitting |\n",
    "| `imgsz` | 640 | Input image size | 640 (default), 1280 (more accurate, slower) |\n",
    "| `batch` | 16 | Batch size | Reduce if OOM error, increase for faster training |\n",
    "| `patience` | 50 | Early stopping patience | 10-20 for small datasets |\n",
    "| `lr0` | 0.01 | Initial learning rate | Auto (default) or 0.001-0.01 |\n",
    "| `device` | 0 | GPU device (0) or CPU | Use 'cpu' if no GPU |\n",
    "| `workers` | 8 | Data loading threads | Reduce if CPU bottleneck |\n",
    "\n",
    "### Loss Functions:\n",
    "- **Box Loss**: Bounding box regression (IoU-based)\n",
    "- **Class Loss**: Classification loss (cross-entropy)\n",
    "- **DFL Loss**: Distribution Focal Loss (localization)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training configuration\n",
    "training_config = {\n",
    "    'data': str(dataset_path / 'data.yaml'),\n",
    "    'epochs': 50,              # Number of training epochs\n",
    "    'imgsz': 640,              # Input image size (pixels)\n",
    "    'batch': 16,               # Batch size (reduce if OOM)\n",
    "    'patience': 10,            # Early stopping patience\n",
    "    'save': True,              # Save checkpoints\n",
    "    'device': 0 if torch.cuda.is_available() else 'cpu',  # GPU or CPU\n",
    "    'workers': 4,              # Data loading threads\n",
    "    'project': 'yolo_training', # Project name\n",
    "    'name': 'exp',             # Experiment name\n",
    "    'exist_ok': True,          # Overwrite existing project\n",
    "    'pretrained': True,        # Use pre-trained weights\n",
    "    'optimizer': 'Adam',       # Optimizer (Adam, SGD, AdamW)\n",
    "    'verbose': True,           # Verbose output\n",
    "    'seed': 42,                # Random seed for reproducibility\n",
    "    'deterministic': True,     # Deterministic training\n",
    "    'plots': True,             # Generate plots\n",
    "}\n",
    "\n",
    "print(\"üîß Training Configuration:\")\n",
    "for key, value in training_config.items():\n",
    "    print(f\"  {key}: {value}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Start Training\n",
    "\n",
    "**Note:** This cell will take 10-15 minutes on GPU, 60+ minutes on CPU.\n",
    "\n",
    "Training progress will show:\n",
    "- Loss values (box, cls, dfl)\n",
    "- Precision, Recall, mAP50, mAP50-95\n",
    "- Training speed (images/second)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start training (this will take time!)\n",
    "print(\"üöÄ Starting training...\\n\")\n",
    "print(\"‚è±Ô∏è Estimated time: 10-15 min (GPU) or 60+ min (CPU)\\n\")\n",
    "\n",
    "# Train the model\n",
    "results = model.train(**training_config)\n",
    "\n",
    "print(\"\\n‚úÖ Training completed!\")\n",
    "print(f\"Results saved to: {results.save_dir}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5: Monitor Training with TensorBoard (Optional)\n",
    "\n",
    "TensorBoard provides real-time visualization of training metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load TensorBoard in Jupyter\n",
    "%load_ext tensorboard\n",
    "\n",
    "# Launch TensorBoard\n",
    "# Point to the training logs directory\n",
    "%tensorboard --logdir yolo_training/exp\n",
    "\n",
    "print(\"üìä TensorBoard launched!\")\n",
    "print(\"You can view real-time training metrics above.\")\n",
    "print(\"\\nKey metrics to watch:\")\n",
    "print(\"  - train/box_loss: Should decrease steadily\")\n",
    "print(\"  - train/cls_loss: Should decrease steadily\")\n",
    "print(\"  - metrics/mAP50: Should increase (target: >0.5)\")\n",
    "print(\"  - metrics/mAP50-95: Should increase (target: >0.3)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 6: Training Results Analysis\n",
    "\n",
    "Let's analyze the training performance and visualize key metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and plot training results\n",
    "import pandas as pd\n",
    "\n",
    "# Read results CSV\n",
    "results_csv = Path('yolo_training/exp/results.csv')\n",
    "if results_csv.exists():\n",
    "    df = pd.read_csv(results_csv)\n",
    "    df.columns = df.columns.str.strip()  # Remove whitespace\n",
    "    \n",
    "    # Create figure with subplots\n",
    "    fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
    "    fig.suptitle('YOLOv8 Training Results', fontsize=16, fontweight='bold')\n",
    "    \n",
    "    # Plot 1: Loss curves\n",
    "    axes[0, 0].plot(df['epoch'], df['train/box_loss'], label='Box Loss', linewidth=2)\n",
    "    axes[0, 0].plot(df['epoch'], df['train/cls_loss'], label='Class Loss', linewidth=2)\n",
    "    axes[0, 0].plot(df['epoch'], df['train/dfl_loss'], label='DFL Loss', linewidth=2)\n",
    "    axes[0, 0].set_xlabel('Epoch')\n",
    "    axes[0, 0].set_ylabel('Loss')\n",
    "    axes[0, 0].set_title('Training Losses')\n",
    "    axes[0, 0].legend()\n",
    "    axes[0, 0].grid(True, alpha=0.3)\n",
    "    \n",
    "    # Plot 2: mAP metrics\n",
    "    axes[0, 1].plot(df['epoch'], df['metrics/mAP50(B)'], label='mAP@0.5', linewidth=2, color='green')\n",
    "    axes[0, 1].plot(df['epoch'], df['metrics/mAP50-95(B)'], label='mAP@0.5:0.95', linewidth=2, color='blue')\n",
    "    axes[0, 1].set_xlabel('Epoch')\n",
    "    axes[0, 1].set_ylabel('mAP')\n",
    "    axes[0, 1].set_title('Mean Average Precision')\n",
    "    axes[0, 1].legend()\n",
    "    axes[0, 1].grid(True, alpha=0.3)\n",
    "    \n",
    "    # Plot 3: Precision and Recall\n",
    "    axes[1, 0].plot(df['epoch'], df['metrics/precision(B)'], label='Precision', linewidth=2, color='purple')\n",
    "    axes[1, 0].plot(df['epoch'], df['metrics/recall(B)'], label='Recall', linewidth=2, color='orange')\n",
    "    axes[1, 0].set_xlabel('Epoch')\n",
    "    axes[1, 0].set_ylabel('Score')\n",
    "    axes[1, 0].set_title('Precision and Recall')\n",
    "    axes[1, 0].legend()\n",
    "    axes[1, 0].grid(True, alpha=0.3)\n",
    "    \n",
    "    # Plot 4: Learning rate\n",
    "    if 'lr/pg0' in df.columns:\n",
    "        axes[1, 1].plot(df['epoch'], df['lr/pg0'], linewidth=2, color='red')\n",
    "        axes[1, 1].set_xlabel('Epoch')\n",
    "        axes[1, 1].set_ylabel('Learning Rate')\n",
    "        axes[1, 1].set_title('Learning Rate Schedule')\n",
    "        axes[1, 1].grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Print final metrics\n",
    "    print(\"\\nüìà Final Training Metrics:\")\n",
    "    print(f\"  mAP@0.5: {df['metrics/mAP50(B)'].iloc[-1]:.3f}\")\n",
    "    print(f\"  mAP@0.5:0.95: {df['metrics/mAP50-95(B)'].iloc[-1]:.3f}\")\n",
    "    print(f\"  Precision: {df['metrics/precision(B)'].iloc[-1]:.3f}\")\n",
    "    print(f\"  Recall: {df['metrics/recall(B)'].iloc[-1]:.3f}\")\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è Results CSV not found. Train the model first.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 7: Evaluate on Validation Set\n",
    "\n",
    "Let's evaluate the trained model on the validation set to measure performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the best trained model\n",
    "best_model = YOLO('yolo_training/exp/weights/best.pt')\n",
    "\n",
    "print(\"üîç Evaluating model on validation set...\\n\")\n",
    "\n",
    "# Run validation\n",
    "metrics = best_model.val()\n",
    "\n",
    "# Display metrics\n",
    "print(\"\\nüìä Validation Metrics:\")\n",
    "print(f\"  mAP@0.5: {metrics.box.map50:.3f}\")\n",
    "print(f\"  mAP@0.5:0.95: {metrics.box.map:.3f}\")\n",
    "print(f\"  Precision: {metrics.box.p:.3f}\")\n",
    "print(f\"  Recall: {metrics.box.r:.3f}\")\n",
    "print(f\"\\n  Per-class mAP@0.5:\")\n",
    "for i, class_map in enumerate(metrics.box.ap50):\n",
    "    print(f\"    Class {i}: {class_map:.3f}\")\n",
    "\n",
    "# Interpretation guide\n",
    "print(\"\\nüìö Metrics Interpretation:\")\n",
    "print(\"  mAP@0.5 > 0.5: Good detection performance\")\n",
    "print(\"  mAP@0.5 > 0.7: Excellent detection performance\")\n",
    "print(\"  mAP@0.5:0.95 > 0.3: Good localization accuracy\")\n",
    "print(\"  Precision: % of correct detections (avoid false positives)\")\n",
    "print(\"  Recall: % of objects detected (avoid missing objects)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 8: Test Trained Model on New Images\n",
    "\n",
    "Let's compare the trained model with the pre-trained model on test images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download a test image or use your own\n",
    "import urllib.request\n",
    "\n",
    "test_image_url = 'https://ultralytics.com/images/bus.jpg'\n",
    "test_image_path = 'test_image.jpg'\n",
    "\n",
    "urllib.request.urlretrieve(test_image_url, test_image_path)\n",
    "\n",
    "# Run inference with both models\n",
    "print(\"üîç Running inference...\\n\")\n",
    "\n",
    "# Pre-trained model\n",
    "pretrained_results = model(test_image_path)\n",
    "\n",
    "# Fine-tuned model\n",
    "finetuned_results = best_model(test_image_path)\n",
    "\n",
    "# Visualize results side-by-side\n",
    "fig, axes = plt.subplots(1, 2, figsize=(15, 7))\n",
    "\n",
    "# Plot pre-trained results\n",
    "pretrained_img = pretrained_results[0].plot()\n",
    "axes[0].imshow(pretrained_img)\n",
    "axes[0].set_title('Pre-trained YOLOv8n (COCO)', fontsize=14, fontweight='bold')\n",
    "axes[0].axis('off')\n",
    "\n",
    "# Plot fine-tuned results\n",
    "finetuned_img = finetuned_results[0].plot()\n",
    "axes[1].imshow(finetuned_img)\n",
    "axes[1].set_title('Fine-tuned YOLOv8n (Custom)', fontsize=14, fontweight='bold')\n",
    "axes[1].axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nüìä Detection Comparison:\")\n",
    "print(f\"  Pre-trained detections: {len(pretrained_results[0].boxes)}\")\n",
    "print(f\"  Fine-tuned detections: {len(finetuned_results[0].boxes)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 9: Save and Export Model\n",
    "\n",
    "Export the trained model for deployment in various formats."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export model to different formats\n",
    "print(\"üì¶ Exporting model...\\n\")\n",
    "\n",
    "# Export to ONNX (for cross-platform deployment)\n",
    "onnx_path = best_model.export(format='onnx')\n",
    "print(f\"‚úÖ ONNX model: {onnx_path}\")\n",
    "\n",
    "# Other export formats:\n",
    "# - 'torchscript': PyTorch TorchScript\n",
    "# - 'coreml': Apple CoreML (iOS)\n",
    "# - 'tflite': TensorFlow Lite (mobile)\n",
    "# - 'pb': TensorFlow SavedModel\n",
    "# - 'engine': TensorRT (NVIDIA)\n",
    "\n",
    "# Example: Export to TensorFlow Lite for mobile deployment\n",
    "# tflite_path = best_model.export(format='tflite')\n",
    "# print(f\"‚úÖ TFLite model: {tflite_path}\")\n",
    "\n",
    "print(\"\\nüìÅ Model files saved:\")\n",
    "print(f\"  PyTorch (.pt): yolo_training/exp/weights/best.pt\")\n",
    "print(f\"  ONNX (.onnx): {onnx_path}\")\n",
    "print(\"\\nüöÄ Models ready for deployment!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 10: Overfitting Check\n",
    "\n",
    "Compare training and validation metrics to detect overfitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Overfitting analysis\n",
    "if results_csv.exists():\n",
    "    df = pd.read_csv(results_csv)\n",
    "    df.columns = df.columns.str.strip()\n",
    "    \n",
    "    # Plot train vs validation loss\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(15, 5))\n",
    "    \n",
    "    # Total loss comparison\n",
    "    train_loss = df['train/box_loss'] + df['train/cls_loss'] + df['train/dfl_loss']\n",
    "    val_loss = df['val/box_loss'] + df['val/cls_loss'] + df['val/dfl_loss']\n",
    "    \n",
    "    axes[0].plot(df['epoch'], train_loss, label='Train Loss', linewidth=2)\n",
    "    axes[0].plot(df['epoch'], val_loss, label='Val Loss', linewidth=2)\n",
    "    axes[0].set_xlabel('Epoch')\n",
    "    axes[0].set_ylabel('Total Loss')\n",
    "    axes[0].set_title('Train vs Validation Loss')\n",
    "    axes[0].legend()\n",
    "    axes[0].grid(True, alpha=0.3)\n",
    "    \n",
    "    # Gap analysis\n",
    "    loss_gap = val_loss - train_loss\n",
    "    axes[1].plot(df['epoch'], loss_gap, linewidth=2, color='red')\n",
    "    axes[1].axhline(y=0, color='black', linestyle='--', alpha=0.5)\n",
    "    axes[1].set_xlabel('Epoch')\n",
    "    axes[1].set_ylabel('Loss Gap (Val - Train)')\n",
    "    axes[1].set_title('Overfitting Indicator')\n",
    "    axes[1].grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Overfitting diagnosis\n",
    "    final_gap = loss_gap.iloc[-1]\n",
    "    print(\"\\nüîç Overfitting Analysis:\")\n",
    "    if final_gap < 0.1:\n",
    "        print(\"  ‚úÖ No overfitting detected (gap < 0.1)\")\n",
    "        print(\"  ‚Üí Model generalizes well\")\n",
    "    elif final_gap < 0.3:\n",
    "        print(\"  ‚ö†Ô∏è Slight overfitting (gap 0.1-0.3)\")\n",
    "        print(\"  ‚Üí Consider: Early stopping, data augmentation\")\n",
    "    else:\n",
    "        print(\"  ‚ùå Significant overfitting (gap > 0.3)\")\n",
    "        print(\"  ‚Üí Solutions:\")\n",
    "        print(\"    1. Reduce epochs (early stopping)\")\n",
    "        print(\"    2. Increase data augmentation\")\n",
    "        print(\"    3. Add dropout/regularization\")\n",
    "        print(\"    4. Collect more training data\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 11: Hyperparameter Tuning Tips\n",
    "\n",
    "### Common Issues and Solutions:\n",
    "\n",
    "#### 1. Low mAP (<0.3)\n",
    "**Solutions:**\n",
    "- ‚úÖ Increase epochs (50 ‚Üí 100)\n",
    "- ‚úÖ Improve data quality (better annotations)\n",
    "- ‚úÖ Balance dataset (equal samples per class)\n",
    "- ‚úÖ Try larger model (yolov8n ‚Üí yolov8s)\n",
    "\n",
    "#### 2. Out of Memory (OOM)\n",
    "**Solutions:**\n",
    "- ‚úÖ Reduce batch size (16 ‚Üí 8 ‚Üí 4)\n",
    "- ‚úÖ Reduce image size (640 ‚Üí 480)\n",
    "- ‚úÖ Use smaller model (yolov8s ‚Üí yolov8n)\n",
    "- ‚úÖ Reduce workers (8 ‚Üí 4 ‚Üí 2)\n",
    "\n",
    "#### 3. Slow Training\n",
    "**Solutions:**\n",
    "- ‚úÖ Use GPU instead of CPU\n",
    "- ‚úÖ Increase batch size (if memory allows)\n",
    "- ‚úÖ Use smaller model (yolov8m ‚Üí yolov8n)\n",
    "- ‚úÖ Reduce image size (1280 ‚Üí 640)\n",
    "\n",
    "#### 4. Overfitting\n",
    "**Solutions:**\n",
    "- ‚úÖ Early stopping (patience=10)\n",
    "- ‚úÖ Data augmentation (built-in YOLO augmentation)\n",
    "- ‚úÖ Reduce epochs\n",
    "- ‚úÖ Collect more training data\n",
    "\n",
    "### Recommended Hyperparameters:\n",
    "\n",
    "| Scenario | Model | Epochs | Batch | Image Size |\n",
    "|----------|-------|--------|-------|------------|\n",
    "| Quick test | yolov8n | 20 | 16 | 640 |\n",
    "| Small dataset (<500 images) | yolov8n | 50 | 16 | 640 |\n",
    "| Medium dataset (500-5000) | yolov8s | 100 | 16 | 640 |\n",
    "| Large dataset (>5000) | yolov8m | 150 | 32 | 640 |\n",
    "| High accuracy needed | yolov8l | 200 | 16 | 1280 |\n",
    "| Mobile deployment | yolov8n | 100 | 16 | 320 |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 12: Common Training Issues\n",
    "\n",
    "### Troubleshooting Guide:\n",
    "\n",
    "```python\n",
    "# Issue 1: CUDA Out of Memory\n",
    "# Error: RuntimeError: CUDA out of memory\n",
    "# Solution:\n",
    "training_config['batch'] = 8  # Reduce from 16\n",
    "training_config['workers'] = 2  # Reduce from 4\n",
    "\n",
    "# Issue 2: Poor mAP (<0.3)\n",
    "# Solution:\n",
    "training_config['epochs'] = 100  # Increase from 50\n",
    "model = YOLO('yolov8s.pt')  # Use larger model\n",
    "\n",
    "# Issue 3: Slow training on CPU\n",
    "# Solution:\n",
    "training_config['device'] = 'cpu'\n",
    "training_config['batch'] = 4  # Smaller batch\n",
    "training_config['epochs'] = 20  # Fewer epochs for testing\n",
    "\n",
    "# Issue 4: Dataset not found\n",
    "# Solution: Check data.yaml path\n",
    "import os\n",
    "yaml_path = training_config['data']\n",
    "print(f\"YAML exists: {os.path.exists(yaml_path)}\")\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise: Train on Your Own Dataset\n",
    "\n",
    "### Task:\n",
    "1. Prepare your own dataset using Roboflow or LabelImg\n",
    "2. Create `data.yaml` with your class names\n",
    "3. Train YOLOv8 for 50 epochs\n",
    "4. Evaluate and export the model\n",
    "\n",
    "### Dataset Requirements:\n",
    "- ‚úÖ At least 100 images per class\n",
    "- ‚úÖ 80% train, 20% validation split\n",
    "- ‚úÖ YOLO format annotations (.txt)\n",
    "- ‚úÖ Balanced class distribution\n",
    "\n",
    "### Steps:\n",
    "```python\n",
    "# 1. Update data.yaml path\n",
    "training_config['data'] = 'path/to/your/data.yaml'\n",
    "\n",
    "# 2. Train model\n",
    "results = model.train(**training_config)\n",
    "\n",
    "# 3. Evaluate\n",
    "metrics = model.val()\n",
    "print(f\"mAP@0.5: {metrics.box.map50}\")\n",
    "\n",
    "# 4. Export\n",
    "model.export(format='onnx')\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exercise workspace - Train your own model here\n",
    "\n",
    "# TODO: Update with your dataset path\n",
    "my_dataset_path = 'path/to/your/dataset/data.yaml'\n",
    "\n",
    "# TODO: Configure training parameters\n",
    "my_config = {\n",
    "    'data': my_dataset_path,\n",
    "    'epochs': 50,\n",
    "    'imgsz': 640,\n",
    "    'batch': 16,\n",
    "    'device': 0 if torch.cuda.is_available() else 'cpu',\n",
    "}\n",
    "\n",
    "# TODO: Train your model\n",
    "# my_model = YOLO('yolov8n.pt')\n",
    "# my_results = my_model.train(**my_config)\n",
    "\n",
    "print(\"‚úèÔ∏è Complete the exercise above with your own dataset!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "### What We Learned:\n",
    "1. ‚úÖ **Model Selection**: Choosing appropriate YOLOv8 variant (nano to extra-large)\n",
    "2. ‚úÖ **Training Configuration**: Understanding epochs, batch size, learning rate, patience\n",
    "3. ‚úÖ **Training Process**: Running training, monitoring progress with TensorBoard\n",
    "4. ‚úÖ **Evaluation Metrics**: Interpreting mAP, precision, recall, loss curves\n",
    "5. ‚úÖ **Overfitting Detection**: Analyzing train vs validation performance\n",
    "6. ‚úÖ **Model Export**: Deploying models in ONNX, TFLite, TorchScript formats\n",
    "7. ‚úÖ **Troubleshooting**: Solving common training issues (OOM, slow training, low mAP)\n",
    "\n",
    "### Key Takeaways:\n",
    "- **Start small**: Use YOLOv8n for quick iterations, then scale up\n",
    "- **Monitor metrics**: Watch mAP@0.5 (target >0.5) and loss curves\n",
    "- **Early stopping**: Use patience=10-20 to prevent overfitting\n",
    "- **GPU acceleration**: Training on GPU is 10-50√ó faster than CPU\n",
    "- **Data quality**: Better annotations ‚Üí better model performance\n",
    "\n",
    "### Performance Benchmarks:\n",
    "- **mAP@0.5 > 0.5**: Good detection performance\n",
    "- **mAP@0.5 > 0.7**: Excellent detection performance\n",
    "- **mAP@0.5:0.95 > 0.3**: Good localization accuracy\n",
    "\n",
    "### Next Steps:\n",
    "1. **Notebook 05**: Explore SSD architecture and implementation\n",
    "2. **Notebook 06**: Compare YOLO vs SSD for different use cases\n",
    "3. **Practice**: Train on your own custom dataset with real-world images\n",
    "\n",
    "---\n",
    "\n",
    "**Congratulations! You can now train custom YOLO models for object detection! üéâ**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
