{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# YOLOv8 Pretrained Detection\n",
    "\n",
    "**Week 14 - Module 5: Object Detection Models**\n",
    "\n",
    "**Estimated Time:** 20 minutes\n",
    "\n",
    "## Learning Objectives\n",
    "- Use YOLOv8 for real-time object detection\n",
    "- Detect objects in images and videos\n",
    "- Understand confidence and NMS thresholds\n",
    "- Compare different YOLO model sizes\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup and Installation\n",
    "\n",
    "We'll use the **Ultralytics** library, which provides a clean, modern interface for YOLOv8.\n",
    "\n",
    "### Installation\n",
    "```bash\n",
    "pip install ultralytics\n",
    "```\n",
    "\n",
    "### What's Included?\n",
    "- Pretrained models (YOLOv8n, YOLOv8s, YOLOv8m, YOLOv8l, YOLOv8x)\n",
    "- Easy-to-use API\n",
    "- Built-in visualization\n",
    "- Support for images, videos, and webcam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install ultralytics (if not already installed)\n",
    "!pip install -q ultralytics opencv-python matplotlib pillow\n",
    "\n",
    "# Import libraries\n",
    "from ultralytics import YOLO\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import urllib.request\n",
    "import time\n",
    "\n",
    "print(\"‚úÖ Setup complete!\")\n",
    "print(f\"OpenCV version: {cv2.__version__}\")\n",
    "print(f\"NumPy version: {np.__version__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Load YOLOv8 Model\n",
    "\n",
    "### Available Model Sizes\n",
    "\n",
    "| Model | Parameters | Size | Speed | mAP |\n",
    "|-------|-----------|------|-------|-----|\n",
    "| YOLOv8n | 3.2M | 6.3 MB | Fastest | 37.3% |\n",
    "| YOLOv8s | 11.2M | 21.5 MB | Fast | 44.9% |\n",
    "| YOLOv8m | 25.9M | 49.7 MB | Medium | 50.2% |\n",
    "| YOLOv8l | 43.7M | 83.7 MB | Slow | 52.9% |\n",
    "| YOLOv8x | 68.2M | 130.5 MB | Slowest | 53.9% |\n",
    "\n",
    "**Recommendation**: Start with YOLOv8n (nano) for learning and prototyping."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load YOLOv8 nano model (smallest, fastest)\n",
    "model = YOLO('yolov8n.pt')\n",
    "\n",
    "print(\"‚úÖ Model loaded successfully!\")\n",
    "print(f\"\\nüìä Model Info:\")\n",
    "print(f\"Model type: YOLOv8n (Nano)\")\n",
    "print(f\"Number of classes: {len(model.names)}\")\n",
    "print(f\"\\nüè∑Ô∏è First 10 classes:\")\n",
    "for i, name in list(model.names.items())[:10]:\n",
    "    print(f\"  {i}: {name}\")\n",
    "\n",
    "print(\"\\n...and 70 more classes (trained on COCO dataset)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Single Image Detection\n",
    "\n",
    "Let's detect objects in a sample image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download sample image\n",
    "image_url = 'https://ultralytics.com/images/bus.jpg'\n",
    "urllib.request.urlretrieve(image_url, 'bus.jpg')\n",
    "\n",
    "# Load and display original image\n",
    "image = cv2.imread('bus.jpg')\n",
    "image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "plt.figure(figsize=(12, 8))\n",
    "plt.imshow(image_rgb)\n",
    "plt.title('Original Image', fontsize=16, fontweight='bold')\n",
    "plt.axis('off')\n",
    "plt.show()\n",
    "\n",
    "print(f\"Image shape: {image_rgb.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run detection\n",
    "print(\"Running YOLO detection...\")\n",
    "start_time = time.time()\n",
    "results = model(image_rgb, verbose=False)\n",
    "inference_time = (time.time() - start_time) * 1000  # Convert to ms\n",
    "\n",
    "print(f\"‚úÖ Detection complete in {inference_time:.2f} ms\")\n",
    "\n",
    "# Display results\n",
    "result_img = results[0].plot()\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(18, 8))\n",
    "\n",
    "axes[0].imshow(image_rgb)\n",
    "axes[0].set_title('Original Image', fontsize=14, fontweight='bold')\n",
    "axes[0].axis('off')\n",
    "\n",
    "axes[1].imshow(result_img)\n",
    "axes[1].set_title(f'YOLO Detections ({inference_time:.1f} ms)', fontsize=14, fontweight='bold')\n",
    "axes[1].axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Print detection details\n",
    "print(\"\\nüéØ Detection Details:\")\n",
    "print(\"=\"*80)\n",
    "print(f\"{'Class':<15} {'Confidence':<12} {'Bounding Box (x1, y1, x2, y2)':<40}\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "for box in results[0].boxes:\n",
    "    cls_id = int(box.cls[0])\n",
    "    conf = float(box.conf[0])\n",
    "    bbox = box.xyxy[0].cpu().numpy()\n",
    "    class_name = model.names[cls_id]\n",
    "    \n",
    "    print(f\"{class_name:<15} {conf:<12.3f} [{bbox[0]:>6.1f}, {bbox[1]:>6.1f}, {bbox[2]:>6.1f}, {bbox[3]:>6.1f}]\")\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(f\"Total detections: {len(results[0].boxes)}\")\n",
    "print(f\"Inference time: {inference_time:.2f} ms\")\n",
    "print(f\"FPS: {1000/inference_time:.1f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Batch Image Detection\n",
    "\n",
    "Process multiple images at once."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download multiple sample images\n",
    "image_urls = [\n",
    "    ('https://ultralytics.com/images/bus.jpg', 'bus.jpg'),\n",
    "    ('https://ultralytics.com/images/zidane.jpg', 'zidane.jpg'),\n",
    "]\n",
    "\n",
    "# Download images\n",
    "for url, filename in image_urls:\n",
    "    try:\n",
    "        urllib.request.urlretrieve(url, filename)\n",
    "        print(f\"‚úì Downloaded {filename}\")\n",
    "    except:\n",
    "        print(f\"‚úó Failed to download {filename}\")\n",
    "\n",
    "# Load images\n",
    "image_paths = ['bus.jpg', 'zidane.jpg']\n",
    "images = [cv2.cvtColor(cv2.imread(path), cv2.COLOR_BGR2RGB) for path in image_paths]\n",
    "\n",
    "# Run batch detection\n",
    "print(\"\\nRunning batch detection...\")\n",
    "results = model(images, verbose=False)\n",
    "\n",
    "# Display results in grid\n",
    "fig, axes = plt.subplots(2, 2, figsize=(16, 12))\n",
    "axes = axes.flatten()\n",
    "\n",
    "for idx, (img, result) in enumerate(zip(images, results)):\n",
    "    # Original image\n",
    "    axes[idx*2].imshow(img)\n",
    "    axes[idx*2].set_title(f'Original Image {idx+1}', fontsize=12, fontweight='bold')\n",
    "    axes[idx*2].axis('off')\n",
    "    \n",
    "    # Detection result\n",
    "    result_img = result.plot()\n",
    "    axes[idx*2 + 1].imshow(result_img)\n",
    "    axes[idx*2 + 1].set_title(f'Detections ({len(result.boxes)} objects)', fontsize=12, fontweight='bold')\n",
    "    axes[idx*2 + 1].axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Summary statistics\n",
    "print(\"\\nüìä Batch Detection Summary:\")\n",
    "print(\"=\"*60)\n",
    "for idx, result in enumerate(results):\n",
    "    unique_classes = set([model.names[int(box.cls[0])] for box in result.boxes])\n",
    "    print(f\"Image {idx+1}: {len(result.boxes)} detections - {', '.join(unique_classes)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Confidence Threshold Tuning\n",
    "\n",
    "The **confidence threshold** determines which detections to keep.\n",
    "\n",
    "- **High threshold (0.7-0.9)**: Only very confident detections (fewer false positives)\n",
    "- **Low threshold (0.1-0.3)**: More detections (more false positives)\n",
    "- **Default**: Usually 0.25-0.5\n",
    "\n",
    "Let's see the effect of different thresholds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test different confidence thresholds\n",
    "thresholds = [0.1, 0.3, 0.5, 0.7, 0.9]\n",
    "\n",
    "# Load image\n",
    "image = cv2.cvtColor(cv2.imread('bus.jpg'), cv2.COLOR_BGR2RGB)\n",
    "\n",
    "# Create subplot grid\n",
    "fig, axes = plt.subplots(2, 3, figsize=(18, 12))\n",
    "axes = axes.flatten()\n",
    "\n",
    "# Original image\n",
    "axes[0].imshow(image)\n",
    "axes[0].set_title('Original Image', fontsize=12, fontweight='bold')\n",
    "axes[0].axis('off')\n",
    "\n",
    "# Run detection with different thresholds\n",
    "for idx, threshold in enumerate(thresholds):\n",
    "    results = model(image, conf=threshold, verbose=False)\n",
    "    result_img = results[0].plot()\n",
    "    \n",
    "    axes[idx + 1].imshow(result_img)\n",
    "    axes[idx + 1].set_title(\n",
    "        f'Confidence ‚â• {threshold} ({len(results[0].boxes)} detections)',\n",
    "        fontsize=12, fontweight='bold'\n",
    "    )\n",
    "    axes[idx + 1].axis('off')\n",
    "\n",
    "plt.suptitle('Effect of Confidence Threshold on Detections', fontsize=16, fontweight='bold', y=1.02)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Print statistics\n",
    "print(\"\\nüìä Confidence Threshold Analysis:\")\n",
    "print(\"=\"*60)\n",
    "print(f\"{'Threshold':<12} {'Detections':<12} {'Change':<12}\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "prev_count = 0\n",
    "for threshold in thresholds:\n",
    "    results = model(image, conf=threshold, verbose=False)\n",
    "    count = len(results[0].boxes)\n",
    "    change = f\"{count - prev_count:+d}\" if prev_count > 0 else \"-\"\n",
    "    print(f\"{threshold:<12.1f} {count:<12} {change:<12}\")\n",
    "    prev_count = count\n",
    "\n",
    "print(\"\\nüí° Key Insight: Higher threshold = Fewer but more confident detections\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. NMS Threshold Tuning\n",
    "\n",
    "The **NMS (Non-Maximum Suppression) threshold** controls duplicate removal.\n",
    "\n",
    "- **High IoU threshold (0.7-0.9)**: Keep more overlapping boxes\n",
    "- **Low IoU threshold (0.3-0.5)**: Aggressive duplicate removal\n",
    "- **Default**: Usually 0.45-0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test different NMS thresholds\n",
    "nms_thresholds = [0.2, 0.45, 0.7]\n",
    "\n",
    "# Create subplot grid\n",
    "fig, axes = plt.subplots(1, 3, figsize=(18, 6))\n",
    "\n",
    "# Run detection with different NMS thresholds\n",
    "for idx, nms_thresh in enumerate(nms_thresholds):\n",
    "    results = model(image, iou=nms_thresh, conf=0.25, verbose=False)\n",
    "    result_img = results[0].plot()\n",
    "    \n",
    "    axes[idx].imshow(result_img)\n",
    "    axes[idx].set_title(\n",
    "        f'NMS IoU Threshold = {nms_thresh}\\n({len(results[0].boxes)} detections)',\n",
    "        fontsize=12, fontweight='bold'\n",
    "    )\n",
    "    axes[idx].axis('off')\n",
    "\n",
    "plt.suptitle('Effect of NMS Threshold on Duplicate Removal', fontsize=14, fontweight='bold', y=1.02)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nüí° NMS Threshold Guide:\")\n",
    "print(\"  ‚Ä¢ Low (0.2-0.3): Aggressive removal, fewer overlapping boxes\")\n",
    "print(\"  ‚Ä¢ Medium (0.45-0.5): Balanced (default)\")\n",
    "print(\"  ‚Ä¢ High (0.7-0.9): Keep more overlapping detections\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Model Size Comparison\n",
    "\n",
    "Compare YOLOv8n (nano), YOLOv8s (small), and YOLOv8m (medium) on the same image.\n",
    "\n",
    "**Trade-off**: Accuracy vs Speed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load different model sizes\n",
    "model_sizes = ['yolov8n.pt', 'yolov8s.pt']  # Start with 2 for speed\n",
    "models = {}\n",
    "\n",
    "print(\"Loading models...\")\n",
    "for model_name in model_sizes:\n",
    "    print(f\"  Loading {model_name}...\")\n",
    "    models[model_name] = YOLO(model_name)\n",
    "    print(f\"  ‚úì {model_name} loaded\")\n",
    "\n",
    "# Compare on same image\n",
    "image = cv2.cvtColor(cv2.imread('bus.jpg'), cv2.COLOR_BGR2RGB)\n",
    "\n",
    "# Run inference and measure time\n",
    "results_comparison = {}\n",
    "times = {}\n",
    "\n",
    "for model_name, model in models.items():\n",
    "    start = time.time()\n",
    "    result = model(image, verbose=False)\n",
    "    times[model_name] = (time.time() - start) * 1000  # ms\n",
    "    results_comparison[model_name] = result[0]\n",
    "\n",
    "# Visualize comparison\n",
    "fig, axes = plt.subplots(1, len(model_sizes), figsize=(9 * len(model_sizes), 8))\n",
    "if len(model_sizes) == 1:\n",
    "    axes = [axes]\n",
    "\n",
    "for idx, model_name in enumerate(model_sizes):\n",
    "    result_img = results_comparison[model_name].plot()\n",
    "    axes[idx].imshow(result_img)\n",
    "    \n",
    "    model_label = model_name.replace('.pt', '').replace('yolov8', 'YOLOv8-').upper()\n",
    "    axes[idx].set_title(\n",
    "        f'{model_label}\\n{times[model_name]:.1f} ms | {len(results_comparison[model_name].boxes)} detections',\n",
    "        fontsize=14, fontweight='bold'\n",
    "    )\n",
    "    axes[idx].axis('off')\n",
    "\n",
    "plt.suptitle('Model Size Comparison: Accuracy vs Speed', fontsize=16, fontweight='bold', y=0.98)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Print detailed comparison\n",
    "print(\"\\nüìä Model Comparison Summary:\")\n",
    "print(\"=\"*70)\n",
    "print(f\"{'Model':<15} {'Time (ms)':<12} {'FPS':<10} {'Detections':<12}\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "for model_name in model_sizes:\n",
    "    fps = 1000 / times[model_name]\n",
    "    detections = len(results_comparison[model_name].boxes)\n",
    "    model_label = model_name.replace('.pt', '')\n",
    "    print(f\"{model_label:<15} {times[model_name]:<12.2f} {fps:<10.1f} {detections:<12}\")\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\"\\nüí° Generally: Larger models are slower but more accurate\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Class-Specific Detection\n",
    "\n",
    "Sometimes you only want to detect specific classes (e.g., only people, only vehicles).\n",
    "\n",
    "This is useful for:\n",
    "- People counting\n",
    "- Vehicle detection in traffic\n",
    "- Specific object tracking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Detect only specific classes\n",
    "# COCO class IDs: 0=person, 2=car, 5=bus, 7=truck\n",
    "\n",
    "# Run full detection first\n",
    "results_full = model(image, verbose=False)\n",
    "\n",
    "# Filter to only people (class 0)\n",
    "results_people = model(image, classes=[0], verbose=False)  # Only person\n",
    "\n",
    "# Filter to only vehicles (car, bus, truck)\n",
    "results_vehicles = model(image, classes=[2, 5, 7], verbose=False)  # car, bus, truck\n",
    "\n",
    "# Visualize\n",
    "fig, axes = plt.subplots(1, 3, figsize=(18, 6))\n",
    "\n",
    "# All detections\n",
    "axes[0].imshow(results_full[0].plot())\n",
    "axes[0].set_title(f'All Classes\\n({len(results_full[0].boxes)} detections)', fontsize=12, fontweight='bold')\n",
    "axes[0].axis('off')\n",
    "\n",
    "# Only people\n",
    "axes[1].imshow(results_people[0].plot())\n",
    "axes[1].set_title(f'Only People\\n({len(results_people[0].boxes)} detections)', fontsize=12, fontweight='bold')\n",
    "axes[1].axis('off')\n",
    "\n",
    "# Only vehicles\n",
    "axes[2].imshow(results_vehicles[0].plot())\n",
    "axes[2].set_title(f'Only Vehicles\\n({len(results_vehicles[0].boxes)} detections)', fontsize=12, fontweight='bold')\n",
    "axes[2].axis('off')\n",
    "\n",
    "plt.suptitle('Class-Specific Detection', fontsize=14, fontweight='bold', y=1.02)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nüéØ Class Filtering Examples:\")\n",
    "print(\"  model(image, classes=[0])           # Only people\")\n",
    "print(\"  model(image, classes=[2, 5, 7])     # Only vehicles\")\n",
    "print(\"  model(image, classes=[16])          # Only dogs\")\n",
    "print(\"  model(image, classes=[0, 16, 17])   # People, dogs, cats\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Video Detection (Frame-by-Frame)\n",
    "\n",
    "YOLO can process videos frame by frame. Here's how to do it efficiently."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note: This is a demonstration. For actual video processing,\n",
    "# you would use model.predict(source='video.mp4', save=True)\n",
    "\n",
    "# Simulate video processing on multiple frames (using same image for demo)\n",
    "print(\"Simulating video processing...\\n\")\n",
    "\n",
    "num_frames = 10\n",
    "total_time = 0\n",
    "total_detections = 0\n",
    "\n",
    "for frame_idx in range(num_frames):\n",
    "    start = time.time()\n",
    "    results = model(image, verbose=False)\n",
    "    frame_time = (time.time() - start) * 1000\n",
    "    \n",
    "    total_time += frame_time\n",
    "    total_detections += len(results[0].boxes)\n",
    "    \n",
    "    if frame_idx % 3 == 0:\n",
    "        print(f\"Frame {frame_idx+1:2d}: {frame_time:6.2f} ms | {len(results[0].boxes)} objects\")\n",
    "\n",
    "avg_time = total_time / num_frames\n",
    "avg_fps = 1000 / avg_time\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(f\"Average inference time: {avg_time:.2f} ms/frame\")\n",
    "print(f\"Average FPS: {avg_fps:.1f}\")\n",
    "print(f\"Total detections: {total_detections}\")\n",
    "print(f\"Average detections per frame: {total_detections/num_frames:.1f}\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "print(\"\\nüí° For real video processing, use:\")\n",
    "print(\"   results = model.predict(source='video.mp4', save=True)\")\n",
    "print(\"   This will process and save the output video automatically.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Webcam Detection (Code Template)\n",
    "\n",
    "For real-time webcam detection, use this code locally (not in Jupyter)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Webcam detection template (run locally, not in Jupyter)\n",
    "\n",
    "webcam_code = '''\n",
    "from ultralytics import YOLO\n",
    "import cv2\n",
    "\n",
    "# Load model\n",
    "model = YOLO('yolov8n.pt')\n",
    "\n",
    "# Open webcam\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "print(\"Press 'q' to quit\")\n",
    "\n",
    "while True:\n",
    "    # Read frame\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "    \n",
    "    # Run detection\n",
    "    results = model(frame, verbose=False)\n",
    "    \n",
    "    # Display results\n",
    "    annotated_frame = results[0].plot()\n",
    "    cv2.imshow('YOLOv8 Webcam', annotated_frame)\n",
    "    \n",
    "    # Exit on 'q'\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n",
    "'''\n",
    "\n",
    "print(\"üìπ Webcam Detection Code:\")\n",
    "print(\"=\"*60)\n",
    "print(webcam_code)\n",
    "print(\"=\"*60)\n",
    "print(\"\\nüí° Save this as 'webcam_detection.py' and run locally!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11. Custom Visualization\n",
    "\n",
    "Create custom visualizations with specific colors and labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom visualization function\n",
    "def custom_plot(image, results, model_names):\n",
    "    \"\"\"\n",
    "    Create custom visualization with class-specific colors\n",
    "    \"\"\"\n",
    "    img = image.copy()\n",
    "    \n",
    "    # Define colors for different classes (BGR format for cv2)\n",
    "    class_colors = {\n",
    "        'person': (0, 255, 0),      # Green\n",
    "        'car': (255, 0, 0),         # Blue\n",
    "        'bus': (0, 0, 255),         # Red\n",
    "        'truck': (255, 255, 0),     # Cyan\n",
    "    }\n",
    "    \n",
    "    for box in results.boxes:\n",
    "        # Get box coordinates\n",
    "        x1, y1, x2, y2 = box.xyxy[0].cpu().numpy().astype(int)\n",
    "        \n",
    "        # Get class info\n",
    "        cls_id = int(box.cls[0])\n",
    "        conf = float(box.conf[0])\n",
    "        class_name = model_names[cls_id]\n",
    "        \n",
    "        # Get color (default to yellow if class not in dict)\n",
    "        color = class_colors.get(class_name, (0, 255, 255))\n",
    "        \n",
    "        # Draw box\n",
    "        cv2.rectangle(img, (x1, y1), (x2, y2), color, 3)\n",
    "        \n",
    "        # Prepare label\n",
    "        label = f\"{class_name} {conf:.2f}\"\n",
    "        \n",
    "        # Draw label background\n",
    "        (label_w, label_h), _ = cv2.getTextSize(label, cv2.FONT_HERSHEY_SIMPLEX, 0.8, 2)\n",
    "        cv2.rectangle(img, (x1, y1 - label_h - 10), (x1 + label_w, y1), color, -1)\n",
    "        \n",
    "        # Draw label text\n",
    "        cv2.putText(img, label, (x1, y1 - 5), cv2.FONT_HERSHEY_SIMPLEX, 0.8, (255, 255, 255), 2)\n",
    "    \n",
    "    return img\n",
    "\n",
    "# Apply custom visualization\n",
    "results = model(image, verbose=False)\n",
    "custom_img = custom_plot(cv2.cvtColor(image, cv2.COLOR_RGB2BGR), results[0], model.names)\n",
    "custom_img = cv2.cvtColor(custom_img, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "# Compare default vs custom\n",
    "fig, axes = plt.subplots(1, 2, figsize=(16, 6))\n",
    "\n",
    "axes[0].imshow(results[0].plot())\n",
    "axes[0].set_title('Default YOLO Visualization', fontsize=14, fontweight='bold')\n",
    "axes[0].axis('off')\n",
    "\n",
    "axes[1].imshow(custom_img)\n",
    "axes[1].set_title('Custom Visualization (Class-Specific Colors)', fontsize=14, fontweight='bold')\n",
    "axes[1].axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nüé® Custom Colors:\")\n",
    "print(\"  ‚Ä¢ Person: Green\")\n",
    "print(\"  ‚Ä¢ Car: Blue\")\n",
    "print(\"  ‚Ä¢ Bus: Red\")\n",
    "print(\"  ‚Ä¢ Truck: Cyan\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 12. Detection Statistics\n",
    "\n",
    "Analyze detection results with statistics and visualizations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run detection\n",
    "results = model(image, verbose=False)[0]\n",
    "\n",
    "# Count objects by class\n",
    "class_counts = {}\n",
    "confidence_scores = {}\n",
    "\n",
    "for box in results.boxes:\n",
    "    cls_id = int(box.cls[0])\n",
    "    conf = float(box.conf[0])\n",
    "    class_name = model.names[cls_id]\n",
    "    \n",
    "    if class_name not in class_counts:\n",
    "        class_counts[class_name] = 0\n",
    "        confidence_scores[class_name] = []\n",
    "    \n",
    "    class_counts[class_name] += 1\n",
    "    confidence_scores[class_name].append(conf)\n",
    "\n",
    "# Create visualizations\n",
    "fig, axes = plt.subplots(1, 2, figsize=(16, 5))\n",
    "\n",
    "# Bar chart of object counts\n",
    "classes = list(class_counts.keys())\n",
    "counts = list(class_counts.values())\n",
    "colors_bar = ['#FF6B6B', '#4ECDC4', '#45B7D1', '#FFA07A', '#98D8C8']\n",
    "\n",
    "bars = axes[0].bar(classes, counts, color=colors_bar[:len(classes)])\n",
    "axes[0].set_xlabel('Object Class', fontsize=12, fontweight='bold')\n",
    "axes[0].set_ylabel('Count', fontsize=12, fontweight='bold')\n",
    "axes[0].set_title('Object Detection Counts', fontsize=14, fontweight='bold')\n",
    "axes[0].grid(axis='y', alpha=0.3)\n",
    "\n",
    "# Add count labels on bars\n",
    "for bar in bars:\n",
    "    height = bar.get_height()\n",
    "    axes[0].text(bar.get_x() + bar.get_width()/2., height,\n",
    "                f'{int(height)}',\n",
    "                ha='center', va='bottom', fontweight='bold')\n",
    "\n",
    "# Box plot of confidence scores\n",
    "conf_data = [confidence_scores[cls] for cls in classes]\n",
    "bp = axes[1].boxplot(conf_data, labels=classes, patch_artist=True)\n",
    "\n",
    "# Color the boxes\n",
    "for patch, color in zip(bp['boxes'], colors_bar[:len(classes)]):\n",
    "    patch.set_facecolor(color)\n",
    "    patch.set_alpha(0.7)\n",
    "\n",
    "axes[1].set_xlabel('Object Class', fontsize=12, fontweight='bold')\n",
    "axes[1].set_ylabel('Confidence Score', fontsize=12, fontweight='bold')\n",
    "axes[1].set_title('Confidence Score Distribution', fontsize=14, fontweight='bold')\n",
    "axes[1].grid(axis='y', alpha=0.3)\n",
    "axes[1].set_ylim([0, 1])\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Print detailed statistics\n",
    "print(\"\\nüìä Detection Statistics:\")\n",
    "print(\"=\"*70)\n",
    "print(f\"{'Class':<15} {'Count':<8} {'Avg Conf':<12} {'Min Conf':<12} {'Max Conf':<12}\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "for class_name in classes:\n",
    "    count = class_counts[class_name]\n",
    "    confs = confidence_scores[class_name]\n",
    "    avg_conf = np.mean(confs)\n",
    "    min_conf = np.min(confs)\n",
    "    max_conf = np.max(confs)\n",
    "    \n",
    "    print(f\"{class_name:<15} {count:<8} {avg_conf:<12.3f} {min_conf:<12.3f} {max_conf:<12.3f}\")\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(f\"Total detections: {len(results.boxes)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 13. Exercise: Apply to Your Own Images\n",
    "\n",
    "Now it's your turn! Try these exercises:\n",
    "\n",
    "### Exercise 1: Basic Detection\n",
    "1. Upload or download your own image\n",
    "2. Run YOLOv8 detection on it\n",
    "3. Print the number and types of objects detected\n",
    "\n",
    "### Exercise 2: Threshold Tuning\n",
    "1. Take an image with multiple objects\n",
    "2. Test confidence thresholds from 0.1 to 0.9\n",
    "3. Find the optimal threshold for your use case\n",
    "\n",
    "### Exercise 3: Class-Specific Detection\n",
    "1. Choose a specific class you're interested in (e.g., \"person\", \"car\")\n",
    "2. Filter detections to show only that class\n",
    "3. Count how many instances were found\n",
    "\n",
    "### Exercise 4: Model Comparison\n",
    "1. Download YOLOv8n, YOLOv8s, and YOLOv8m\n",
    "2. Run all three on the same image\n",
    "3. Compare accuracy, speed, and detection quality\n",
    "\n",
    "### Starter Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exercise starter code\n",
    "\n",
    "# TODO: Load your image\n",
    "# my_image = cv2.imread('path/to/your/image.jpg')\n",
    "# my_image = cv2.cvtColor(my_image, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "# TODO: Run detection\n",
    "# results = model(my_image)\n",
    "\n",
    "# TODO: Display results\n",
    "# plt.figure(figsize=(12, 8))\n",
    "# plt.imshow(results[0].plot())\n",
    "# plt.axis('off')\n",
    "# plt.show()\n",
    "\n",
    "# TODO: Print statistics\n",
    "# print(f\"Total detections: {len(results[0].boxes)}\")\n",
    "\n",
    "print(\"‚úèÔ∏è Complete the TODOs above to apply YOLO to your own images!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 14. Summary\n",
    "\n",
    "### What We Learned\n",
    "\n",
    "‚úÖ **Setup**: Install and use Ultralytics YOLOv8\n",
    "\n",
    "‚úÖ **Basic Detection**: Detect objects in images\n",
    "\n",
    "‚úÖ **Batch Processing**: Process multiple images efficiently\n",
    "\n",
    "‚úÖ **Threshold Tuning**: Adjust confidence and NMS thresholds\n",
    "\n",
    "‚úÖ **Model Comparison**: Trade-off between speed and accuracy\n",
    "\n",
    "‚úÖ **Class Filtering**: Detect only specific object types\n",
    "\n",
    "‚úÖ **Video Processing**: Apply YOLO to video streams\n",
    "\n",
    "‚úÖ **Custom Visualization**: Create custom detection displays\n",
    "\n",
    "‚úÖ **Statistics**: Analyze detection results\n",
    "\n",
    "### Key Takeaways\n",
    "\n",
    "1. **YOLOv8 is powerful yet easy to use** - Just a few lines of code!\n",
    "2. **Model size matters** - Choose based on your speed/accuracy needs\n",
    "3. **Thresholds are important** - Tune them for your application\n",
    "4. **Real-time is achievable** - Even on modest hardware\n",
    "\n",
    "### Best Practices\n",
    "\n",
    "- **Start with YOLOv8n** for prototyping\n",
    "- **Tune thresholds** on your specific data\n",
    "- **Use class filtering** when you know what you're looking for\n",
    "- **Monitor FPS** for real-time applications\n",
    "- **Consider model size** based on deployment constraints\n",
    "\n",
    "### Preview: Notebook 03 - Custom Dataset Preparation\n",
    "\n",
    "In the next notebook, we'll learn:\n",
    "- YOLO dataset format\n",
    "- How to prepare custom datasets\n",
    "- Annotation tools and workflows\n",
    "- Data splitting strategies\n",
    "- Ready for fine-tuning YOLO on your data!\n",
    "\n",
    "---\n",
    "\n",
    "**Next: Prepare your own dataset for training!** üéØ"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
