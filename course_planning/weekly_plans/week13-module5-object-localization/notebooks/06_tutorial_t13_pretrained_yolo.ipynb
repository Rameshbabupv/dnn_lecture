{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 06: Tutorial T13 - Object Detection with Pre-trained YOLO\n",
    "\n",
    "## Learning Objectives\n",
    "By the end of this tutorial, you will be able to:\n",
    "- Use YOLOv8 pre-trained model for object detection\n",
    "- Detect objects in images with bounding boxes\n",
    "- Visualize detection results with confidence scores\n",
    "- Understand how confidence thresholds affect detections\n",
    "- Apply object detection to real-world images\n",
    "\n",
    "**Estimated Time:** 15-20 minutes  \n",
    "**Note:** This is a PREVIEW of Week 14! You'll get hands-on experience with YOLO before learning the theory.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What is YOLO?\n",
    "\n",
    "### YOLO = You Only Look Once\n",
    "\n",
    "**Key Features:**\n",
    "- **Real-time object detection** - Can process 30+ frames per second\n",
    "- **Single CNN forward pass** - Unlike two-stage detectors (R-CNN)\n",
    "- **80 object classes** - Trained on COCO dataset (Common Objects in Context)\n",
    "- **State-of-the-art accuracy** - Excellent balance of speed and accuracy\n",
    "\n",
    "### YOLO Evolution\n",
    "- **YOLOv1 (2016):** Original paper \"You Only Look Once\"\n",
    "- **YOLOv3 (2018):** Multi-scale predictions\n",
    "- **YOLOv5 (2020):** PyTorch implementation\n",
    "- **YOLOv8 (2023):** Latest - fastest and most accurate!\n",
    "\n",
    "### Real-World Applications\n",
    "- Autonomous driving (detecting pedestrians, vehicles)\n",
    "- Surveillance systems (security monitoring)\n",
    "- Retail analytics (customer tracking, product detection)\n",
    "- Sports analysis (player tracking)\n",
    "- Medical imaging (tumor detection)\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup and Installation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install Ultralytics YOLOv8 (official implementation)\n",
    "!pip install -q ultralytics\n",
    "\n",
    "# Import required libraries\n",
    "from ultralytics import YOLO\n",
    "import cv2\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "import requests\n",
    "from io import BytesIO\n",
    "\n",
    "print(\"Libraries imported successfully!\")\n",
    "print(\"Ready to start object detection!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Pre-trained Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load YOLOv8 nano model (smallest, fastest)\n",
    "# Model options (size vs accuracy tradeoff):\n",
    "#   - yolov8n.pt (nano)   - Fastest, smallest\n",
    "#   - yolov8s.pt (small)  - Good balance\n",
    "#   - yolov8m.pt (medium) - More accurate\n",
    "#   - yolov8l.pt (large)  - Very accurate\n",
    "#   - yolov8x.pt (xlarge) - Most accurate, slowest\n",
    "\n",
    "model = YOLO('yolov8n.pt')  # Will auto-download (~6MB) on first run\n",
    "\n",
    "print(\"\\nModel loaded successfully!\")\n",
    "print(f\"Total classes: {len(model.names)}\")\n",
    "print(f\"\\nSample classes: {list(model.names.values())[:10]}\")\n",
    "print(\"\\nModel is ready for detection!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Image 1 - Simple Scene\n",
    "\n",
    "Let's start with a simple image and detect objects!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download a sample image from the web\n",
    "# Using a street scene with people and vehicles\n",
    "url = \"https://ultralytics.com/images/bus.jpg\"\n",
    "response = requests.get(url)\n",
    "img = Image.open(BytesIO(response.content))\n",
    "img.save(\"test_image1.jpg\")\n",
    "\n",
    "# Display original image\n",
    "plt.figure(figsize=(12, 8))\n",
    "plt.imshow(img)\n",
    "plt.axis('off')\n",
    "plt.title(\"Original Image\")\n",
    "plt.show()\n",
    "\n",
    "# Run YOLO detection\n",
    "results = model(\"test_image1.jpg\")\n",
    "\n",
    "# Display results with bounding boxes\n",
    "results[0].show()  # Auto-displays with boxes + labels\n",
    "\n",
    "# Print detection details\n",
    "print(\"\\nDetection Results:\")\n",
    "print(\"-\" * 50)\n",
    "for i, box in enumerate(results[0].boxes):\n",
    "    class_id = int(box.cls)\n",
    "    class_name = model.names[class_id]\n",
    "    confidence = float(box.conf)\n",
    "    print(f\"{i+1}. Class: {class_name:15s} | Confidence: {confidence:.2%}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Understanding the Output\n",
    "\n",
    "### Each Detection Contains:\n",
    "\n",
    "1. **Class Label** (e.g., \"person\", \"car\", \"dog\")\n",
    "   - One of 80 COCO classes\n",
    "   - Predicted by the neural network\n",
    "\n",
    "2. **Bounding Box Coordinates** `[x1, y1, x2, y2]`\n",
    "   - `(x1, y1)` = Top-left corner\n",
    "   - `(x2, y2)` = Bottom-right corner\n",
    "   - Coordinates in pixels\n",
    "\n",
    "3. **Confidence Score** `[0.0 - 1.0]`\n",
    "   - How certain the model is about this detection\n",
    "   - 0.0 = 0% confident, 1.0 = 100% confident\n",
    "   - Default threshold: 0.25 (25%)\n",
    "\n",
    "### Visualizations Show:\n",
    "- **Colored boxes** - Different color for each object class\n",
    "- **Labels** - Class name + confidence percentage\n",
    "- **Filtering** - Only shows detections above confidence threshold\n",
    "\n",
    "### How It Works:\n",
    "1. Image is resized to 640×640 (YOLO input size)\n",
    "2. Single forward pass through CNN\n",
    "3. Model outputs: class probabilities + box coordinates\n",
    "4. Non-maximum suppression removes duplicate boxes\n",
    "5. Results filtered by confidence threshold\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Image 2 - Complex Scene\n",
    "\n",
    "Now let's try a more challenging image with multiple objects!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download a crowded street scene\n",
    "url2 = \"https://ultralytics.com/images/zidane.jpg\"\n",
    "response2 = requests.get(url2)\n",
    "img2 = Image.open(BytesIO(response2.content))\n",
    "img2.save(\"test_image2.jpg\")\n",
    "\n",
    "# Run detection with higher confidence threshold\n",
    "results2 = model(\"test_image2.jpg\", conf=0.5)  # Only show detections ≥ 50% confidence\n",
    "\n",
    "# Show results\n",
    "results2[0].show()\n",
    "\n",
    "# Count objects by class\n",
    "classes = [model.names[int(box.cls)] for box in results2[0].boxes]\n",
    "counts = Counter(classes)\n",
    "\n",
    "print(\"\\nObject Count Summary:\")\n",
    "print(\"-\" * 50)\n",
    "for obj_class, count in counts.items():\n",
    "    print(f\"{obj_class:15s}: {count}\")\n",
    "print(\"-\" * 50)\n",
    "print(f\"Total objects detected: {len(results2[0].boxes)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Custom Visualization Function\n",
    "\n",
    "Let's create our own visualization with better control!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_detections(results, image_path):\n",
    "    \"\"\"\n",
    "    Custom visualization with better formatting\n",
    "    \n",
    "    Args:\n",
    "        results: YOLO detection results\n",
    "        image_path: Path to original image\n",
    "    \"\"\"\n",
    "    # Load original image\n",
    "    img = cv2.imread(image_path)\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    \n",
    "    # Define colors for different classes (BGR format)\n",
    "    colors = [\n",
    "        (0, 255, 0),    # Green\n",
    "        (255, 0, 0),    # Red\n",
    "        (0, 0, 255),    # Blue\n",
    "        (255, 255, 0),  # Cyan\n",
    "        (255, 0, 255),  # Magenta\n",
    "        (0, 255, 255),  # Yellow\n",
    "    ]\n",
    "    \n",
    "    # Draw boxes and labels\n",
    "    for i, box in enumerate(results[0].boxes):\n",
    "        # Extract box coordinates\n",
    "        x1, y1, x2, y2 = map(int, box.xyxy[0])\n",
    "        \n",
    "        # Get class and confidence\n",
    "        cls = int(box.cls)\n",
    "        conf = float(box.conf)\n",
    "        label = f\"{model.names[cls]}: {conf:.2%}\"\n",
    "        \n",
    "        # Choose color based on class\n",
    "        color = colors[cls % len(colors)]\n",
    "        \n",
    "        # Draw bounding box\n",
    "        cv2.rectangle(img, (x1, y1), (x2, y2), color, 2)\n",
    "        \n",
    "        # Draw label background\n",
    "        (text_width, text_height), _ = cv2.getTextSize(\n",
    "            label, cv2.FONT_HERSHEY_SIMPLEX, 0.6, 2\n",
    "        )\n",
    "        cv2.rectangle(\n",
    "            img, (x1, y1 - text_height - 10), \n",
    "            (x1 + text_width, y1), color, -1\n",
    "        )\n",
    "        \n",
    "        # Draw label text\n",
    "        cv2.putText(\n",
    "            img, label, (x1, y1 - 5), \n",
    "            cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255, 255, 255), 2\n",
    "        )\n",
    "    \n",
    "    # Display with matplotlib\n",
    "    plt.figure(figsize=(14, 10))\n",
    "    plt.imshow(img)\n",
    "    plt.axis('off')\n",
    "    plt.title(f\"Detected {len(results[0].boxes)} objects\", fontsize=16, fontweight='bold')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Test custom visualization\n",
    "print(\"Testing custom visualization...\\n\")\n",
    "visualize_detections(results2, \"test_image2.jpg\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Batch Processing\n",
    "\n",
    "Detect objects in multiple images at once!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download multiple test images\n",
    "image_urls = [\n",
    "    \"https://ultralytics.com/images/bus.jpg\",\n",
    "    \"https://ultralytics.com/images/zidane.jpg\",\n",
    "]\n",
    "\n",
    "image_paths = []\n",
    "for i, url in enumerate(image_urls):\n",
    "    response = requests.get(url)\n",
    "    img = Image.open(BytesIO(response.content))\n",
    "    path = f\"batch_image_{i+1}.jpg\"\n",
    "    img.save(path)\n",
    "    image_paths.append(path)\n",
    "\n",
    "# Batch detection\n",
    "print(\"Running batch detection...\\n\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "for i, img_path in enumerate(image_paths):\n",
    "    results = model(img_path, verbose=False)\n",
    "    num_objects = len(results[0].boxes)\n",
    "    \n",
    "    print(f\"\\nImage {i+1}: {img_path}\")\n",
    "    print(f\"Objects detected: {num_objects}\")\n",
    "    \n",
    "    # Show class distribution\n",
    "    classes = [model.names[int(box.cls)] for box in results[0].boxes]\n",
    "    counts = Counter(classes)\n",
    "    print(f\"Classes found: {dict(counts)}\")\n",
    "    \n",
    "    # Display results\n",
    "    results[0].show()\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"Batch processing complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Webcam Detection (Optional)\n",
    "\n",
    "Real-time object detection from webcam!  \n",
    "**Note:** This works better in local Jupyter notebook, not Google Colab."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Real-time detection from webcam\n",
    "# Uncomment the code below to run (works in local environment)\n",
    "\n",
    "\"\"\"\n",
    "import cv2\n",
    "\n",
    "# Open webcam\n",
    "cap = cv2.VideoCapture(0)  # 0 = default webcam\n",
    "\n",
    "print(\"Starting webcam detection...\")\n",
    "print(\"Press 'q' to quit\")\n",
    "\n",
    "while True:\n",
    "    # Read frame from webcam\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        print(\"Failed to grab frame\")\n",
    "        break\n",
    "    \n",
    "    # Run YOLO detection\n",
    "    results = model(frame, verbose=False)\n",
    "    \n",
    "    # Draw results on frame\n",
    "    annotated_frame = results[0].plot()\n",
    "    \n",
    "    # Display frame\n",
    "    cv2.imshow('YOLO Real-time Detection', annotated_frame)\n",
    "    \n",
    "    # Press 'q' to quit\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "# Cleanup\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n",
    "print(\"Webcam detection stopped\")\n",
    "\"\"\"\n",
    "\n",
    "print(\"Webcam detection code provided above.\")\n",
    "print(\"Uncomment and run in local Jupyter environment.\")\n",
    "print(\"\\nFor Colab users: Upload images or use URLs instead.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Available Classes\n",
    "\n",
    "Let's see all 80 object classes that YOLOv8 can detect!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display all 80 COCO classes\n",
    "print(\"YOLOv8 Pre-trained Model - 80 COCO Classes\")\n",
    "print(\"=\" * 60)\n",
    "print(\"\\nPeople & Animals:\")\n",
    "print(\"-\" * 60)\n",
    "\n",
    "# Organize classes by category\n",
    "categories = {\n",
    "    \"People & Animals\": [0, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23],\n",
    "    \"Vehicles\": [1, 2, 3, 4, 5, 6, 7, 8],\n",
    "    \"Outdoor Objects\": [9, 10, 11, 12, 13],\n",
    "    \"Sports Equipment\": [32, 33, 34, 35, 36, 37, 38],\n",
    "    \"Kitchen & Dining\": [39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50],\n",
    "    \"Furniture & Electronics\": [56, 57, 58, 59, 60, 61, 62, 63],\n",
    "    \"Food\": [46, 47, 48, 49, 50, 51, 52, 53, 54, 55],\n",
    "    \"Accessories\": [24, 25, 26, 27, 28, 29, 30, 31],\n",
    "    \"Indoor Objects\": [64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79]\n",
    "}\n",
    "\n",
    "# Print all classes organized by category\n",
    "for category, class_ids in categories.items():\n",
    "    print(f\"\\n{category}:\")\n",
    "    print(\"-\" * 60)\n",
    "    for idx in class_ids:\n",
    "        if idx in model.names:\n",
    "            print(f\"  {idx:2d}: {model.names[idx]}\")\n",
    "\n",
    "# Print complete list\n",
    "print(\"\\n\\nComplete List (All 80 Classes):\")\n",
    "print(\"=\" * 60)\n",
    "for idx in range(len(model.names)):\n",
    "    name = model.names[idx]\n",
    "    # Print in columns\n",
    "    if idx % 4 == 0:\n",
    "        print()\n",
    "    print(f\"{idx:2d}: {name:15s}\", end=\"  \")\n",
    "\n",
    "print(\"\\n\\n\" + \"=\" * 60)\n",
    "print(f\"Total: {len(model.names)} classes\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercises\n",
    "\n",
    "### TODO Exercise 1: Upload Your Own Image\n",
    "Upload an image from your computer and detect objects in it.\n",
    "\n",
    "```python\n",
    "# For Google Colab:\n",
    "from google.colab import files\n",
    "uploaded = files.upload()\n",
    "# Then run detection on uploaded image\n",
    "```\n",
    "\n",
    "### TODO Exercise 2: Confidence Threshold Experiment\n",
    "Try different confidence thresholds (0.1, 0.5, 0.9) on the same image.  \n",
    "**Question:** What changes? Why does a lower threshold show more detections?\n",
    "\n",
    "### TODO Exercise 3: Count Specific Objects\n",
    "Find a crowded photo (e.g., stadium, concert, street) and count how many \"person\" objects are detected.  \n",
    "**Challenge:** Can you find an image with 10+ people?\n",
    "\n",
    "### TODO Exercise 4: Diverse Detection\n",
    "Find or create an image that has at least 5 different object classes detected.  \n",
    "**Hint:** Try a kitchen scene, park, or busy street.\n",
    "\n",
    "### Bonus Challenge:\n",
    "Modify the `visualize_detections()` function to:\n",
    "- Show only detections of a specific class (e.g., only \"person\")\n",
    "- Draw boxes in different colors based on confidence score\n",
    "- Add a legend showing all detected classes\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Confidence Threshold Experiment\n",
    "\n",
    "Let's visualize how confidence threshold affects detection results!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test different confidence thresholds\n",
    "thresholds = [0.25, 0.5, 0.75, 0.9]\n",
    "test_image = \"test_image1.jpg\"\n",
    "\n",
    "print(\"Running confidence threshold experiment...\\n\")\n",
    "\n",
    "# Create figure with subplots\n",
    "fig, axes = plt.subplots(2, 2, figsize=(16, 14))\n",
    "axes = axes.flatten()\n",
    "\n",
    "for i, conf in enumerate(thresholds):\n",
    "    # Run detection with specific confidence threshold\n",
    "    results = model(test_image, conf=conf, verbose=False)\n",
    "    \n",
    "    # Get annotated image\n",
    "    img_annotated = results[0].plot()\n",
    "    img_rgb = cv2.cvtColor(img_annotated, cv2.COLOR_BGR2RGB)\n",
    "    \n",
    "    # Display in subplot\n",
    "    axes[i].imshow(img_rgb)\n",
    "    axes[i].set_title(\n",
    "        f\"Confidence ≥ {conf:.0%} ({len(results[0].boxes)} detections)\",\n",
    "        fontsize=14, fontweight='bold'\n",
    "    )\n",
    "    axes[i].axis('off')\n",
    "    \n",
    "    # Print summary\n",
    "    print(f\"Confidence ≥ {conf:.0%}: {len(results[0].boxes)} objects detected\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nObservations:\")\n",
    "print(\"- Lower threshold → More detections (including less certain ones)\")\n",
    "print(\"- Higher threshold → Fewer detections (only high-confidence ones)\")\n",
    "print(\"- Default 0.25 is a good balance for most applications\")\n",
    "print(\"- Adjust based on your use case (precision vs recall tradeoff)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What's Next?\n",
    "\n",
    "### This Week (Week 13): Fundamentals\n",
    "You learned the **theoretical foundations**:\n",
    "- **IoU (Intersection over Union)** - How to measure box overlap\n",
    "- **mAP (mean Average Precision)** - How to evaluate detector performance\n",
    "- **Precision vs Recall** - Tradeoffs in detection\n",
    "- **Confidence scores** - How detectors express certainty\n",
    "\n",
    "### Week 14: YOLO Architecture Deep Dive\n",
    "You'll learn **HOW YOLO works internally**:\n",
    "- **Grid-based detection** - How image is divided into cells\n",
    "- **Anchor boxes** - Predefined box shapes for different objects\n",
    "- **Multi-scale predictions** - Detecting objects at different sizes\n",
    "- **Loss function** - How YOLO learns (localization + classification + objectness)\n",
    "- **Training on custom dataset** - Fine-tuning for your specific objects\n",
    "- **YOLO variants** - YOLOv3, YOLOv5, YOLOv8 evolution\n",
    "\n",
    "### Week 15: Alternative Approaches\n",
    "You'll learn about **R-CNN family**:\n",
    "- **R-CNN** - Region-based CNN (two-stage detector)\n",
    "- **Fast R-CNN** - Improved speed with RoI pooling\n",
    "- **Faster R-CNN** - Region Proposal Network (RPN)\n",
    "- **Mask R-CNN** - Instance segmentation\n",
    "- **Comparison** - YOLO vs R-CNN (speed vs accuracy)\n",
    "- **When to use which** - Application-specific choices\n",
    "\n",
    "### Progression:\n",
    "```\n",
    "Week 13: Evaluation Metrics (IoU, mAP)\n",
    "    ↓\n",
    "Week 14: YOLO Architecture (How it works)\n",
    "    ↓\n",
    "Week 15: R-CNN Family (Alternative approach)\n",
    "```\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "### Key Takeaways:\n",
    "\n",
    "1. **YOLOv8 is Fast and Accurate**\n",
    "   - Real-time performance (30+ FPS)\n",
    "   - State-of-the-art accuracy on COCO dataset\n",
    "   - Single forward pass through network\n",
    "\n",
    "2. **Pre-trained Models Work Out-of-the-Box**\n",
    "   - No training required for 80 COCO classes\n",
    "   - Download model once, use everywhere\n",
    "   - Multiple model sizes (nano to xlarge)\n",
    "\n",
    "3. **80 Object Classes Supported**\n",
    "   - People, animals, vehicles, sports equipment\n",
    "   - Kitchen items, furniture, electronics\n",
    "   - Food, accessories, outdoor objects\n",
    "\n",
    "4. **Confidence Threshold Controls Detections**\n",
    "   - Lower threshold → More detections (less precise)\n",
    "   - Higher threshold → Fewer detections (more precise)\n",
    "   - Default 0.25 works well for most cases\n",
    "   - Adjust based on precision/recall needs\n",
    "\n",
    "5. **Real-World Applications**\n",
    "   - **Autonomous Driving** - Pedestrian and vehicle detection\n",
    "   - **Surveillance** - Security monitoring and alerts\n",
    "   - **Retail Analytics** - Customer tracking, product recognition\n",
    "   - **Sports Analysis** - Player tracking and performance\n",
    "   - **Medical Imaging** - Tumor and anomaly detection\n",
    "\n",
    "### What You Can Do Now:\n",
    "- Detect objects in any image\n",
    "- Understand confidence scores\n",
    "- Adjust detection parameters\n",
    "- Count and classify objects\n",
    "- Visualize results with bounding boxes\n",
    "\n",
    "### Next Steps:\n",
    "1. **Try on Your Own Images**\n",
    "   - Upload personal photos\n",
    "   - Test on different scenes (indoor, outdoor, crowded)\n",
    "   - Experiment with various object types\n",
    "\n",
    "2. **Experiment with Different Models**\n",
    "   - Try YOLOv8s (small) for better accuracy\n",
    "   - Try YOLOv8m (medium) for even better results\n",
    "   - Compare speed vs accuracy tradeoffs\n",
    "\n",
    "3. **Explore Advanced Features**\n",
    "   - Tracking objects across video frames\n",
    "   - Custom class training (Week 14!)\n",
    "   - Multi-camera setups\n",
    "\n",
    "4. **Preview Week 14 Materials**\n",
    "   - Read about YOLO architecture\n",
    "   - Understand grid-based detection\n",
    "   - Learn about anchor boxes\n",
    "\n",
    "### Resources:\n",
    "- **Official Documentation:** https://docs.ultralytics.com/\n",
    "- **YOLO Paper:** https://arxiv.org/abs/1506.02640\n",
    "- **COCO Dataset:** https://cocodataset.org/\n",
    "- **GitHub:** https://github.com/ultralytics/ultralytics\n",
    "\n",
    "### Congratulations!\n",
    "You've successfully completed Tutorial T13! You can now:\n",
    "- Use pre-trained YOLO models\n",
    "- Detect and visualize objects\n",
    "- Understand detection outputs\n",
    "- Apply object detection to real problems\n",
    "\n",
    "**You're ready for Week 14's deep dive into YOLO architecture!**\n",
    "\n",
    "---\n",
    "\n",
    "*Tutorial T13 - Object Detection with Pre-trained YOLO*  \n",
    "*Course: Deep Neural Network Architectures (21CSE558T)*  \n",
    "*Week 13 - Module 5: Object Detection*"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
