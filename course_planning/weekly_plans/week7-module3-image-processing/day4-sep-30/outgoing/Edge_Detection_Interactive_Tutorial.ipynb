{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Edge Detection - The Visual Boundary Intelligence\n",
    "\n",
    "**Course:** 21CSE558T - Deep Neural Network Architectures  \n",
    "**Week 7, Day 4** | **Module 3:** Image Processing & DNNs  \n",
    "**Instructor:** Prof. Ramesh Babu | **Date:** September 30, 2025\n",
    "\n",
    "---\n",
    "\n",
    "## üéØ Learning Path Overview\n",
    "\n",
    "This interactive notebook takes you from basic concepts to advanced edge detection techniques:\n",
    "\n",
    "1. **Setup** ‚Üí Get libraries and test images ready\n",
    "2. **Computer's Challenge** ‚Üí Show the pixel problem (numbers vs boundaries)\n",
    "3. **Gradients (Captain Mike)** ‚Üí Build intuition from 1D to 2D, manual to Sobel\n",
    "4. **Canny Protocol** ‚Üí 4-stage systematic approach with visual proof\n",
    "5. **Advanced (Laplacian)** ‚Üí Second derivatives and when to use them\n",
    "6. **Multi-Scale** ‚Üí Image pyramids for robust detection\n",
    "7. **Real Applications** ‚Üí Medical, automotive, manufacturing with code\n",
    "8. **Interactive Challenges** ‚Üí Students experiment and compete\n",
    "9. **CNN Bridge** ‚Üí Connect manual filters to deep learning\n",
    "10. **Assessment Prep** ‚Üí Unit Test 2 study guide\n",
    "11. **Summary** ‚Üí Key takeaways and Tutorial T7 assignment\n",
    "\n",
    "---\n",
    "\n",
    "## üí° Key Learning Objectives\n",
    "\n",
    "By the end of this notebook, you will:\n",
    "\n",
    "‚úÖ Understand **why edge detection matters** for computer vision  \n",
    "‚úÖ Master **gradient concepts** through intuitive analogies  \n",
    "‚úÖ Implement **Sobel and Canny edge detectors** in OpenCV  \n",
    "‚úÖ Compare **different edge detection methods** and know when to use each  \n",
    "‚úÖ Apply edge detection to **real-world problems**  \n",
    "‚úÖ Bridge classical edge detection to **modern deep learning (CNNs)**  \n",
    "\n",
    "---\n",
    "\n",
    "## üö® Course Context\n",
    "\n",
    "**Where We Are:** Week 7 of 15 (47% through course)  \n",
    "**Module Progress:** Transitioning from neural network foundations ‚Üí computer vision applications  \n",
    "**Next Assessment:** Unit Test 2 (October 31) - Modules 3 & 4  \n",
    "**Connection to Future:** This prepares you for CNNs (Week 10) and Object Detection (Week 13)  \n",
    "\n",
    "---\n",
    "\n",
    "**Let's begin our journey into teaching computers to see boundaries!** üîç"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# SECTION 0: Setup & Environment Preparation\n",
    "\n",
    "Let's get everything ready for our edge detection investigation!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cell 0.1: Import Essential Libraries\n",
    "\n",
    "We'll need:\n",
    "- **OpenCV (cv2):** For image processing and edge detection\n",
    "- **NumPy:** For numerical operations and array manipulation\n",
    "- **Matplotlib:** For visualizing our results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import essential libraries\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.gridspec import GridSpec\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Configure matplotlib for better visualizations\n",
    "plt.rcParams['figure.figsize'] = (15, 5)\n",
    "plt.rcParams['font.size'] = 10\n",
    "%matplotlib inline\n",
    "\n",
    "print(\"‚úÖ Libraries imported successfully!\")\n",
    "print(f\"üì¶ OpenCV Version: {cv2.__version__}\")\n",
    "print(f\"üì¶ NumPy Version: {np.__version__}\")\n",
    "print(\"\\nüéâ Ready to start edge detection!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cell 0.2: Helper Visualization Functions\n",
    "\n",
    "Let's create useful functions to display our results beautifully!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_comparison(images, titles, cmaps=None, figsize=(15, 5)):\n",
    "    \"\"\"\n",
    "    Display multiple images side-by-side for comparison\n",
    "    \n",
    "    Parameters:\n",
    "    - images: List of images to display\n",
    "    - titles: List of titles for each image\n",
    "    - cmaps: List of colormaps (default: 'gray' for all)\n",
    "    - figsize: Figure size tuple\n",
    "    \"\"\"\n",
    "    n = len(images)\n",
    "    if cmaps is None:\n",
    "        cmaps = ['gray'] * n\n",
    "    \n",
    "    fig, axes = plt.subplots(1, n, figsize=figsize)\n",
    "    if n == 1:\n",
    "        axes = [axes]\n",
    "    \n",
    "    for i, (img, title, cmap) in enumerate(zip(images, titles, cmaps)):\n",
    "        axes[i].imshow(img, cmap=cmap)\n",
    "        axes[i].set_title(title, fontsize=12, fontweight='bold')\n",
    "        axes[i].axis('off')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def show_gradient_analysis(image, gx, gy, magnitude):\n",
    "    \"\"\"\n",
    "    Display complete gradient analysis in a 2x2 grid\n",
    "    \"\"\"\n",
    "    fig, axes = plt.subplots(2, 2, figsize=(12, 10))\n",
    "    \n",
    "    # Original image\n",
    "    axes[0, 0].imshow(image, cmap='gray')\n",
    "    axes[0, 0].set_title('Original Image', fontsize=12, fontweight='bold')\n",
    "    axes[0, 0].axis('off')\n",
    "    \n",
    "    # Gradient X (vertical edges)\n",
    "    axes[0, 1].imshow(np.abs(gx), cmap='hot')\n",
    "    axes[0, 1].set_title('Gradient X (Vertical Edges)', fontsize=12, fontweight='bold')\n",
    "    axes[0, 1].axis('off')\n",
    "    \n",
    "    # Gradient Y (horizontal edges)\n",
    "    axes[1, 0].imshow(np.abs(gy), cmap='hot')\n",
    "    axes[1, 0].set_title('Gradient Y (Horizontal Edges)', fontsize=12, fontweight='bold')\n",
    "    axes[1, 0].axis('off')\n",
    "    \n",
    "    # Combined magnitude\n",
    "    axes[1, 1].imshow(magnitude, cmap='hot')\n",
    "    axes[1, 1].set_title('Combined Magnitude (All Edges)', fontsize=12, fontweight='bold')\n",
    "    axes[1, 1].axis('off')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def print_section_header(section_num, title):\n",
    "    \"\"\"\n",
    "    Print a nice section header\n",
    "    \"\"\"\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(f\"SECTION {section_num}: {title}\")\n",
    "    print(\"=\"*80 + \"\\n\")\n",
    "\n",
    "\n",
    "print(\"‚úÖ Visualization helper functions created!\")\n",
    "print(\"üìä Functions available:\")\n",
    "print(\"   - show_comparison(): Display multiple images side-by-side\")\n",
    "print(\"   - show_gradient_analysis(): Show complete gradient breakdown\")\n",
    "print(\"   - print_section_header(): Format section titles nicely\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cell 0.3: Create Test Images\n",
    "\n",
    "We'll create several test images with different characteristics:  \n",
    "- **Simple shapes** (easy to understand)\n",
    "- **Geometric patterns** (clear boundaries)\n",
    "- **Real-world scenarios** (complex edges)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_simple_square():\n",
    "    \"\"\"Create a simple white square on black background - Detective Sarah's first case!\"\"\"\n",
    "    image = np.zeros((200, 200), dtype=np.uint8)\n",
    "    image[50:150, 50:150] = 255\n",
    "    return image\n",
    "\n",
    "\n",
    "def create_circle_image():\n",
    "    \"\"\"Create a white circle on black background\"\"\"\n",
    "    image = np.zeros((200, 200), dtype=np.uint8)\n",
    "    cv2.circle(image, (100, 100), 50, 255, -1)\n",
    "    return image\n",
    "\n",
    "\n",
    "def create_multi_shapes():\n",
    "    \"\"\"Create multiple shapes - more complex case\"\"\"\n",
    "    image = np.zeros((300, 400), dtype=np.uint8)\n",
    "    # Rectangle\n",
    "    cv2.rectangle(image, (50, 50), (150, 150), 255, -1)\n",
    "    # Circle\n",
    "    cv2.circle(image, (250, 100), 40, 255, -1)\n",
    "    # Triangle\n",
    "    pts = np.array([[150, 250], [100, 180], [200, 180]], np.int32)\n",
    "    cv2.fillPoly(image, [pts], 255)\n",
    "    return image\n",
    "\n",
    "\n",
    "def create_gradient_ramp():\n",
    "    \"\"\"Create a gradient for understanding intensity changes\"\"\"\n",
    "    image = np.zeros((200, 400), dtype=np.uint8)\n",
    "    for i in range(400):\n",
    "        intensity = int(255 * i / 400)\n",
    "        image[:, i] = intensity\n",
    "    return image\n",
    "\n",
    "\n",
    "def add_noise_to_image(image, noise_type='gaussian', intensity=25):\n",
    "    \"\"\"Add noise to an image to demonstrate noise handling\"\"\"\n",
    "    if noise_type == 'gaussian':\n",
    "        noise = np.random.normal(0, intensity, image.shape).astype(np.uint8)\n",
    "        noisy = cv2.add(image, noise)\n",
    "    elif noise_type == 'salt_pepper':\n",
    "        noisy = image.copy()\n",
    "        # Salt\n",
    "        num_salt = np.ceil(intensity * image.size * 0.01)\n",
    "        coords = [np.random.randint(0, i - 1, int(num_salt)) for i in image.shape]\n",
    "        noisy[coords[0], coords[1]] = 255\n",
    "        # Pepper\n",
    "        num_pepper = np.ceil(intensity * image.size * 0.01)\n",
    "        coords = [np.random.randint(0, i - 1, int(num_pepper)) for i in image.shape]\n",
    "        noisy[coords[0], coords[1]] = 0\n",
    "    return noisy\n",
    "\n",
    "\n",
    "# Create our test image library\n",
    "test_images = {\n",
    "    'simple_square': create_simple_square(),\n",
    "    'circle': create_circle_image(),\n",
    "    'multi_shapes': create_multi_shapes(),\n",
    "    'gradient_ramp': create_gradient_ramp(),\n",
    "}\n",
    "\n",
    "# Display our test library\n",
    "print(\"‚úÖ Test image library created!\\n\")\n",
    "print(\"üì∏ Available test images:\")\n",
    "for name, img in test_images.items():\n",
    "    print(f\"   - {name}: {img.shape[1]}x{img.shape[0]} pixels\")\n",
    "\n",
    "# Show the test images\n",
    "print(\"\\nüëÅÔ∏è  Preview of Test Images:\\n\")\n",
    "show_comparison(\n",
    "    [test_images['simple_square'], test_images['circle'], \n",
    "     test_images['multi_shapes'], test_images['gradient_ramp']],\n",
    "    ['Simple Square', 'Circle', 'Multiple Shapes', 'Gradient Ramp'],\n",
    "    figsize=(16, 4)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cell 0.4: Load Real-World Image (Optional)\n",
    "\n",
    "If you have your own image, load it here! Otherwise, we'll work with our synthetic test images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Option 1: Load your own image (update the path)\n",
    "# YOUR_IMAGE_PATH = 'path/to/your/image.jpg'\n",
    "# try:\n",
    "#     user_image = cv2.imread(YOUR_IMAGE_PATH, cv2.IMREAD_GRAYSCALE)\n",
    "#     if user_image is not None:\n",
    "#         test_images['user_image'] = user_image\n",
    "#         print(f\"‚úÖ Your image loaded: {user_image.shape[1]}x{user_image.shape[0]} pixels\")\n",
    "#         plt.figure(figsize=(8, 6))\n",
    "#         plt.imshow(user_image, cmap='gray')\n",
    "#         plt.title('Your Loaded Image')\n",
    "#         plt.axis('off')\n",
    "#         plt.show()\n",
    "#     else:\n",
    "#         print(\"‚ùå Could not load image. Check the path.\")\n",
    "# except:\n",
    "#     print(\"‚ùå Error loading image. Using test images instead.\")\n",
    "\n",
    "# Option 2: Use OpenCV sample images (if available)\n",
    "print(\"üìù To use your own image:\")\n",
    "print(\"   1. Uncomment the code above\")\n",
    "print(\"   2. Update YOUR_IMAGE_PATH with your image path\")\n",
    "print(\"   3. Run this cell again\")\n",
    "print(\"\\n‚úÖ For now, we'll use our test images to learn the concepts!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# SECTION 1: The Computer's Challenge - Seeing vs Understanding\n",
    "\n",
    "## üîç Detective Sarah's Story\n",
    "\n",
    "Imagine **Detective Sarah** arriving at a museum burglary. Her eyes instantly see:\n",
    "- Wall boundaries\n",
    "- Painting frames\n",
    "- Scattered objects\n",
    "- Evidence locations\n",
    "\n",
    "**Sarah's insight:** *\"I'm not looking AT objects - I'm looking at the BOUNDARIES between objects!\"*\n",
    "\n",
    "But computers? They see **just numbers**. Let's see the problem..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cell 1.1: What Computers Actually See"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_section_header(1, \"The Computer's Challenge\")\n",
    "\n",
    "# Take a small patch from our simple square\n",
    "image = test_images['simple_square']\n",
    "patch = image[45:55, 45:55]  # 10x10 patch across the edge\n",
    "\n",
    "print(\"üëÅÔ∏è  What WE see: A clear boundary between black and white\\n\")\n",
    "print(\"ü§ñ What the COMPUTER sees (raw pixel values):\\n\")\n",
    "print(patch)\n",
    "print(\"\\nüí° The Challenge: How do we teach the computer to find that boundary?\")\n",
    "print(\"   Answer: EDGE DETECTION! üéØ\")\n",
    "\n",
    "# Visualize the patch\n",
    "fig, axes = plt.subplots(1, 2, figsize=(10, 4))\n",
    "\n",
    "# Show the patch\n",
    "axes[0].imshow(patch, cmap='gray')\n",
    "axes[0].set_title('What We See: Clear Edge', fontsize=12, fontweight='bold')\n",
    "axes[0].axis('off')\n",
    "\n",
    "# Show as heatmap with values\n",
    "im = axes[1].imshow(patch, cmap='gray')\n",
    "axes[1].set_title('What Computer Sees: Numbers', fontsize=12, fontweight='bold')\n",
    "for i in range(patch.shape[0]):\n",
    "    for j in range(patch.shape[1]):\n",
    "        text = axes[1].text(j, i, int(patch[i, j]),\n",
    "                           ha=\"center\", va=\"center\", color=\"red\", fontsize=8)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cell 1.2: Pixel Intensity as a 3D Mountain\n",
    "\n",
    "**Captain Mike's Mountain Analogy:**  \n",
    "Think of pixel brightness as mountain height:\n",
    "- **Bright pixels** = High peaks ‚õ∞Ô∏è\n",
    "- **Dark pixels** = Deep valleys üèîÔ∏è\n",
    "- **Sudden changes** = Steep cliffs (EDGES!) üéØ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a 3D visualization of intensity as height\n",
    "image = test_images['simple_square']\n",
    "\n",
    "# Take a cross-section to visualize\n",
    "cross_section = image[100, :]  # Horizontal line through middle\n",
    "\n",
    "fig = plt.figure(figsize=(15, 5))\n",
    "\n",
    "# Original image\n",
    "ax1 = fig.add_subplot(131)\n",
    "ax1.imshow(image, cmap='gray')\n",
    "ax1.axhline(y=100, color='red', linestyle='--', linewidth=2, label='Cross-section line')\n",
    "ax1.set_title('Original Image\\n(Red line shows cross-section)', fontsize=12, fontweight='bold')\n",
    "ax1.legend()\n",
    "ax1.axis('off')\n",
    "\n",
    "# 1D intensity profile\n",
    "ax2 = fig.add_subplot(132)\n",
    "ax2.plot(cross_section, linewidth=2, color='blue')\n",
    "ax2.set_title('Intensity Profile\\n(Height represents brightness)', fontsize=12, fontweight='bold')\n",
    "ax2.set_xlabel('X Position (pixels)')\n",
    "ax2.set_ylabel('Intensity (0-255)')\n",
    "ax2.grid(True, alpha=0.3)\n",
    "ax2.axvline(x=50, color='red', linestyle='--', alpha=0.7, label='Left edge (cliff)')\n",
    "ax2.axvline(x=150, color='red', linestyle='--', alpha=0.7, label='Right edge (cliff)')\n",
    "ax2.legend()\n",
    "\n",
    "# 3D surface plot (small region for clarity)\n",
    "ax3 = fig.add_subplot(133, projection='3d')\n",
    "x = np.arange(0, 100, 1)\n",
    "y = np.arange(0, 100, 1)\n",
    "X, Y = np.meshgrid(x, y)\n",
    "Z = image[50:150, 50:150]\n",
    "\n",
    "surf = ax3.plot_surface(X, Y, Z, cmap='viridis', alpha=0.8)\n",
    "ax3.set_title('3D Mountain View\\n(Edges = Steep Cliffs)', fontsize=12, fontweight='bold')\n",
    "ax3.set_xlabel('X')\n",
    "ax3.set_ylabel('Y')\n",
    "ax3.set_zlabel('Intensity')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nüèîÔ∏è  Mountain Analogy Explained:\")\n",
    "print(\"   - Flat areas (black or white) = Gentle terrain (NO edges)\")\n",
    "print(\"   - Steep cliffs (sudden intensity change) = EDGES!\")\n",
    "print(\"   - Our goal: Find these 'cliffs' automatically\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cell 1.3: Real-World Applications - Why Edge Detection Matters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nüåç Real-World Applications of Edge Detection:\\n\")\n",
    "\n",
    "applications = [\n",
    "    (\"üè• Medical Imaging\", \"Finding tumor boundaries in X-rays and MRIs\"),\n",
    "    (\"üöó Autonomous Vehicles\", \"Detecting road edges and lane markings\"),\n",
    "    (\"üè≠ Manufacturing\", \"Quality control - finding defects and measuring parts\"),\n",
    "    (\"üë§ Face Recognition\", \"Identifying facial features and boundaries\"),\n",
    "    (\"üì± Document Scanning\", \"Detecting page edges for perspective correction\"),\n",
    "    (\"üéÆ Augmented Reality\", \"Tracking objects and overlaying digital content\"),\n",
    "    (\"üî¨ Microscopy\", \"Analyzing cell boundaries and structures\"),\n",
    "    (\"üõ∞Ô∏è Satellite Imagery\", \"Detecting roads, buildings, and geographic features\")\n",
    "]\n",
    "\n",
    "for i, (domain, application) in enumerate(applications, 1):\n",
    "    print(f\"{i}. {domain}\")\n",
    "    print(f\"   ‚Üí {application}\\n\")\n",
    "\n",
    "print(\"\\nüí° Key Insight: Edge detection is the FOUNDATION of computer vision!\")\n",
    "print(\"   Without edges, computers can't understand images.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cell 1.4: Detective's Toolkit Preview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nüïµÔ∏è Detective Sarah's Investigation Methods:\\n\")\n",
    "print(\"‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\")\n",
    "print(\"‚îÇ Method 1: THE QUICK SCAN (Sobel Method)                    ‚îÇ\")\n",
    "print(\"‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\")\n",
    "print(\"‚îÇ ‚Ä¢ Fast horizontal and vertical scans                        ‚îÇ\")\n",
    "print(\"‚îÇ ‚Ä¢ Good for simple cases                                     ‚îÇ\")\n",
    "print(\"‚îÇ ‚Ä¢ May miss subtle edges                                     ‚îÇ\")\n",
    "print(\"‚îÇ Speed: ‚ö°‚ö°‚ö° | Quality: ‚≠ê‚≠ê                              ‚îÇ\")\n",
    "print(\"‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\")\n",
    "print(\"\")\n",
    "print(\"‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\")\n",
    "print(\"‚îÇ Method 2: THE THOROUGH INVESTIGATION (Canny Method)         ‚îÇ\")\n",
    "print(\"‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\")\n",
    "print(\"‚îÇ ‚Ä¢ 4-stage systematic protocol                               ‚îÇ\")\n",
    "print(\"‚îÇ ‚Ä¢ Clean scene ‚Üí Find evidence ‚Üí Eliminate false leads      ‚îÇ\")\n",
    "print(\"‚îÇ ‚Ä¢ Connects related evidence                                 ‚îÇ\")\n",
    "print(\"‚îÇ Speed: ‚ö°‚ö° | Quality: ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê                         ‚îÇ\")\n",
    "print(\"‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\")\n",
    "print(\"\")\n",
    "print(\"‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\")\n",
    "print(\"‚îÇ Method 3: THE AERIAL VIEW (Laplacian Method)                ‚îÇ\")\n",
    "print(\"‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\")\n",
    "print(\"‚îÇ ‚Ä¢ Single-pass detection                                     ‚îÇ\")\n",
    "print(\"‚îÇ ‚Ä¢ Finds edges in all directions                             ‚îÇ\")\n",
    "print(\"‚îÇ ‚Ä¢ Sensitive to noise                                        ‚îÇ\")\n",
    "print(\"‚îÇ Speed: ‚ö°‚ö°‚ö° | Quality: ‚≠ê‚≠ê‚≠ê                            ‚îÇ\")\n",
    "print(\"‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\")\n",
    "print(\"\\nüìö We'll learn each method step-by-step in this notebook!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# SECTION 2: Captain Mike's Mountain Survey - Understanding Gradients\n",
    "\n",
    "## ‚õ∞Ô∏è The Mountain Rescue Story\n",
    "\n",
    "**Meet Captain Mike**, expert mountain rescue leader on Mount DataPeak.\n",
    "\n",
    "**The Problem:** Hikers lost in dense fog. Can't see cliffs directly.\n",
    "\n",
    "**Mike's Solution:** *\"In fog, you can't SEE the cliffs - but you can FEEL when the ground suddenly drops!\"*\n",
    "\n",
    "**Mike's Two-Team Strategy:**\n",
    "- **Team Alpha:** East-West scouts measure horizontal steepness\n",
    "- **Team Beta:** North-South scouts measure vertical steepness\n",
    "- **Combined Intel:** Complete danger map of all cliffs!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cell 2.1: Understanding Gradients - 1D Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_section_header(2, \"Understanding Gradients (Captain Mike's Mountain Survey)\")\n",
    "\n",
    "# Create a simple 1D intensity profile with a clear edge\n",
    "intensity_profile = np.array([30, 30, 30, 30, 50, 100, 180, 220, 220, 220, 220])\n",
    "positions = np.arange(len(intensity_profile))\n",
    "\n",
    "# Calculate gradient manually (difference between consecutive values)\n",
    "gradient_profile = np.diff(intensity_profile)\n",
    "\n",
    "fig, axes = plt.subplots(2, 1, figsize=(12, 8))\n",
    "\n",
    "# Plot intensity profile\n",
    "axes[0].plot(positions, intensity_profile, 'bo-', linewidth=2, markersize=8, label='Intensity')\n",
    "axes[0].set_title('1D Intensity Profile (Like Walking Along the Mountain)', \n",
    "                  fontsize=13, fontweight='bold')\n",
    "axes[0].set_xlabel('Position')\n",
    "axes[0].set_ylabel('Intensity (Brightness)')\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "axes[0].legend()\n",
    "axes[0].axvspan(4, 7, alpha=0.2, color='red', label='Edge region')\n",
    "\n",
    "# Plot gradient (steepness)\n",
    "axes[1].bar(positions[:-1], gradient_profile, color='red', alpha=0.7, label='Gradient (Steepness)')\n",
    "axes[1].axhline(y=0, color='black', linestyle='--', linewidth=1)\n",
    "axes[1].set_title('Gradient Profile (How Steep is the Slope?)', \n",
    "                  fontsize=13, fontweight='bold')\n",
    "axes[1].set_xlabel('Position')\n",
    "axes[1].set_ylabel('Gradient Value')\n",
    "axes[1].grid(True, alpha=0.3)\n",
    "axes[1].legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nüìä Gradient Analysis:\")\n",
    "print(f\"   Original values: {intensity_profile}\")\n",
    "print(f\"   Gradient values: {gradient_profile}\")\n",
    "print(\"\\nüí° Key Insight:\")\n",
    "print(\"   - Gradient = How much intensity CHANGES between adjacent pixels\")\n",
    "print(\"   - Large gradient = Steep slope = EDGE!\")\n",
    "print(\"   - Small gradient = Flat area = NO edge\")\n",
    "print(\"\\nüèîÔ∏è Mountain Analogy:\")\n",
    "print(\"   - Flat regions (positions 0-3, 7-10) ‚Üí Small gradient\")\n",
    "print(\"   - Steep cliff (positions 4-7) ‚Üí Large gradient = EDGE DETECTED!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cell 2.2: Manual Gradient Calculation\n",
    "\n",
    "Let's calculate gradients by hand to really understand what's happening!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Take a small region from our simple square image\n",
    "image = test_images['simple_square']\n",
    "\n",
    "# Extract a 5x5 region that crosses the edge\n",
    "row, col = 100, 48  # Position near the left edge\n",
    "region = image[row-2:row+3, col-2:col+3]\n",
    "\n",
    "print(\"üîç Let's manually calculate gradients for this 5x5 region:\\n\")\n",
    "print(\"Original pixel values:\")\n",
    "print(region)\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "\n",
    "# Calculate horizontal gradient (East-West: Team Alpha)\n",
    "center_pixel = region[2, 2]\n",
    "right_pixel = region[2, 3]\n",
    "left_pixel = region[2, 1]\n",
    "\n",
    "# Gradient = difference\n",
    "gradient_right = right_pixel - center_pixel\n",
    "gradient_left = center_pixel - left_pixel\n",
    "gradient_horizontal = (right_pixel - left_pixel) / 2  # Average of both directions\n",
    "\n",
    "print(\"\\nüßÆ Manual Horizontal Gradient Calculation:\")\n",
    "print(f\"   Center pixel value: {center_pixel}\")\n",
    "print(f\"   Right pixel value:  {right_pixel}\")\n",
    "print(f\"   Left pixel value:   {left_pixel}\")\n",
    "print(f\"   ‚Üí Right gradient:    {gradient_right}\")\n",
    "print(f\"   ‚Üí Left gradient:     {gradient_left}\")\n",
    "print(f\"   ‚Üí Horizontal gradient: {gradient_horizontal}\")\n",
    "\n",
    "# Calculate vertical gradient (North-South: Team Beta)\n",
    "top_pixel = region[1, 2]\n",
    "bottom_pixel = region[3, 2]\n",
    "gradient_vertical = (bottom_pixel - top_pixel) / 2\n",
    "\n",
    "print(\"\\nüßÆ Manual Vertical Gradient Calculation:\")\n",
    "print(f\"   Center pixel value: {center_pixel}\")\n",
    "print(f\"   Top pixel value:    {top_pixel}\")\n",
    "print(f\"   Bottom pixel value: {bottom_pixel}\")\n",
    "print(f\"   ‚Üí Vertical gradient: {gradient_vertical}\")\n",
    "\n",
    "# Calculate gradient magnitude\n",
    "gradient_magnitude = np.sqrt(gradient_horizontal**2 + gradient_vertical**2)\n",
    "\n",
    "print(\"\\nüìê Combined Gradient Magnitude:\")\n",
    "print(f\"   ‚àö(Horizontal¬≤ + Vertical¬≤) = ‚àö({gradient_horizontal}¬≤ + {gradient_vertical}¬≤)\")\n",
    "print(f\"   = {gradient_magnitude:.2f}\")\n",
    "\n",
    "print(\"\\nüí° Interpretation:\")\n",
    "if gradient_magnitude > 50:\n",
    "    print(\"   ‚úÖ STRONG EDGE DETECTED! (Large gradient magnitude)\")\n",
    "elif gradient_magnitude > 10:\n",
    "    print(\"   ‚ö†Ô∏è  Weak edge detected (Moderate gradient)\")\n",
    "else:\n",
    "    print(\"   ‚ùå No edge (Small gradient - flat region)\")\n",
    "\n",
    "# Visualize the region\n",
    "fig, ax = plt.subplots(1, 1, figsize=(6, 6))\n",
    "im = ax.imshow(region, cmap='gray', interpolation='nearest')\n",
    "ax.set_title('5x5 Region (Center = Red Square)', fontsize=12, fontweight='bold')\n",
    "\n",
    "# Annotate with values\n",
    "for i in range(region.shape[0]):\n",
    "    for j in range(region.shape[1]):\n",
    "        color = 'red' if (i == 2 and j == 2) else 'yellow'\n",
    "        weight = 'bold' if (i == 2 and j == 2) else 'normal'\n",
    "        text = ax.text(j, i, int(region[i, j]),\n",
    "                      ha=\"center\", va=\"center\", \n",
    "                      color=color, fontsize=11, weight=weight)\n",
    "\n",
    "# Highlight center pixel\n",
    "ax.add_patch(plt.Rectangle((1.5, 1.5), 1, 1, fill=False, edgecolor='red', linewidth=3))\n",
    "plt.colorbar(im, ax=ax)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cell 2.3: Introducing Sobel Filters\n",
    "\n",
    "**Meet Sam and Steve Sobel** - Captain Mike's equipment specialists!\n",
    "\n",
    "They designed special **3√ó3 filter masks** that efficiently calculate gradients:\n",
    "- **Sam's filter (Gx):** Detects vertical edges (left-right changes)\n",
    "- **Steve's filter (Gy):** Detects horizontal edges (top-bottom changes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define Sobel filters\n",
    "sobel_x = np.array([[-1, 0, 1],\n",
    "                    [-2, 0, 2],\n",
    "                    [-1, 0, 1]])\n",
    "\n",
    "sobel_y = np.array([[-1, -2, -1],\n",
    "                    [ 0,  0,  0],\n",
    "                    [ 1,  2,  1]])\n",
    "\n",
    "print(\"üîß The Sobel Brothers' Survey Equipment:\\n\")\n",
    "print(\"=\"*60)\n",
    "print(\"\\nüìç Sam's X-Direction Equipment (Detects VERTICAL edges):\")\n",
    "print(\"   Compares LEFT vs RIGHT neighbors\\n\")\n",
    "print(sobel_x)\n",
    "print(\"\\n   üí° How it works:\")\n",
    "print(\"      ‚Ä¢ Negative weights on LEFT (-1, -2, -1)\")\n",
    "print(\"      ‚Ä¢ Positive weights on RIGHT (+1, +2, +2)\")\n",
    "print(\"      ‚Ä¢ Center column is ZERO (we're comparing sides!)\")\n",
    "print(\"      ‚Ä¢ Middle row gets double weight (-2, 0, +2) - most important!\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"\\nüìç Steve's Y-Direction Equipment (Detects HORIZONTAL edges):\")\n",
    "print(\"   Compares TOP vs BOTTOM neighbors\\n\")\n",
    "print(sobel_y)\n",
    "print(\"\\n   üí° How it works:\")\n",
    "print(\"      ‚Ä¢ Negative weights on TOP (-1, -2, -1)\")\n",
    "print(\"      ‚Ä¢ Positive weights on BOTTOM (+1, +2, +1)\")\n",
    "print(\"      ‚Ä¢ Center row is ZERO (we're comparing top/bottom!)\")\n",
    "print(\"      ‚Ä¢ Middle column gets double weight - most important!\")\n",
    "\n",
    "# Visualize the filters as heatmaps\n",
    "fig, axes = plt.subplots(1, 2, figsize=(12, 5))\n",
    "\n",
    "# Sobel X\n",
    "im1 = axes[0].imshow(sobel_x, cmap='RdBu', vmin=-2, vmax=2)\n",
    "axes[0].set_title(\"Sam's X-Filter\\n(Vertical Edge Detector)\", fontsize=13, fontweight='bold')\n",
    "for i in range(3):\n",
    "    for j in range(3):\n",
    "        text = axes[0].text(j, i, sobel_x[i, j],\n",
    "                          ha=\"center\", va=\"center\", color=\"black\", fontsize=14, weight='bold')\n",
    "axes[0].set_xticks([])\n",
    "axes[0].set_yticks([])\n",
    "plt.colorbar(im1, ax=axes[0])\n",
    "\n",
    "# Sobel Y\n",
    "im2 = axes[1].imshow(sobel_y, cmap='RdBu', vmin=-2, vmax=2)\n",
    "axes[1].set_title(\"Steve's Y-Filter\\n(Horizontal Edge Detector)\", fontsize=13, fontweight='bold')\n",
    "for i in range(3):\n",
    "    for j in range(3):\n",
    "        text = axes[1].text(j, i, sobel_y[i, j],\n",
    "                          ha=\"center\", va=\"center\", color=\"black\", fontsize=14, weight='bold')\n",
    "axes[1].set_xticks([])\n",
    "axes[1].set_yticks([])\n",
    "plt.colorbar(im2, ax=axes[1])\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nüéØ Key Insight:\")\n",
    "print(\"   These filters are CONVOLUTION KERNELS!\")\n",
    "print(\"   We slide them over the image and multiply values.\")\n",
    "print(\"   This is the SAME operation CNNs will learn in Week 10!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cell 2.4: Apply Sobel X (Detect Vertical Edges)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sam's east-west survey (detects vertical edges)\n",
    "image = test_images['simple_square']\n",
    "sobel_x_result = cv2.Sobel(image, cv2.CV_64F, 1, 0, ksize=3)\n",
    "\n",
    "# Normalize for visualization\n",
    "sobel_x_display = np.abs(sobel_x_result)\n",
    "sobel_x_display = (sobel_x_display / sobel_x_display.max() * 255).astype(np.uint8)\n",
    "\n",
    "print(\"\\nüîç Sam's X-Direction Survey (Team Alpha Report):\\n\")\n",
    "print(\"Looking for VERTICAL edges (left-right intensity changes)...\\n\")\n",
    "\n",
    "# Count detected edges\n",
    "edge_pixels = np.sum(sobel_x_display > 50)\n",
    "print(f\"‚úÖ Found {edge_pixels} edge pixels (threshold > 50)\")\n",
    "\n",
    "show_comparison(\n",
    "    [image, sobel_x_display],\n",
    "    ['Original Image', 'Sobel X (Vertical Edges Detected)'],\n",
    "    cmaps=['gray', 'hot'],\n",
    "    figsize=(12, 5)\n",
    ")\n",
    "\n",
    "print(\"\\nüí° Observations:\")\n",
    "print(\"   ‚Ä¢ LEFT edge of square: Bright in result (dark‚Üíbright transition)\")\n",
    "print(\"   ‚Ä¢ RIGHT edge of square: Bright in result (bright‚Üídark transition)\")\n",
    "print(\"   ‚Ä¢ TOP and BOTTOM edges: NOT detected (no left-right change)\")\n",
    "print(\"   ‚Ä¢ Interior of square: Dark (no horizontal gradient)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cell 2.5: Apply Sobel Y (Detect Horizontal Edges)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Steve's north-south survey (detects horizontal edges)\n",
    "sobel_y_result = cv2.Sobel(image, cv2.CV_64F, 0, 1, ksize=3)\n",
    "\n",
    "# Normalize for visualization\n",
    "sobel_y_display = np.abs(sobel_y_result)\n",
    "sobel_y_display = (sobel_y_display / sobel_y_display.max() * 255).astype(np.uint8)\n",
    "\n",
    "print(\"\\nüîç Steve's Y-Direction Survey (Team Beta Report):\\n\")\n",
    "print(\"Looking for HORIZONTAL edges (top-bottom intensity changes)...\\n\")\n",
    "\n",
    "# Count detected edges\n",
    "edge_pixels = np.sum(sobel_y_display > 50)\n",
    "print(f\"‚úÖ Found {edge_pixels} edge pixels (threshold > 50)\")\n",
    "\n",
    "show_comparison(\n",
    "    [image, sobel_y_display],\n",
    "    ['Original Image', 'Sobel Y (Horizontal Edges Detected)'],\n",
    "    cmaps=['gray', 'hot'],\n",
    "    figsize=(12, 5)\n",
    ")\n",
    "\n",
    "print(\"\\nüí° Observations:\")\n",
    "print(\"   ‚Ä¢ TOP edge of square: Bright in result (dark‚Üíbright transition)\")\n",
    "print(\"   ‚Ä¢ BOTTOM edge of square: Bright in result (bright‚Üídark transition)\")\n",
    "print(\"   ‚Ä¢ LEFT and RIGHT edges: NOT detected (no top-bottom change)\")\n",
    "print(\"   ‚Ä¢ Interior of square: Dark (no vertical gradient)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cell 2.6: Combined Gradient Magnitude (Complete Edge Map!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Captain Mike's complete danger map: Combine both surveys!\n",
    "gradient_magnitude = np.sqrt(sobel_x_result**2 + sobel_y_result**2)\n",
    "\n",
    "# Normalize for visualization\n",
    "gradient_display = (gradient_magnitude / gradient_magnitude.max() * 255).astype(np.uint8)\n",
    "\n",
    "print(\"\\nüó∫Ô∏è  Captain Mike's Complete Danger Map:\\n\")\n",
    "print(\"Combining Team Alpha (X) + Team Beta (Y) reports...\\n\")\n",
    "print(\"Formula: Magnitude = ‚àö(Gx¬≤ + Gy¬≤)\\n\")\n",
    "\n",
    "# Statistics\n",
    "edge_pixels = np.sum(gradient_display > 50)\n",
    "total_pixels = gradient_display.size\n",
    "edge_percentage = (edge_pixels / total_pixels) * 100\n",
    "\n",
    "print(f\"üìä Detection Statistics:\")\n",
    "print(f\"   Total pixels: {total_pixels}\")\n",
    "print(f\"   Edge pixels: {edge_pixels}\")\n",
    "print(f\"   Edge coverage: {edge_percentage:.2f}%\")\n",
    "\n",
    "# Show the complete progression\n",
    "show_gradient_analysis(image, sobel_x_display, sobel_y_display, gradient_display)\n",
    "\n",
    "print(\"\\nüéØ Mission Accomplished!\")\n",
    "print(\"   ‚úÖ ALL four edges detected (top, bottom, left, right)\")\n",
    "print(\"   ‚úÖ Combined survey captures complete boundary\")\n",
    "print(\"   ‚úÖ This is the foundation of edge detection!\")\n",
    "\n",
    "print(\"\\nüí° Key Formula to Remember:\")\n",
    "print(\"   Gradient Magnitude = ‚àö(Gx¬≤ + Gy¬≤)\")\n",
    "print(\"   where Gx = Sobel X response, Gy = Sobel Y response\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cell 2.7: Sobel on Complex Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply Sobel to a more complex image\n",
    "complex_image = test_images['multi_shapes']\n",
    "\n",
    "# Apply Sobel edge detection\n",
    "sobel_x = cv2.Sobel(complex_image, cv2.CV_64F, 1, 0, ksize=3)\n",
    "sobel_y = cv2.Sobel(complex_image, cv2.CV_64F, 0, 1, ksize=3)\n",
    "sobel_combined = np.sqrt(sobel_x**2 + sobel_y**2)\n",
    "\n",
    "# Normalize\n",
    "sobel_combined = (sobel_combined / sobel_combined.max() * 255).astype(np.uint8)\n",
    "\n",
    "print(\"\\nüé® Sobel Detection on Complex Scene:\\n\")\n",
    "\n",
    "show_comparison(\n",
    "    [complex_image, sobel_combined],\n",
    "    ['Multiple Shapes (Original)', 'Sobel Edge Detection Result'],\n",
    "    cmaps=['gray', 'hot'],\n",
    "    figsize=(14, 6)\n",
    ")\n",
    "\n",
    "print(\"\\n‚úÖ Sobel successfully detects:\")\n",
    "print(\"   ‚Ä¢ Rectangle boundaries\")\n",
    "print(\"   ‚Ä¢ Circle outline\")\n",
    "print(\"   ‚Ä¢ Triangle edges\")\n",
    "print(\"\\n‚ö†Ô∏è  Sobel limitations noticed:\")\n",
    "print(\"   ‚Ä¢ Edges are THICK (multiple pixels wide)\")\n",
    "print(\"   ‚Ä¢ Some edges are BROKEN (not fully connected)\")\n",
    "print(\"   ‚Ä¢ Sensitive to noise (would show up as false edges)\")\n",
    "print(\"\\n‚û°Ô∏è  This is why we need Detective Canny's better method!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# SECTION 3: Detective Canny's Master Protocol\n",
    "\n",
    "## üïµÔ∏è Meet Detective Canny - The Master Investigator\n",
    "\n",
    "While Sobel gives us quick results, **Detective Canny** follows a proven 4-stage protocol that produces superior edge detection:\n",
    "\n",
    "### Canny's 4-Stage Investigation Method:\n",
    "\n",
    "1. **Stage 1: Clean the Crime Scene** üßπ\n",
    "   - Remove noise with Gaussian blur\n",
    "   - *\"Never investigate a messy scene!\"*\n",
    "\n",
    "2. **Stage 2: Mark All Potential Evidence** üîç\n",
    "   - Calculate gradients (like Sobel)\n",
    "   - Find ALL possible edge locations\n",
    "\n",
    "3. **Stage 3: Eliminate False Evidence** ‚úÇÔ∏è\n",
    "   - Non-Maximum Suppression (NMS)\n",
    "   - Keep only the strongest edges\n",
    "   - Thin edges to single-pixel width\n",
    "\n",
    "4. **Stage 4: Connect Related Evidence** üîó\n",
    "   - Hysteresis thresholding\n",
    "   - Strong edges are kept\n",
    "   - Weak edges kept only if connected to strong\n",
    "\n",
    "Let's see each stage in action!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cell 3.1: The Problem with Sobel - Why We Need Canny"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_section_header(3, \"Detective Canny's Master Protocol\")\n",
    "\n",
    "# Create a noisy image to show Sobel's limitations\n",
    "clean_image = test_images['simple_square']\n",
    "noisy_image = add_noise_to_image(clean_image, 'gaussian', intensity=30)\n",
    "\n",
    "# Apply Sobel to noisy image\n",
    "sobel_x = cv2.Sobel(noisy_image, cv2.CV_64F, 1, 0, ksize=3)\n",
    "sobel_y = cv2.Sobel(noisy_image, cv2.CV_64F, 0, 1, ksize=3)\n",
    "sobel_noisy = np.sqrt(sobel_x**2 + sobel_y**2)\n",
    "sobel_noisy = (sobel_noisy / sobel_noisy.max() * 255).astype(np.uint8)\n",
    "\n",
    "print(\"‚ö†Ô∏è  Problems with Amateur Detection (Sobel on Noisy Image):\\n\")\n",
    "\n",
    "show_comparison(\n",
    "    [clean_image, noisy_image, sobel_noisy],\n",
    "    ['Original Clean', 'After Adding Noise', 'Sobel Result (Messy!)'],\n",
    "    cmaps=['gray', 'gray', 'hot'],\n",
    "    figsize=(15, 4)\n",
    ")\n",
    "\n",
    "print(\"\\nüî¥ Issues Detected:\")\n",
    "print(\"   1. THICK EDGES: Edges are several pixels wide (imprecise)\")\n",
    "print(\"   2. NOISE SENSITIVITY: False edges from random noise\")\n",
    "print(\"   3. BROKEN EDGES: True edges may be disconnected\")\n",
    "print(\"   4. NO PRIORITIZATION: Can't distinguish strong vs weak edges\")\n",
    "\n",
    "print(\"\\n‚úÖ Enter Detective Canny's Systematic Approach!\")\n",
    "print(\"   His 4-stage protocol solves ALL these problems.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cell 3.2: Stage 1 - Clean the Crime Scene (Gaussian Blur)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nüßπ STAGE 1: Clean the Crime Scene\\n\")\n",
    "print(\"Canny's Rule: 'Never investigate a messy scene!'\\n\")\n",
    "\n",
    "# Apply Gaussian blur to remove noise\n",
    "kernel_size = (5, 5)\n",
    "cleaned_image = cv2.GaussianBlur(noisy_image, kernel_size, 0)\n",
    "\n",
    "print(f\"üîß Applying Gaussian blur with {kernel_size} kernel...\\n\")\n",
    "\n",
    "show_comparison(\n",
    "    [noisy_image, cleaned_image],\n",
    "    ['Before Cleaning (Noisy)', 'After Cleaning (Blurred)'],\n",
    "    figsize=(12, 5)\n",
    ")\n",
    "\n",
    "# Calculate noise reduction\n",
    "noise_before = np.std(noisy_image.astype(np.float32))\n",
    "noise_after = np.std(cleaned_image.astype(np.float32))\n",
    "reduction = ((noise_before - noise_after) / noise_before) * 100\n",
    "\n",
    "print(f\"\\nüìä Noise Reduction Statistics:\")\n",
    "print(f\"   Noise level before: {noise_before:.2f}\")\n",
    "print(f\"   Noise level after:  {noise_after:.2f}\")\n",
    "print(f\"   Reduction: {reduction:.1f}%\")\n",
    "\n",
    "print(\"\\nüí° Why Gaussian Blur?\")\n",
    "print(\"   ‚Ä¢ Smooths image while preserving edges\")\n",
    "print(\"   ‚Ä¢ Reduces random noise (false edge candidates)\")\n",
    "print(\"   ‚Ä¢ Makes gradient calculation more reliable\")\n",
    "print(\"   ‚Ä¢ Trade-off: Slight edge blurring (acceptable!)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cell 3.3: Stage 2 - Mark All Potential Evidence (Gradient Calculation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nüîç STAGE 2: Mark All Potential Evidence\\n\")\n",
    "print(\"Canny's Process: 'Find EVERY possible clue location'\\n\")\n",
    "\n",
    "# Calculate gradients on cleaned image (same as Sobel)\n",
    "gradient_x = cv2.Sobel(cleaned_image, cv2.CV_64F, 1, 0, ksize=3)\n",
    "gradient_y = cv2.Sobel(cleaned_image, cv2.CV_64F, 0, 1, ksize=3)\n",
    "gradient_magnitude = np.sqrt(gradient_x**2 + gradient_y**2)\n",
    "gradient_direction = np.arctan2(gradient_y, gradient_x) * (180 / np.pi)\n",
    "\n",
    "# Normalize for display\n",
    "gradient_display = (gradient_magnitude / gradient_magnitude.max() * 255).astype(np.uint8)\n",
    "\n",
    "print(\"‚úÖ Gradient calculation complete!\\n\")\n",
    "\n",
    "show_comparison(\n",
    "    [cleaned_image, gradient_display],\n",
    "    ['Cleaned Image (Stage 1)', 'Gradient Magnitude (Stage 2)'],\n",
    "    cmaps=['gray', 'hot'],\n",
    "    figsize=(12, 5)\n",
    ")\n",
    "\n",
    "print(\"\\nüìä Evidence Inventory:\")\n",
    "strong_evidence = np.sum(gradient_magnitude > 100)\n",
    "moderate_evidence = np.sum((gradient_magnitude > 50) & (gradient_magnitude <= 100))\n",
    "weak_evidence = np.sum((gradient_magnitude > 10) & (gradient_magnitude <= 50))\n",
    "\n",
    "print(f\"   Strong evidence points (>100): {strong_evidence}\")\n",
    "print(f\"   Moderate evidence (50-100): {moderate_evidence}\")\n",
    "print(f\"   Weak evidence (10-50): {weak_evidence}\")\n",
    "print(f\"   Total evidence locations: {strong_evidence + moderate_evidence + weak_evidence}\")\n",
    "\n",
    "print(\"\\nüí° Stage 2 Output:\")\n",
    "print(\"   ‚Ä¢ Gradient MAGNITUDE (edge strength)\")\n",
    "print(\"   ‚Ä¢ Gradient DIRECTION (edge orientation)\")\n",
    "print(\"   ‚Ä¢ Both needed for Stage 3 (Non-Maximum Suppression)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cell 3.4: Stage 3 - Eliminate False Evidence (Non-Maximum Suppression)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n‚úÇÔ∏è  STAGE 3: Eliminate False Evidence\\n\")\n",
    "print(\"Canny's Insight: 'Most potential evidence is actually false evidence'\\n\")\n",
    "print(\"Solution: NON-MAXIMUM SUPPRESSION (NMS)\\n\")\n",
    "\n",
    "print(\"üéØ How NMS Works:\")\n",
    "print(\"   1. Look at gradient DIRECTION at each pixel\")\n",
    "print(\"   2. Compare gradient MAGNITUDE with neighbors along that direction\")\n",
    "print(\"   3. KEEP pixel only if it has the MAXIMUM value\")\n",
    "print(\"   4. SUPPRESS all others (set to zero)\")\n",
    "print(\"\\n   Result: Thick edges ‚Üí Thin, precise single-pixel edges!\\n\")\n",
    "\n",
    "# Demonstrate the concept with a simple example\n",
    "example_text = \"\"\"\n",
    "Example: Detecting a vertical edge\n",
    "\n",
    "Before NMS (thick edge):        After NMS (thin edge):\n",
    "    0   0  50  80  90  85  50       0   0   0   0  90   0   0\n",
    "    0   0  55  85  95  80  45       0   0   0   0  95   0   0  \n",
    "    0   0  48  82  93  88  52       0   0   0   0  93   0   0\n",
    "\n",
    "Only the CENTER of the edge (maximum values) survives!\n",
    "\"\"\"\n",
    "print(example_text)\n",
    "\n",
    "# Apply complete Canny (which includes NMS) and compare with Sobel\n",
    "# First, apply just gradient for comparison\n",
    "sobel_result = cv2.Sobel(cleaned_image, cv2.CV_64F, 1, 0, ksize=3)\n",
    "sobel_result = np.abs(sobel_result)\n",
    "sobel_result = (sobel_result / sobel_result.max() * 255).astype(np.uint8)\n",
    "\n",
    "# Apply Canny (includes NMS internally)\n",
    "canny_with_nms = cv2.Canny(cleaned_image, 50, 150)\n",
    "\n",
    "print(\"\\nüìä Visual Comparison: Before vs After NMS\\n\")\n",
    "\n",
    "show_comparison(\n",
    "    [gradient_display, canny_with_nms],\n",
    "    ['Before NMS (Thick Edges)', 'After NMS (Thin Edges)'],\n",
    "    figsize=(12, 5)\n",
    ")\n",
    "\n",
    "# Measure edge thickness\n",
    "thick_edge_pixels = np.sum(gradient_display > 50)\n",
    "thin_edge_pixels = np.sum(canny_with_nms > 0)\n",
    "reduction_ratio = (thick_edge_pixels - thin_edge_pixels) / thick_edge_pixels * 100\n",
    "\n",
    "print(f\"\\nüìè Edge Thinning Statistics:\")\n",
    "print(f\"   Before NMS: {thick_edge_pixels} edge pixels (thick)\")\n",
    "print(f\"   After NMS:  {thin_edge_pixels} edge pixels (thin)\")\n",
    "print(f\"   Reduction:  {reduction_ratio:.1f}%\")\n",
    "\n",
    "print(\"\\n‚úÖ Stage 3 Achievement:\")\n",
    "print(\"   ‚Ä¢ Edges thinned to 1-pixel width (precise!)\")\n",
    "print(\"   ‚Ä¢ False evidence suppressed\")\n",
    "print(\"   ‚Ä¢ Edge localization greatly improved\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cell 3.5: Stage 4 - Connect Related Evidence (Hysteresis Thresholding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nüîó STAGE 4: Connect Related Evidence\\n\")\n",
    "print(\"Canny's Final Step: 'Strong evidence is reliable, weak evidence needs verification'\\n\")\n",
    "print(\"Solution: HYSTERESIS THRESHOLDING (Two-Threshold System)\\n\")\n",
    "\n",
    "print(\"üéØ The Two-Threshold Strategy:\\n\")\n",
    "print(\"   üìç HIGH THRESHOLD (e.g., 150):\")\n",
    "print(\"      ‚Ä¢ Edges above this = DEFINITELY REAL\")\n",
    "print(\"      ‚Ä¢ 'Strong Evidence' - kept unconditionally\")\n",
    "print(\"\\n   üìç LOW THRESHOLD (e.g., 50):\")\n",
    "print(\"      ‚Ä¢ Edges between low and high = MAYBE REAL\")\n",
    "print(\"      ‚Ä¢ 'Weak Evidence' - kept ONLY if connected to strong evidence\")\n",
    "print(\"\\n   ‚ùå Below low threshold:\")\n",
    "print(\"      ‚Ä¢ Definitely false - discarded\")\n",
    "\n",
    "# Demonstrate with different thresholds\n",
    "low_thresh = 50\n",
    "high_thresh = 150\n",
    "\n",
    "# High threshold only (conservative)\n",
    "canny_high_only = cv2.Canny(cleaned_image, high_thresh, high_thresh)\n",
    "\n",
    "# Low threshold only (too sensitive)\n",
    "canny_low_only = cv2.Canny(cleaned_image, low_thresh, low_thresh)\n",
    "\n",
    "# Proper hysteresis (both thresholds)\n",
    "canny_proper = cv2.Canny(cleaned_image, low_thresh, high_thresh)\n",
    "\n",
    "print(\"\\nüìä Comparing Different Threshold Strategies:\\n\")\n",
    "\n",
    "show_comparison(\n",
    "    [canny_high_only, canny_low_only, canny_proper],\n",
    "    [f'High Only ({high_thresh})\\n(Missing edges!)', \n",
    "     f'Low Only ({low_thresh})\\n(Too many false edges!)',\n",
    "     f'Hysteresis ({low_thresh}, {high_thresh})\\n(Perfect balance!)'],\n",
    "    figsize=(15, 4)\n",
    ")\n",
    "\n",
    "# Statistics\n",
    "high_edges = np.sum(canny_high_only > 0)\n",
    "low_edges = np.sum(canny_low_only > 0)\n",
    "proper_edges = np.sum(canny_proper > 0)\n",
    "\n",
    "print(f\"\\nüìä Edge Detection Counts:\")\n",
    "print(f\"   High threshold only:  {high_edges} pixels (too conservative)\")\n",
    "print(f\"   Low threshold only:   {low_edges} pixels (too many false edges)\")\n",
    "print(f\"   Hysteresis (proper): {proper_edges} pixels (just right! ‚úÖ)\")\n",
    "\n",
    "print(\"\\nüí° Why Hysteresis Works:\")\n",
    "print(\"   1. Start with strong edges (high confidence)\")\n",
    "print(\"   2. Follow connected weak edges (likely part of same boundary)\")\n",
    "print(\"   3. Ignore isolated weak edges (probably noise)\")\n",
    "print(\"   4. Result: Complete, connected boundaries!\")\n",
    "\n",
    "print(\"\\nüìê Threshold Selection Rule of Thumb:\")\n",
    "print(\"   ‚Ä¢ Low threshold ‚âà 0.4 √ó High threshold\")\n",
    "print(\"   ‚Ä¢ Example: If high=150, then low=60\")\n",
    "print(f\"   ‚Ä¢ Our example: low={low_thresh}, high={high_thresh}, ratio={low_thresh/high_thresh:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cell 3.6: Complete Canny Implementation - All Stages Together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nüéâ DETECTIVE CANNY'S COMPLETE INVESTIGATION PROTOCOL\\n\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Start with the noisy image from earlier\n",
    "print(\"\\nüîç Case: Detect edges in noisy crime scene image\\n\")\n",
    "\n",
    "# Apply complete Canny edge detection (all 4 stages)\n",
    "canny_edges = cv2.Canny(noisy_image, 50, 150)\n",
    "\n",
    "# For comparison, apply Sobel to the same noisy image\n",
    "sobel_x = cv2.Sobel(noisy_image, cv2.CV_64F, 1, 0, ksize=3)\n",
    "sobel_y = cv2.Sobel(noisy_image, cv2.CV_64F, 0, 1, ksize=3)\n",
    "sobel_edges = np.sqrt(sobel_x**2 + sobel_y**2)\n",
    "sobel_edges = (sobel_edges / sobel_edges.max() * 255).astype(np.uint8)\n",
    "\n",
    "print(\"üìã Canny Protocol Executed:\")\n",
    "print(\"   ‚úÖ Stage 1: Gaussian blur (5x5 kernel, built-in)\")\n",
    "print(\"   ‚úÖ Stage 2: Gradient calculation (Sobel, built-in)\")\n",
    "print(\"   ‚úÖ Stage 3: Non-maximum suppression (thinning)\")\n",
    "print(\"   ‚úÖ Stage 4: Hysteresis thresholding (50, 150)\")\n",
    "\n",
    "print(\"\\nüÜö Amateur Detective (Sobel) vs Master Detective (Canny):\\n\")\n",
    "\n",
    "show_comparison(\n",
    "    [noisy_image, sobel_edges, canny_edges],\n",
    "    ['Original Noisy Image', \n",
    "     'Sobel Result\\n(Thick, noisy, broken edges)', \n",
    "     'Canny Result\\n(Thin, clean, connected edges)'],\n",
    "    cmaps=['gray', 'hot', 'gray'],\n",
    "    figsize=(15, 4)\n",
    ")\n",
    "\n",
    "print(\"\\nüìä Quality Comparison:\")\n",
    "print(\"\\n   üî¥ Sobel (Amateur):\")\n",
    "print(\"      ‚Ä¢ Thick edges (imprecise)\")\n",
    "print(\"      ‚Ä¢ Many false edges from noise\")\n",
    "print(\"      ‚Ä¢ Broken discontinuous edges\")\n",
    "print(\"      ‚Ä¢ No edge prioritization\")\n",
    "\n",
    "print(\"\\n   üü¢ Canny (Master):\")\n",
    "print(\"      ‚Ä¢ Thin 1-pixel edges (precise!)\")\n",
    "print(\"      ‚Ä¢ Noise-resistant (blur first)\")\n",
    "print(\"      ‚Ä¢ Connected continuous edges\")\n",
    "print(\"      ‚Ä¢ Intelligent thresholding\")\n",
    "\n",
    "print(\"\\nüíª Complete Python Code:\")\n",
    "print(\"\"\"\n",
    "# Detective Canny's one-line solution!\n",
    "edges = cv2.Canny(image, low_threshold, high_threshold)\n",
    "\n",
    "# Example:\n",
    "edges = cv2.Canny(image, 50, 150)\n",
    "\"\"\")\n",
    "\n",
    "print(\"\\nüéØ When to Use Canny:\")\n",
    "print(\"   ‚Ä¢ When you need PRECISE edge localization\")\n",
    "print(\"   ‚Ä¢ When working with NOISY images\")\n",
    "print(\"   ‚Ä¢ When you need CONNECTED boundaries\")\n",
    "print(\"   ‚Ä¢ Production applications (self-driving cars, medical imaging)\")\n",
    "print(\"\\n   ‚úÖ Canny is the GOLD STANDARD for edge detection!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cell 3.7: Interactive Parameter Tuning - Find the Sweet Spot!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def explore_canny_parameters(image, low_values, high_values):\n",
    "    \"\"\"\n",
    "    Explore different Canny parameter combinations\n",
    "    \"\"\"\n",
    "    print(\"\\nüß™ CANNY PARAMETER EXPLORATION LAB\\n\")\n",
    "    print(\"=\"*70)\n",
    "    print(\"\\nTesting different threshold combinations...\\n\")\n",
    "    \n",
    "    results = []\n",
    "    \n",
    "    for low, high in zip(low_values, high_values):\n",
    "        edges = cv2.Canny(image, low, high)\n",
    "        edge_count = np.sum(edges > 0)\n",
    "        results.append((low, high, edges, edge_count))\n",
    "        \n",
    "        print(f\"   Thresholds ({low:3d}, {high:3d}) ‚Üí {edge_count:5d} edge pixels\")\n",
    "    \n",
    "    # Display results\n",
    "    n = len(results)\n",
    "    fig, axes = plt.subplots(1, n+1, figsize=(4*(n+1), 4))\n",
    "    \n",
    "    # Show original\n",
    "    axes[0].imshow(image, cmap='gray')\n",
    "    axes[0].set_title('Original Image', fontsize=11, fontweight='bold')\n",
    "    axes[0].axis('off')\n",
    "    \n",
    "    # Show each result\n",
    "    for i, (low, high, edges, count) in enumerate(results, 1):\n",
    "        axes[i].imshow(edges, cmap='gray')\n",
    "        axes[i].set_title(f'Canny({low}, {high})\\n{count} pixels', \n",
    "                         fontsize=11, fontweight='bold')\n",
    "        axes[i].axis('off')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    return results\n",
    "\n",
    "\n",
    "# Try different threshold combinations\n",
    "image = test_images['multi_shapes']\n",
    "\n",
    "# Conservative, Standard, Aggressive\n",
    "low_values = [30, 50, 100]\n",
    "high_values = [90, 150, 200]\n",
    "\n",
    "results = explore_canny_parameters(image, low_values, high_values)\n",
    "\n",
    "print(\"\\nüí° Observations:\")\n",
    "print(\"   ‚Ä¢ LOW thresholds (30, 90): More edges detected (sensitive)\")\n",
    "print(\"   ‚Ä¢ MEDIUM thresholds (50, 150): Balanced detection (recommended!)\")\n",
    "print(\"   ‚Ä¢ HIGH thresholds (100, 200): Fewer edges (conservative)\")\n",
    "\n",
    "print(\"\\nüéØ Guideline:\")\n",
    "print(\"   Choose thresholds based on your application:\")\n",
    "print(\"   ‚Ä¢ Medical imaging: Conservative (don't want to miss anything)\")\n",
    "print(\"   ‚Ä¢ Quality control: Aggressive (catch all defects)\")\n",
    "print(\"   ‚Ä¢ General purpose: Standard (50, 150) works well!\")\n",
    "\n",
    "print(\"\\nüî¨ TRY IT YOURSELF:\")\n",
    "print(\"   Experiment with your own threshold values!\")\n",
    "print(\"   Uncomment and modify the code below:\\n\")\n",
    "print(\"   # my_low = 40\")\n",
    "print(\"   # my_high = 120\")\n",
    "print(\"   # my_edges = cv2.Canny(image, my_low, my_high)\")\n",
    "print(\"   # plt.imshow(my_edges, cmap='gray')\")\n",
    "print(\"   # plt.title(f'My Canny({my_low}, {my_high})')\")\n",
    "print(\"   # plt.show()\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cell 3.8: Sobel vs Canny - Final Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n‚öñÔ∏è  FINAL VERDICT: Sobel vs Canny\\n\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Test both methods on all our test images\n",
    "comparison_results = []\n",
    "\n",
    "for name, img in test_images.items():\n",
    "    # Sobel\n",
    "    sobel_x = cv2.Sobel(img, cv2.CV_64F, 1, 0, ksize=3)\n",
    "    sobel_y = cv2.Sobel(img, cv2.CV_64F, 0, 1, ksize=3)\n",
    "    sobel_result = np.sqrt(sobel_x**2 + sobel_y**2)\n",
    "    sobel_result = (sobel_result / sobel_result.max() * 255).astype(np.uint8)\n",
    "    \n",
    "    # Canny\n",
    "    canny_result = cv2.Canny(img, 50, 150)\n",
    "    \n",
    "    comparison_results.append((name, img, sobel_result, canny_result))\n",
    "\n",
    "# Display comparison for one example\n",
    "name, img, sobel, canny = comparison_results[2]  # multi_shapes\n",
    "\n",
    "show_comparison(\n",
    "    [img, sobel, canny],\n",
    "    ['Original', 'Sobel (Quick Scan)', 'Canny (Master Protocol)'],\n",
    "    cmaps=['gray', 'hot', 'gray'],\n",
    "    figsize=(15, 4)\n",
    ")\n",
    "\n",
    "print(\"\\nüìä Method Comparison Table:\\n\")\n",
    "print(\"‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\")\n",
    "print(\"‚îÇ Criteria            ‚îÇ Sobel           ‚îÇ Canny           ‚îÇ\")\n",
    "print(\"‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\")\n",
    "print(\"‚îÇ Edge Thickness      ‚îÇ Multi-pixel     ‚îÇ Single-pixel ‚úÖ ‚îÇ\")\n",
    "print(\"‚îÇ Noise Handling      ‚îÇ Poor ‚ö†Ô∏è         ‚îÇ Excellent ‚úÖ     ‚îÇ\")\n",
    "print(\"‚îÇ Edge Connectivity   ‚îÇ Often broken    ‚îÇ Connected ‚úÖ     ‚îÇ\")\n",
    "print(\"‚îÇ Computation Speed   ‚îÇ Fast ‚ö°‚ö°‚ö°      ‚îÇ Moderate ‚ö°‚ö°    ‚îÇ\")\n",
    "print(\"‚îÇ Implementation      ‚îÇ Simple          ‚îÇ Complex         ‚îÇ\")\n",
    "print(\"‚îÇ Parameter Tuning    ‚îÇ None needed     ‚îÇ 2 thresholds    ‚îÇ\")\n",
    "print(\"‚îÇ Edge Localization   ‚îÇ Approximate     ‚îÇ Precise ‚úÖ      ‚îÇ\")\n",
    "print(\"‚îÇ False Positives     ‚îÇ Many            ‚îÇ Few ‚úÖ          ‚îÇ\")\n",
    "print(\"‚îÇ Production Use      ‚îÇ Prototyping     ‚îÇ Standard ‚úÖ     ‚îÇ\")\n",
    "print(\"‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\")\n",
    "\n",
    "print(\"\\nüéØ Recommendation:\")\n",
    "print(\"   ‚Ä¢ Use SOBEL for: Quick experiments, understanding gradients\")\n",
    "print(\"   ‚Ä¢ Use CANNY for: Production systems, precise edge detection\")\n",
    "print(\"\\n   ‚úÖ For most applications, CANNY is the right choice!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "*This is a comprehensive Jupyter notebook. Due to length constraints, I'm providing the structure and first 3 major sections with detailed implementations.*\n",
    "\n",
    "*The remaining sections (4-11) would follow the same pattern with:*\n",
    "- *Section 4: Laplacian edge detection with helicopter analogy*\n",
    "- *Section 5: Multi-scale detection with image pyramids*\n",
    "- *Section 6: Real-world applications (medical, automotive, manufacturing)*\n",
    "- *Section 7: Interactive challenges for students*\n",
    "- *Section 8: Bridge to CNNs (how neural networks learn edge filters)*\n",
    "- *Section 9: Complete detective toolkit class*\n",
    "- *Section 10: Unit Test 2 preparation*\n",
    "- *Section 11: Summary and Tutorial T7 assignment*\n",
    "\n",
    "**Would you like me to continue with the remaining sections (4-11)?**\n",
    "\n",
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}