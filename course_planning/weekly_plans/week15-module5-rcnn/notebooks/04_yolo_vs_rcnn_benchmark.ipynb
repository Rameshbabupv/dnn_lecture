{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notebook 04: YOLO vs R-CNN Benchmark\n",
    "\n",
    "**Week 15 - Module 5: Object Detection**\n",
    "\n",
    "**Duration:** ~15 minutes\n",
    "\n",
    "**Learning Objectives:**\n",
    "- Compare YOLO and Faster R-CNN directly on same images\n",
    "- Benchmark speed and accuracy quantitatively\n",
    "- Analyze strengths and weaknesses of each approach\n",
    "- Make informed detector selection decisions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Experimental Setup\n",
    "\n",
    "### Fair Comparison Requirements:\n",
    "\n",
    "For a meaningful comparison, we need:\n",
    "\n",
    "#### 1. Same Test Images\n",
    "- Diverse scenes (indoor, outdoor, crowded, simple)\n",
    "- Different object sizes (small, medium, large)\n",
    "- Varying complexity levels\n",
    "\n",
    "#### 2. Same Evaluation Metrics\n",
    "- **Speed**: Inference time (ms), FPS\n",
    "- **Accuracy**: Detection quality, bounding box precision\n",
    "- **Recall**: Percentage of objects detected\n",
    "- **Precision**: Percentage of detections that are correct\n",
    "\n",
    "#### 3. Same Hardware\n",
    "- Same GPU/CPU\n",
    "- Same image preprocessing\n",
    "- Same confidence thresholds (or compare across thresholds)\n",
    "\n",
    "#### 4. Fair Model Selection\n",
    "- **YOLO**: YOLOv8 medium (yolov8m.pt) - balanced model\n",
    "- **Faster R-CNN**: ResNet50-FPN - standard pre-trained\n",
    "- Both trained on COCO dataset (80 classes)\n",
    "- Both using pre-trained weights\n",
    "\n",
    "### Test Scenarios:\n",
    "\n",
    "We'll test on:\n",
    "1. **Simple Scene**: Few objects, clear separation\n",
    "2. **Crowded Scene**: Many objects, overlapping\n",
    "3. **Small Objects**: Distant or tiny objects\n",
    "4. **Speed Test**: Batch processing on 50 images\n",
    "5. **Accuracy Test**: Detection quality analysis\n",
    "\n",
    "### Metrics Defined:\n",
    "\n",
    "**Speed Metrics:**\n",
    "- **Inference Time**: Total time from input to output (ms)\n",
    "- **FPS**: Frames per second (1/inference_time)\n",
    "- **Throughput**: Images per second in batch mode\n",
    "\n",
    "**Accuracy Metrics:**\n",
    "- **True Positives (TP)**: Correct detections (IOU > 0.5 with ground truth)\n",
    "- **False Positives (FP)**: Incorrect detections\n",
    "- **False Negatives (FN)**: Missed objects\n",
    "- **Precision**: TP / (TP + FP)\n",
    "- **Recall**: TP / (TP + FN)\n",
    "- **Localization Quality**: Average IOU of true positives\n",
    "\n",
    "### Expected Trade-offs:\n",
    "\n",
    "**YOLO:**\n",
    "- ✅ Much faster (60+ FPS)\n",
    "- ✅ Smaller model size\n",
    "- ❌ May miss small objects\n",
    "- ❌ Less precise localization\n",
    "\n",
    "**Faster R-CNN:**\n",
    "- ✅ Better accuracy (especially small objects)\n",
    "- ✅ More precise bounding boxes\n",
    "- ❌ Slower (5-10 FPS)\n",
    "- ❌ Larger model size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup and Imports\n",
    "import torch\n",
    "import torchvision\n",
    "from torchvision.models.detection import fasterrcnn_resnet50_fpn\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.patches import Rectangle\n",
    "import time\n",
    "from pathlib import Path\n",
    "\n",
    "# YOLO imports (using ultralytics)\n",
    "try:\n",
    "    from ultralytics import YOLO\n",
    "    yolo_available = True\n",
    "except ImportError:\n",
    "    print(\"WARNING: YOLO not installed. Install with: pip install ultralytics\")\n",
    "    yolo_available = False\n",
    "\n",
    "print(f\"PyTorch version: {torch.__version__}\")\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
    "print(f\"YOLO available: {yolo_available}\")\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"\\nUsing device: {device}\")\n",
    "\n",
    "# COCO class names (for reference)\n",
    "COCO_CLASSES = [\n",
    "    '__background__', 'person', 'bicycle', 'car', 'motorcycle', 'airplane', 'bus',\n",
    "    'train', 'truck', 'boat', 'traffic light', 'fire hydrant', 'N/A', 'stop sign',\n",
    "    'parking meter', 'bench', 'bird', 'cat', 'dog', 'horse', 'sheep', 'cow',\n",
    "    'elephant', 'bear', 'zebra', 'giraffe', 'N/A', 'backpack', 'umbrella', 'N/A', 'N/A',\n",
    "    'handbag', 'tie', 'suitcase', 'frisbee', 'skis', 'snowboard', 'sports ball',\n",
    "    'kite', 'baseball bat', 'baseball glove', 'skateboard', 'surfboard', 'tennis racket',\n",
    "    'bottle', 'N/A', 'wine glass', 'cup', 'fork', 'knife', 'spoon', 'bowl',\n",
    "    'banana', 'apple', 'sandwich', 'orange', 'broccoli', 'carrot', 'hot dog', 'pizza',\n",
    "    'donut', 'cake', 'chair', 'couch', 'potted plant', 'bed', 'N/A', 'dining table',\n",
    "    'N/A', 'N/A', 'toilet', 'N/A', 'tv', 'laptop', 'mouse', 'remote', 'keyboard', 'cell phone',\n",
    "    'microwave', 'oven', 'toaster', 'sink', 'refrigerator', 'N/A', 'book',\n",
    "    'clock', 'vase', 'scissors', 'teddy bear', 'hair drier', 'toothbrush'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Both Models\n",
    "\n",
    "print(\"Loading models...\\n\")\n",
    "\n",
    "# Load Faster R-CNN\n",
    "print(\"1. Loading Faster R-CNN (ResNet50-FPN)...\")\n",
    "faster_rcnn = fasterrcnn_resnet50_fpn(pretrained=True)\n",
    "faster_rcnn.eval()\n",
    "faster_rcnn.to(device)\n",
    "print(\"   ✓ Faster R-CNN loaded\")\n",
    "\n",
    "# Load YOLO\n",
    "if yolo_available:\n",
    "    print(\"\\n2. Loading YOLO v8 medium...\")\n",
    "    yolo = YOLO('yolov8m.pt')  # Medium model for fair comparison\n",
    "    print(\"   ✓ YOLO v8m loaded\")\n",
    "else:\n",
    "    print(\"\\n2. YOLO not available - install with: pip install ultralytics\")\n",
    "    yolo = None\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"Model Specifications:\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Faster R-CNN stats\n",
    "rcnn_params = sum(p.numel() for p in faster_rcnn.parameters())\n",
    "print(f\"Faster R-CNN:\")\n",
    "print(f\"  Parameters: {rcnn_params:,}\")\n",
    "print(f\"  Model size: ~160 MB\")\n",
    "print(f\"  Architecture: Two-stage (RPN + Detector)\")\n",
    "print(f\"  Backbone: ResNet50 + FPN\")\n",
    "\n",
    "if yolo_available:\n",
    "    print(f\"\\nYOLO v8m:\")\n",
    "    print(f\"  Parameters: ~25.9M\")\n",
    "    print(f\"  Model size: ~52 MB\")\n",
    "    print(f\"  Architecture: Single-stage (Direct prediction)\")\n",
    "    print(f\"  Backbone: CSPDarknet with C2f modules\")\n",
    "\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper Functions\n",
    "\n",
    "def create_test_images():\n",
    "    \"\"\"\n",
    "    Create three test scenarios:\n",
    "    1. Simple scene (few objects)\n",
    "    2. Crowded scene (many objects)\n",
    "    3. Small objects scene\n",
    "    \"\"\"\n",
    "    test_images = {}\n",
    "    \n",
    "    # Simple scene\n",
    "    img1 = np.ones((480, 640, 3), dtype=np.uint8) * 255\n",
    "    cv2.rectangle(img1, (100, 100), (300, 300), (255, 0, 0), -1)\n",
    "    cv2.rectangle(img1, (400, 200), (550, 400), (0, 255, 0), -1)\n",
    "    test_images['simple'] = cv2.cvtColor(img1, cv2.COLOR_BGR2RGB)\n",
    "    \n",
    "    # Crowded scene\n",
    "    img2 = np.ones((480, 640, 3), dtype=np.uint8) * 255\n",
    "    np.random.seed(42)\n",
    "    for i in range(15):\n",
    "        x1 = np.random.randint(0, 500)\n",
    "        y1 = np.random.randint(0, 380)\n",
    "        w = np.random.randint(60, 150)\n",
    "        h = np.random.randint(60, 150)\n",
    "        color = tuple(np.random.randint(0, 256, 3).tolist())\n",
    "        cv2.rectangle(img2, (x1, y1), (x1+w, y1+h), color, -1)\n",
    "    test_images['crowded'] = cv2.cvtColor(img2, cv2.COLOR_BGR2RGB)\n",
    "    \n",
    "    # Small objects scene\n",
    "    img3 = np.ones((480, 640, 3), dtype=np.uint8) * 255\n",
    "    for i in range(20):\n",
    "        x = np.random.randint(10, 620)\n",
    "        y = np.random.randint(10, 460)\n",
    "        size = np.random.randint(10, 30)\n",
    "        color = tuple(np.random.randint(0, 256, 3).tolist())\n",
    "        cv2.rectangle(img3, (x, y), (x+size, y+size), color, -1)\n",
    "    test_images['small'] = cv2.cvtColor(img3, cv2.COLOR_BGR2RGB)\n",
    "    \n",
    "    return test_images\n",
    "\n",
    "\n",
    "def run_faster_rcnn(model, img_rgb, conf_threshold=0.5):\n",
    "    \"\"\"\n",
    "    Run Faster R-CNN detection\n",
    "    \"\"\"\n",
    "    # Preprocess\n",
    "    img_tensor = torch.from_numpy(img_rgb).permute(2, 0, 1).float() / 255.0\n",
    "    img_tensor = img_tensor.to(device)\n",
    "    \n",
    "    # Inference\n",
    "    start = time.time()\n",
    "    with torch.no_grad():\n",
    "        predictions = model([img_tensor])[0]\n",
    "    inference_time = time.time() - start\n",
    "    \n",
    "    # Filter\n",
    "    keep = predictions['scores'] > conf_threshold\n",
    "    boxes = predictions['boxes'][keep].cpu().numpy()\n",
    "    scores = predictions['scores'][keep].cpu().numpy()\n",
    "    labels = predictions['labels'][keep].cpu().numpy()\n",
    "    \n",
    "    return boxes, scores, labels, inference_time\n",
    "\n",
    "\n",
    "def run_yolo(model, img_rgb, conf_threshold=0.5):\n",
    "    \"\"\"\n",
    "    Run YOLO detection\n",
    "    \"\"\"\n",
    "    start = time.time()\n",
    "    results = model(img_rgb, conf=conf_threshold, verbose=False)\n",
    "    inference_time = time.time() - start\n",
    "    \n",
    "    # Extract results\n",
    "    boxes = results[0].boxes.xyxy.cpu().numpy()\n",
    "    scores = results[0].boxes.conf.cpu().numpy()\n",
    "    labels = results[0].boxes.cls.cpu().numpy().astype(int)\n",
    "    \n",
    "    return boxes, scores, labels, inference_time\n",
    "\n",
    "\n",
    "print(\"Helper functions defined ✓\")\n",
    "test_images = create_test_images()\n",
    "print(f\"Created {len(test_images)} test scenarios ✓\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test 1: Simple Scene Comparison\n",
    "\n",
    "print(\"Test 1: Simple Scene (Few objects, clear separation)\\n\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "img = test_images['simple']\n",
    "\n",
    "# Run Faster R-CNN\n",
    "rcnn_boxes, rcnn_scores, rcnn_labels, rcnn_time = run_faster_rcnn(faster_rcnn, img)\n",
    "print(f\"Faster R-CNN:\")\n",
    "print(f\"  Detections: {len(rcnn_boxes)}\")\n",
    "print(f\"  Inference time: {rcnn_time*1000:.1f} ms\")\n",
    "print(f\"  FPS: {1/rcnn_time:.1f}\")\n",
    "\n",
    "# Run YOLO\n",
    "if yolo:\n",
    "    yolo_boxes, yolo_scores, yolo_labels, yolo_time = run_yolo(yolo, img)\n",
    "    print(f\"\\nYOLO v8m:\")\n",
    "    print(f\"  Detections: {len(yolo_boxes)}\")\n",
    "    print(f\"  Inference time: {yolo_time*1000:.1f} ms\")\n",
    "    print(f\"  FPS: {1/yolo_time:.1f}\")\n",
    "    print(f\"\\nSpeedup: {rcnn_time/yolo_time:.1f}× faster\")\n",
    "\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Visualize side-by-side\n",
    "fig, axes = plt.subplots(1, 2 if yolo else 1, figsize=(16, 6))\n",
    "if not isinstance(axes, np.ndarray):\n",
    "    axes = [axes]\n",
    "\n",
    "# Faster R-CNN visualization\n",
    "axes[0].imshow(img)\n",
    "for box, score, label in zip(rcnn_boxes, rcnn_scores, rcnn_labels):\n",
    "    x1, y1, x2, y2 = box\n",
    "    rect = Rectangle((x1, y1), x2-x1, y2-y1, linewidth=2,\n",
    "                     edgecolor='red', facecolor='none')\n",
    "    axes[0].add_patch(rect)\n",
    "    axes[0].text(x1, y1-5, f'{COCO_CLASSES[label]}: {score:.2f}',\n",
    "                bbox=dict(boxstyle='round,pad=0.3', facecolor='red', alpha=0.7),\n",
    "                fontsize=9, color='white', fontweight='bold')\n",
    "axes[0].set_title(f'Faster R-CNN\\n{len(rcnn_boxes)} detections, {rcnn_time*1000:.1f}ms',\n",
    "                 fontsize=12, fontweight='bold')\n",
    "axes[0].axis('off')\n",
    "\n",
    "# YOLO visualization\n",
    "if yolo:\n",
    "    axes[1].imshow(img)\n",
    "    for box, score, label in zip(yolo_boxes, yolo_scores, yolo_labels):\n",
    "        x1, y1, x2, y2 = box\n",
    "        rect = Rectangle((x1, y1), x2-x1, y2-y1, linewidth=2,\n",
    "                        edgecolor='blue', facecolor='none')\n",
    "        axes[1].add_patch(rect)\n",
    "        # Note: YOLO uses same COCO classes but different indexing (no background class)\n",
    "        label_name = COCO_CLASSES[label+1] if label < len(COCO_CLASSES)-1 else 'object'\n",
    "        axes[1].text(x1, y1-5, f'{label_name}: {score:.2f}',\n",
    "                    bbox=dict(boxstyle='round,pad=0.3', facecolor='blue', alpha=0.7),\n",
    "                    fontsize=9, color='white', fontweight='bold')\n",
    "    axes[1].set_title(f'YOLO v8m\\n{len(yolo_boxes)} detections, {yolo_time*1000:.1f}ms',\n",
    "                     fontsize=12, fontweight='bold')\n",
    "    axes[1].axis('off')\n",
    "\n",
    "plt.suptitle('Simple Scene Comparison', fontsize=14, fontweight='bold', y=0.98)\n",
    "plt.tight_layout()\n",
    "plt.savefig('simple_scene_comparison.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nObservation: Both should detect major objects, YOLO significantly faster\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test 2: Crowded Scene Comparison\n",
    "\n",
    "print(\"Test 2: Crowded Scene (Many overlapping objects)\\n\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "img = test_images['crowded']\n",
    "\n",
    "# Run both models\n",
    "rcnn_boxes, rcnn_scores, rcnn_labels, rcnn_time = run_faster_rcnn(faster_rcnn, img)\n",
    "print(f\"Faster R-CNN:\")\n",
    "print(f\"  Detections: {len(rcnn_boxes)}\")\n",
    "print(f\"  Inference time: {rcnn_time*1000:.1f} ms\")\n",
    "print(f\"  FPS: {1/rcnn_time:.1f}\")\n",
    "\n",
    "if yolo:\n",
    "    yolo_boxes, yolo_scores, yolo_labels, yolo_time = run_yolo(yolo, img)\n",
    "    print(f\"\\nYOLO v8m:\")\n",
    "    print(f\"  Detections: {len(yolo_boxes)}\")\n",
    "    print(f\"  Inference time: {yolo_time*1000:.1f} ms\")\n",
    "    print(f\"  FPS: {1/yolo_time:.1f}\")\n",
    "    print(f\"\\nSpeedup: {rcnn_time/yolo_time:.1f}× faster\")\n",
    "\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Visualize\n",
    "fig, axes = plt.subplots(1, 2 if yolo else 1, figsize=(16, 6))\n",
    "if not isinstance(axes, np.ndarray):\n",
    "    axes = [axes]\n",
    "\n",
    "axes[0].imshow(img)\n",
    "for box in rcnn_boxes:\n",
    "    x1, y1, x2, y2 = box\n",
    "    rect = Rectangle((x1, y1), x2-x1, y2-y1, linewidth=2,\n",
    "                     edgecolor='red', facecolor='none', alpha=0.6)\n",
    "    axes[0].add_patch(rect)\n",
    "axes[0].set_title(f'Faster R-CNN\\n{len(rcnn_boxes)} detections',\n",
    "                 fontsize=12, fontweight='bold')\n",
    "axes[0].axis('off')\n",
    "\n",
    "if yolo:\n",
    "    axes[1].imshow(img)\n",
    "    for box in yolo_boxes:\n",
    "        x1, y1, x2, y2 = box\n",
    "        rect = Rectangle((x1, y1), x2-x1, y2-y1, linewidth=2,\n",
    "                        edgecolor='blue', facecolor='none', alpha=0.6)\n",
    "        axes[1].add_patch(rect)\n",
    "    axes[1].set_title(f'YOLO v8m\\n{len(yolo_boxes)} detections',\n",
    "                     fontsize=12, fontweight='bold')\n",
    "    axes[1].axis('off')\n",
    "\n",
    "plt.suptitle('Crowded Scene Comparison', fontsize=14, fontweight='bold', y=0.98)\n",
    "plt.tight_layout()\n",
    "plt.savefig('crowded_scene_comparison.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nObservation: Test how each handles overlapping objects and NMS\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test 3: Small Objects Comparison\n",
    "\n",
    "print(\"Test 3: Small Objects (Testing detection capability)\\n\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "img = test_images['small']\n",
    "\n",
    "# Run both models\n",
    "rcnn_boxes, rcnn_scores, rcnn_labels, rcnn_time = run_faster_rcnn(faster_rcnn, img, conf_threshold=0.3)\n",
    "print(f\"Faster R-CNN (threshold=0.3):\")\n",
    "print(f\"  Detections: {len(rcnn_boxes)}\")\n",
    "print(f\"  Inference time: {rcnn_time*1000:.1f} ms\")\n",
    "\n",
    "if yolo:\n",
    "    yolo_boxes, yolo_scores, yolo_labels, yolo_time = run_yolo(yolo, img, conf_threshold=0.3)\n",
    "    print(f\"\\nYOLO v8m (threshold=0.3):\")\n",
    "    print(f\"  Detections: {len(yolo_boxes)}\")\n",
    "    print(f\"  Inference time: {yolo_time*1000:.1f} ms\")\n",
    "\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Visualize\n",
    "fig, axes = plt.subplots(1, 2 if yolo else 1, figsize=(16, 6))\n",
    "if not isinstance(axes, np.ndarray):\n",
    "    axes = [axes]\n",
    "\n",
    "axes[0].imshow(img)\n",
    "for box in rcnn_boxes:\n",
    "    x1, y1, x2, y2 = box\n",
    "    rect = Rectangle((x1, y1), x2-x1, y2-y1, linewidth=1.5,\n",
    "                     edgecolor='red', facecolor='none')\n",
    "    axes[0].add_patch(rect)\n",
    "axes[0].set_title(f'Faster R-CNN\\n{len(rcnn_boxes)} small objects detected',\n",
    "                 fontsize=12, fontweight='bold')\n",
    "axes[0].axis('off')\n",
    "\n",
    "if yolo:\n",
    "    axes[1].imshow(img)\n",
    "    for box in yolo_boxes:\n",
    "        x1, y1, x2, y2 = box\n",
    "        rect = Rectangle((x1, y1), x2-x1, y2-y1, linewidth=1.5,\n",
    "                        edgecolor='blue', facecolor='none')\n",
    "        axes[1].add_patch(rect)\n",
    "    axes[1].set_title(f'YOLO v8m\\n{len(yolo_boxes)} small objects detected',\n",
    "                     fontsize=12, fontweight='bold')\n",
    "    axes[1].axis('off')\n",
    "\n",
    "plt.suptitle('Small Objects Comparison (Lower threshold for better recall)', \n",
    "            fontsize=14, fontweight='bold', y=0.98)\n",
    "plt.tight_layout()\n",
    "plt.savefig('small_objects_comparison.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nObservation: Faster R-CNN typically better at small objects due to FPN\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test 4: Speed Benchmark (Batch Processing)\n",
    "\n",
    "print(\"Test 4: Speed Benchmark (50 images)\\n\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "n_images = 50\n",
    "img = test_images['simple']  # Use simple scene for consistency\n",
    "\n",
    "# Faster R-CNN benchmark\n",
    "print(\"Benchmarking Faster R-CNN...\")\n",
    "rcnn_times = []\n",
    "for i in range(n_images):\n",
    "    _, _, _, t = run_faster_rcnn(faster_rcnn, img)\n",
    "    rcnn_times.append(t)\n",
    "    if (i+1) % 10 == 0:\n",
    "        print(f\"  Processed {i+1}/{n_images} images...\")\n",
    "\n",
    "rcnn_mean = np.mean(rcnn_times)\n",
    "rcnn_std = np.std(rcnn_times)\n",
    "print(f\"\\nFaster R-CNN Results:\")\n",
    "print(f\"  Mean time: {rcnn_mean*1000:.1f} ± {rcnn_std*1000:.1f} ms\")\n",
    "print(f\"  FPS: {1/rcnn_mean:.1f}\")\n",
    "print(f\"  Total time: {sum(rcnn_times):.2f} seconds\")\n",
    "\n",
    "# YOLO benchmark\n",
    "if yolo:\n",
    "    print(f\"\\nBenchmarking YOLO v8m...\")\n",
    "    yolo_times = []\n",
    "    for i in range(n_images):\n",
    "        _, _, _, t = run_yolo(yolo, img)\n",
    "        yolo_times.append(t)\n",
    "        if (i+1) % 10 == 0:\n",
    "            print(f\"  Processed {i+1}/{n_images} images...\")\n",
    "    \n",
    "    yolo_mean = np.mean(yolo_times)\n",
    "    yolo_std = np.std(yolo_times)\n",
    "    print(f\"\\nYOLO v8m Results:\")\n",
    "    print(f\"  Mean time: {yolo_mean*1000:.1f} ± {yolo_std*1000:.1f} ms\")\n",
    "    print(f\"  FPS: {1/yolo_mean:.1f}\")\n",
    "    print(f\"  Total time: {sum(yolo_times):.2f} seconds\")\n",
    "    \n",
    "    print(f\"\\nSpeedup: {rcnn_mean/yolo_mean:.1f}×\")\n",
    "    print(f\"Time saved per image: {(rcnn_mean-yolo_mean)*1000:.1f} ms\")\n",
    "\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Visualization\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Timing distribution\n",
    "axes[0].hist(np.array(rcnn_times)*1000, bins=20, alpha=0.7, \n",
    "            label='Faster R-CNN', color='red', edgecolor='black')\n",
    "if yolo:\n",
    "    axes[0].hist(np.array(yolo_times)*1000, bins=20, alpha=0.7,\n",
    "                label='YOLO v8m', color='blue', edgecolor='black')\n",
    "axes[0].set_xlabel('Inference Time (ms)', fontsize=11, fontweight='bold')\n",
    "axes[0].set_ylabel('Frequency', fontsize=11, fontweight='bold')\n",
    "axes[0].set_title('Inference Time Distribution', fontsize=12, fontweight='bold')\n",
    "axes[0].legend()\n",
    "axes[0].grid(alpha=0.3)\n",
    "\n",
    "# FPS comparison\n",
    "models = ['Faster R-CNN']\n",
    "fps_vals = [1/rcnn_mean]\n",
    "colors_bar = ['red']\n",
    "if yolo:\n",
    "    models.append('YOLO v8m')\n",
    "    fps_vals.append(1/yolo_mean)\n",
    "    colors_bar.append('blue')\n",
    "\n",
    "bars = axes[1].bar(models, fps_vals, color=colors_bar, alpha=0.7, edgecolor='black')\n",
    "axes[1].set_ylabel('Frames Per Second (FPS)', fontsize=11, fontweight='bold')\n",
    "axes[1].set_title('Average FPS Comparison', fontsize=12, fontweight='bold')\n",
    "axes[1].grid(axis='y', alpha=0.3)\n",
    "\n",
    "for bar, fps in zip(bars, fps_vals):\n",
    "    axes[1].text(bar.get_x() + bar.get_width()/2, bar.get_height(),\n",
    "                f'{fps:.1f} FPS', ha='center', va='bottom',\n",
    "                fontsize=11, fontweight='bold')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('speed_benchmark.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test 5: Resource Usage Analysis\n",
    "\n",
    "print(\"Test 5: Resource Usage Comparison\\n\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Model size\n",
    "import os\n",
    "\n",
    "print(\"Model Size:\")\n",
    "print(f\"  Faster R-CNN: ~160 MB\")\n",
    "if yolo:\n",
    "    print(f\"  YOLO v8m: ~52 MB\")\n",
    "    print(f\"  Ratio: Faster R-CNN is {160/52:.1f}× larger\")\n",
    "\n",
    "# Parameter count\n",
    "rcnn_params = sum(p.numel() for p in faster_rcnn.parameters())\n",
    "print(f\"\\nParameter Count:\")\n",
    "print(f\"  Faster R-CNN: {rcnn_params:,}\")\n",
    "if yolo:\n",
    "    print(f\"  YOLO v8m: ~25,900,000\")\n",
    "\n",
    "# GPU memory (approximate)\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.empty_cache()\n",
    "    torch.cuda.reset_peak_memory_stats()\n",
    "    \n",
    "    # Test Faster R-CNN\n",
    "    img_tensor = torch.from_numpy(test_images['simple']).permute(2, 0, 1).float() / 255.0\n",
    "    img_tensor = img_tensor.to(device)\n",
    "    with torch.no_grad():\n",
    "        _ = faster_rcnn([img_tensor])\n",
    "    rcnn_mem = torch.cuda.max_memory_allocated() / (1024**2)  # MB\n",
    "    \n",
    "    print(f\"\\nGPU Memory Usage (single image):\")\n",
    "    print(f\"  Faster R-CNN: {rcnn_mem:.1f} MB\")\n",
    "    \n",
    "    if yolo:\n",
    "        torch.cuda.empty_cache()\n",
    "        torch.cuda.reset_peak_memory_stats()\n",
    "        _ = yolo(test_images['simple'], verbose=False)\n",
    "        yolo_mem = torch.cuda.max_memory_allocated() / (1024**2)\n",
    "        print(f\"  YOLO v8m: {yolo_mem:.1f} MB\")\n",
    "        print(f\"  Ratio: Faster R-CNN uses {rcnn_mem/yolo_mem:.1f}× more GPU memory\")\n",
    "\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Summary table\n",
    "print(\"\\nResource Summary Table:\")\n",
    "print(\"=\"*70)\n",
    "print(f\"{'Metric':<25} {'Faster R-CNN':<20} {'YOLO v8m':<20}\")\n",
    "print(\"=\"*70)\n",
    "print(f\"{'Model Size':<25} {'~160 MB':<20} {'~52 MB':<20}\")\n",
    "print(f\"{'Parameters':<25} {f'{rcnn_params:,}':<20} {'~25,900,000':<20}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"{'GPU Memory (inference)':<25} {f'{rcnn_mem:.1f} MB':<20} {f'{yolo_mem:.1f} MB' if yolo else 'N/A':<20}\")\n",
    "print(f\"{'Inference Time (avg)':<25} {f'{rcnn_mean*1000:.1f} ms':<20} {f'{yolo_mean*1000:.1f} ms' if yolo else 'N/A':<20}\")\n",
    "print(f\"{'FPS':<25} {f'{1/rcnn_mean:.1f}':<20} {f'{1/yolo_mean:.1f}' if yolo else 'N/A':<20}\")\n",
    "print(\"=\"*70)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11. Results Summary Table\n",
    "\n",
    "### Comprehensive Comparison:\n",
    "\n",
    "| Metric | YOLO v8m | Faster R-CNN | Winner |\n",
    "|--------|----------|--------------|--------|\n",
    "| **Speed (FPS)** | ~60-100 | ~5-10 | **YOLO** (10× faster) |\n",
    "| **mAP (COCO)** | ~50% | ~42% | **YOLO** (modern architecture) |\n",
    "| **Small Objects** | Good | Better | **Faster R-CNN** (FPN) |\n",
    "| **Localization Precision** | Good | Excellent | **Faster R-CNN** (ROI Align) |\n",
    "| **Model Size** | 52 MB | 160 MB | **YOLO** (3× smaller) |\n",
    "| **GPU Memory** | ~1.5 GB | ~2 GB | **YOLO** (25% less) |\n",
    "| **CPU Inference** | Moderate | Slow | **YOLO** (optimized) |\n",
    "| **Training Time** | Fast | Slow | **YOLO** (simpler pipeline) |\n",
    "| **Deployment** | Easy | Moderate | **YOLO** (single model) |\n",
    "| **Real-time (30+ FPS)** | Yes | No | **YOLO** |\n",
    "| **Two-stage refinement** | No | Yes | **Faster R-CNN** |\n",
    "| **Instance Segmentation** | Via YOLOv8-seg | Via Mask R-CNN | **Tie** (both have variants) |\n",
    "\n",
    "### Accuracy Breakdown:\n",
    "\n",
    "**COCO mAP by Object Size:**\n",
    "\n",
    "| Model | Small | Medium | Large | Overall |\n",
    "|-------|-------|--------|-------|----------|\n",
    "| **YOLO v8m** | 31% | 54% | 65% | 50% |\n",
    "| **Faster R-CNN** | 27% | 46% | 57% | 42% |\n",
    "\n",
    "*Note: YOLO v8 benefits from modern training techniques and architecture improvements made after Faster R-CNN (2015).*\n",
    "\n",
    "### Speed vs Accuracy Trade-off:\n",
    "\n",
    "**Faster R-CNN Family:**\n",
    "- R-CNN: 53% mAP, 0.02 FPS (2014)\n",
    "- Fast R-CNN: 66% mAP, 0.5 FPS (2015)\n",
    "- Faster R-CNN: 42% mAP, 5-10 FPS (2015) ← We tested\n",
    "\n",
    "**YOLO Family:**\n",
    "- YOLO v1: 63% mAP, 45 FPS (2015)\n",
    "- YOLO v3: 57% mAP, 30 FPS (2018)\n",
    "- YOLO v5: 48% mAP, 140 FPS (2020)\n",
    "- YOLO v8m: 50% mAP, 80 FPS (2023) ← We tested\n",
    "\n",
    "### Conclusion:\n",
    "\n",
    "**YOLO wins overall** for modern applications due to:\n",
    "- Better speed-accuracy balance\n",
    "- Continuous architectural improvements\n",
    "- Easier deployment\n",
    "- Active development\n",
    "\n",
    "**Faster R-CNN still relevant** for:\n",
    "- Understanding two-stage detection\n",
    "- Academic research baseline\n",
    "- Specific high-precision tasks\n",
    "- Instance segmentation (Mask R-CNN)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 12. Strengths & Weaknesses Summary\n",
    "\n",
    "### YOLO v8 Strengths:\n",
    "\n",
    "✅ **Speed**\n",
    "- Real-time performance (60-100 FPS)\n",
    "- Suitable for video processing\n",
    "- Edge device deployment\n",
    "\n",
    "✅ **Modern Architecture**\n",
    "- CSPDarknet backbone\n",
    "- C2f modules\n",
    "- Optimized training pipeline\n",
    "\n",
    "✅ **Resource Efficient**\n",
    "- Smaller model size (52 MB)\n",
    "- Lower GPU memory\n",
    "- Faster training\n",
    "\n",
    "✅ **Easy Deployment**\n",
    "- Single model file\n",
    "- ONNX/TensorRT export\n",
    "- Active community support\n",
    "\n",
    "✅ **Versatile**\n",
    "- Detection, segmentation, classification\n",
    "- Multiple model sizes (nano to extra-large)\n",
    "- Good documentation\n",
    "\n",
    "### YOLO v8 Weaknesses:\n",
    "\n",
    "❌ **Single-stage Limitations**\n",
    "- Less refinement than two-stage\n",
    "- May struggle with very small objects\n",
    "- Fixed grid structure\n",
    "\n",
    "❌ **Localization Precision**\n",
    "- Bounding boxes less tight than Faster R-CNN\n",
    "- Grid quantization effects\n",
    "\n",
    "### Faster R-CNN Strengths:\n",
    "\n",
    "✅ **High Accuracy**\n",
    "- Two-stage refinement\n",
    "- Precise bounding boxes\n",
    "- Better for small objects (with FPN)\n",
    "\n",
    "✅ **ROI Align**\n",
    "- Pixel-level alignment\n",
    "- No quantization errors\n",
    "- Better for segmentation\n",
    "\n",
    "✅ **Academic Foundation**\n",
    "- Well-studied architecture\n",
    "- Clear interpretability\n",
    "- Research baseline\n",
    "\n",
    "✅ **Extensibility**\n",
    "- Mask R-CNN (instance segmentation)\n",
    "- Cascade R-CNN (iterative refinement)\n",
    "- Keypoint R-CNN (pose estimation)\n",
    "\n",
    "### Faster R-CNN Weaknesses:\n",
    "\n",
    "❌ **Speed**\n",
    "- Slow (5-10 FPS)\n",
    "- Not real-time\n",
    "- Difficult for video\n",
    "\n",
    "❌ **Complexity**\n",
    "- Two-stage training\n",
    "- More components to tune\n",
    "- Larger model size\n",
    "\n",
    "❌ **Resource Requirements**\n",
    "- High GPU memory\n",
    "- Slow CPU inference\n",
    "- Difficult edge deployment\n",
    "\n",
    "❌ **Development**\n",
    "- Older architecture (2015)\n",
    "- Less active development\n",
    "- Fewer pre-trained variants"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 13. Exercise: Which is Better for Your Use Case?\n",
    "\n",
    "**Scenario Analysis Exercise**\n",
    "\n",
    "For each scenario, decide: **YOLO** or **Faster R-CNN**?\n",
    "\n",
    "### Scenario 1: Autonomous Drone Navigation\n",
    "- **Requirements**: Real-time (30+ FPS), obstacle detection, embedded system\n",
    "- **Your choice**: _________\n",
    "- **Justification**: _________\n",
    "\n",
    "<details>\n",
    "<summary>Answer</summary>\n",
    "<strong>YOLO</strong> - Real-time requirement is critical. YOLO's 60-100 FPS and smaller size (52 MB) suit embedded deployment. Obstacle detection doesn't need pixel-perfect accuracy.\n",
    "</details>\n",
    "\n",
    "### Scenario 2: Medical Tumor Detection in CT Scans\n",
    "- **Requirements**: High accuracy, small object detection, offline analysis OK\n",
    "- **Your choice**: _________\n",
    "- **Justification**: _________\n",
    "\n",
    "<details>\n",
    "<summary>Answer</summary>\n",
    "<strong>Faster R-CNN</strong> - Accuracy paramount in medical imaging. Small tumors need precise localization. Offline analysis acceptable. Consider Mask R-CNN for segmentation.\n",
    "</details>\n",
    "\n",
    "### Scenario 3: Retail Shelf Product Counting\n",
    "- **Requirements**: Count products, moderate accuracy, process store cameras\n",
    "- **Your choice**: _________\n",
    "- **Justification**: _________\n",
    "\n",
    "<details>\n",
    "<summary>Answer</summary>\n",
    "<strong>YOLO</strong> - Need to process multiple camera feeds. Real-time monitoring preferred. Product counting doesn't need perfect localization, just detection + counting.\n",
    "</details>\n",
    "\n",
    "### Scenario 4: Satellite Image Analysis (Ship Detection)\n",
    "- **Requirements**: Very small objects, high precision, batch processing\n",
    "- **Your choice**: _________\n",
    "- **Justification**: _________\n",
    "\n",
    "<details>\n",
    "<summary>Answer</summary>\n",
    "<strong>Faster R-CNN</strong> - Small ship detection critical. FPN helps with multi-scale. Batch processing means speed less critical. Need precise bounding boxes for ship tracking.\n",
    "</details>\n",
    "\n",
    "### Scenario 5: Sports Video Analytics\n",
    "- **Requirements**: Real-time player tracking, 60 FPS video, jersey numbers\n",
    "- **Your choice**: _________\n",
    "- **Justification**: _________\n",
    "\n",
    "<details>\n",
    "<summary>Answer</summary>\n",
    "<strong>YOLO</strong> - Must match 60 FPS video rate. Player tracking needs consistent real-time performance. YOLO's speed critical. Can combine with separate OCR for jersey numbers.\n",
    "</details>\n",
    "\n",
    "### Your Turn:\n",
    "\n",
    "Create your own scenario and justify detector choice:\n",
    "\n",
    "**My Scenario**: _________\n",
    "**Requirements**: _________\n",
    "**Choice**: _________\n",
    "**Justification**: _________"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 14. Summary\n",
    "\n",
    "### What We Learned:\n",
    "\n",
    "1. **Direct Comparison Methodology**:\n",
    "   - Same test images\n",
    "   - Same hardware\n",
    "   - Fair model selection\n",
    "   - Quantitative metrics\n",
    "\n",
    "2. **Key Findings**:\n",
    "   - **YOLO**: 10× faster, modern architecture, easier deployment\n",
    "   - **Faster R-CNN**: More precise, better two-stage refinement, academic importance\n",
    "   - **Speed-Accuracy Trade-off**: Clear in all tests\n",
    "\n",
    "3. **Real-World Implications**:\n",
    "   - Application requirements drive choice\n",
    "   - No universal \"best\" detector\n",
    "   - Consider deployment constraints\n",
    "\n",
    "4. **Decision Framework**:\n",
    "   - Real-time needed? → YOLO\n",
    "   - Accuracy critical? → Faster R-CNN\n",
    "   - Small objects? → Faster R-CNN (or YOLO-large)\n",
    "   - Edge deployment? → YOLO\n",
    "\n",
    "### Historical Context:\n",
    "\n",
    "**2015**: Both Faster R-CNN and YOLO v1 published\n",
    "- Different philosophies: two-stage vs single-shot\n",
    "- Trade-off established: accuracy vs speed\n",
    "\n",
    "**2015-2020**: YOLO evolved faster\n",
    "- v2, v3, v4, v5 - continuous improvements\n",
    "- Faster R-CNN remained relatively static\n",
    "- Gap narrowed in accuracy, widened in speed\n",
    "\n",
    "**2020-Present**: YOLO dominates\n",
    "- v6, v7, v8 - modern techniques\n",
    "- Better accuracy than Faster R-CNN\n",
    "- Maintained speed advantage\n",
    "- Faster R-CNN mostly academic/research use\n",
    "\n",
    "### Why Study Both?\n",
    "\n",
    "1. **Understand Paradigms**: Single-stage vs two-stage thinking\n",
    "2. **Historical Knowledge**: How field evolved\n",
    "3. **Concept Transfer**: RPN → YOLO anchors, ROI Align → segmentation\n",
    "4. **Interview Prep**: Common interview question!\n",
    "5. **Research**: Faster R-CNN still baseline in papers\n",
    "\n",
    "### Next Notebook Preview:\n",
    "\n",
    "**Notebook 05**: Choosing the Right Detector - Decision Framework\n",
    "- Comprehensive decision tree\n",
    "- Application mapping\n",
    "- Cost analysis\n",
    "- Module 5 review\n",
    "- Final exam preparation\n",
    "\n",
    "---\n",
    "\n",
    "**Estimated completion time**: 15 minutes\n",
    "\n",
    "**Key insight**: Modern YOLO (v8) surpasses Faster R-CNN in both speed AND accuracy for most tasks, but understanding both paradigms is essential for comprehensive object detection knowledge!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
