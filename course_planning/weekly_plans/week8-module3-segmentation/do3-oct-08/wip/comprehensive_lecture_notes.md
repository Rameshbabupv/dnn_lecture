# Week 8 - Image Segmentation Methods
## Comprehensive Lecture Notes - Module 3 (Day Order 3)

**Date:** Wednesday, October 8, 2025
**Module:** 3 - Image Processing and Deep Neural Networks
**Week:** 8 of 15
**Session:** Day Order 3, Hours 1-2 (8:00 AM - 9:40 AM)
**Duration:** 2 hours (100 minutes)
**Delivery Mode:** In-person with live demonstrations

---

## üìã Quick Reference

### Prerequisites
- **From Week 7:**
  - Image enhancement techniques (brightness, contrast, histogram equalization)
  - Noise removal methods (Gaussian blur, median filtering)
  - Edge detection algorithms (Sobel, Canny)
  - OpenCV fundamentals (`cv2.imread()`, `cv2.imshow()`, basic operations)

### Learning Outcomes Addressed
- **Primary:** CO-3 - Apply deep neural networks in image processing problems
- **Skills:** Understanding image segmentation as preprocessing for DNNs

### Assessment Integration
- **Unit Test 2 (Oct 31):** Modules 3-4 coverage
- **Tutorial T8:** Image Segmentation Using OpenCV (DO4 - Oct 9)
- **Practical evaluation:** Continuous assessment of segmentation implementations

---

## üéØ Learning Objectives

By the end of this 2-hour lecture, students will be able to:

1. **Define** image segmentation and explain its importance in computer vision pipelines
2. **Compare** different image segmentation techniques (thresholding, region-based, edge-based, clustering)
3. **Implement** basic segmentation methods using OpenCV (thresholding, watershed, contours)
4. **Analyze** when to apply specific segmentation techniques based on image characteristics
5. **Evaluate** segmentation quality and understand common challenges
6. **Connect** segmentation to deep learning preprocessing (preparation for CNNs in Module 4)

**Opening Hook:**
*"When you unlock your phone with face recognition, how does the AI know where your face is in the image? The answer is IMAGE SEGMENTATION - the bridge between raw pixels and intelligent understanding. Today, we'll learn how machines 'see' and separate objects from backgrounds."*

---

## üìö Part 1: Foundations (Hour 1: 50 minutes)

### Segment 1.1: What is Image Segmentation? (15 minutes)

#### üîç Core Concepts

**Definition:**
Image segmentation is the process of partitioning a digital image into multiple segments (sets of pixels) to simplify and/or change the representation of an image into something more meaningful and easier to analyze.

**Goals of Segmentation:**
1. **Simplification:** Reduce complexity while preserving essential structure
2. **Object Localization:** Find regions corresponding to objects
3. **Feature Extraction:** Prepare regions for analysis
4. **Preprocessing:** Enable higher-level tasks (recognition, classification)

**Mathematical Formulation:**
Let I be an input image, segmentation produces a partition:
```
S = {S‚ÇÅ, S‚ÇÇ, ..., S‚Çô}
```
Where:
- ‚ãÉ·µ¢ S·µ¢ = I (covers entire image)
- S·µ¢ ‚à© S‚±º = ‚àÖ for i ‚â† j (non-overlapping)
- Each S·µ¢ satisfies a homogeneity predicate P(S·µ¢) = TRUE

**Visual Aid Needed:**
- Original image ‚Üí Segmented image with color-coded regions
- Medical imaging example (tumor segmentation)
- Autonomous vehicle example (road, pedestrians, vehicles)

#### Real-World Applications

1. **Medical Imaging**
   - Tumor detection and measurement
   - Organ boundary identification
   - Cell counting in microscopy

2. **Autonomous Vehicles**
   - Road segmentation
   - Pedestrian detection
   - Traffic sign recognition

3. **Industrial Quality Control**
   - Defect detection
   - Product counting
   - Dimension measurement

4. **Agriculture**
   - Crop health monitoring
   - Weed detection
   - Fruit ripeness assessment

5. **Augmented Reality**
   - Background removal
   - Object insertion
   - Scene understanding

---

### Segment 1.2: Segmentation Taxonomy (15 minutes)

#### üîç Classification of Segmentation Techniques

**1. Thresholding-Based Methods**
- **Simple (Global) Thresholding**
- **Adaptive (Local) Thresholding**
- **Otsu's Method** (automatic threshold selection)
- **Multi-level Thresholding**

**2. Edge-Based Methods**
- Uses edge detection results (Week 7 content)
- Connects edge pixels to form boundaries
- Techniques: Active contours (Snakes), Level sets

**3. Region-Based Methods**
- **Region Growing:** Start from seed points, expand similar regions
- **Region Splitting and Merging:** Divide and conquer approach
- **Watershed Algorithm:** Topographic interpretation

**4. Clustering-Based Methods**
- **K-Means Clustering:** Group pixels by color/intensity
- **Mean Shift:** Mode-seeking algorithm
- **DBSCAN:** Density-based clustering

**5. Deep Learning Methods** (Preview for Module 4)
- Semantic Segmentation (FCN, U-Net)
- Instance Segmentation (Mask R-CNN)
- Panoptic Segmentation

**Comparison Table:**

| Method | Complexity | Speed | Best For | Limitations |
|--------|------------|-------|----------|-------------|
| Thresholding | Low | Very Fast | Bimodal images, clear contrast | Poor for complex scenes |
| Edge-Based | Medium | Fast | Well-defined boundaries | Sensitive to noise |
| Region-Based | Medium-High | Medium | Homogeneous regions | Parameter sensitive |
| Clustering | High | Slow | Color-based separation | Computationally expensive |
| Deep Learning | Very High | GPU-dependent | Complex scenes | Requires training data |

---

### Segment 1.3: Thresholding Techniques (20 minutes)

#### üîç Theory Foundation

**Global Thresholding**

The simplest segmentation method:
```
g(x, y) = {
    1  if f(x, y) ‚â• T
    0  if f(x, y) < T
}
```
Where:
- f(x, y) = input image
- T = threshold value
- g(x, y) = binary output

**How to Choose Threshold T?**
1. **Manual inspection** (histogram analysis)
2. **Trial and error**
3. **Automatic methods** (Otsu's algorithm)

**Otsu's Method (Automatic Thresholding)**

Finds threshold that **minimizes intra-class variance** (or maximizes inter-class variance):

```
œÉ¬≤within(T) = w‚ÇÄ(T)œÉ¬≤‚ÇÄ(T) + w‚ÇÅ(T)œÉ¬≤‚ÇÅ(T)
```

Where:
- w‚ÇÄ, w‚ÇÅ = probabilities of two classes
- œÉ¬≤‚ÇÄ, œÉ¬≤‚ÇÅ = variances of two classes

**Algorithm:**
1. Compute histogram of image
2. For each possible threshold T:
   - Calculate class probabilities w‚ÇÄ(T), w‚ÇÅ(T)
   - Calculate class means Œº‚ÇÄ(T), Œº‚ÇÅ(T)
   - Calculate between-class variance œÉ¬≤between(T)
3. Select T that maximizes œÉ¬≤between(T)

**Adaptive Thresholding**

Uses **different thresholds for different regions**:
- Divide image into blocks
- Calculate threshold for each block based on local statistics
- Handles varying illumination better than global thresholding

**Types:**
1. **Mean Adaptive:** T = mean of neighborhood - constant
2. **Gaussian Adaptive:** T = weighted mean (Gaussian window) - constant

#### üí° OpenCV Implementation Examples

```python
import cv2
import numpy as np
import matplotlib.pyplot as plt

# Read image
img = cv2.imread('coins.jpg', cv2.IMREAD_GRAYSCALE)

# 1. Simple Global Thresholding
ret, thresh_global = cv2.threshold(img, 127, 255, cv2.THRESH_BINARY)

# 2. Otsu's Thresholding
ret_otsu, thresh_otsu = cv2.threshold(img, 0, 255,
                                       cv2.THRESH_BINARY + cv2.THRESH_OTSU)
print(f"Otsu's optimal threshold: {ret_otsu}")

# 3. Adaptive Mean Thresholding
thresh_adaptive_mean = cv2.adaptiveThreshold(img, 255,
                                              cv2.ADAPTIVE_THRESH_MEAN_C,
                                              cv2.THRESH_BINARY, 11, 2)

# 4. Adaptive Gaussian Thresholding
thresh_adaptive_gaussian = cv2.adaptiveThreshold(img, 255,
                                                  cv2.ADAPTIVE_THRESH_GAUSSIAN_C,
                                                  cv2.THRESH_BINARY, 11, 2)

# Display results
titles = ['Original', 'Global (T=127)', 'Otsu',
          'Adaptive Mean', 'Adaptive Gaussian']
images = [img, thresh_global, thresh_otsu,
          thresh_adaptive_mean, thresh_adaptive_gaussian]

plt.figure(figsize=(15, 3))
for i in range(5):
    plt.subplot(1, 5, i+1)
    plt.imshow(images[i], cmap='gray')
    plt.title(titles[i])
    plt.axis('off')
plt.tight_layout()
plt.show()
```

**Common Use Cases:**
- Document scanning (text extraction)
- Object counting (coins, cells)
- QR code detection
- License plate recognition

---

## üîÑ Break (10 minutes)

*Students should stretch, ask questions, review code examples*

---

## üìö Part 2: Advanced Techniques (Hour 2: 50 minutes)

### Segment 2.1: Contour Detection and Analysis (20 minutes)

#### üîç What are Contours?

**Definition:**
Contours are **curves joining all continuous points along a boundary** having the same color or intensity. They are useful for:
- Shape analysis and object detection
- Object counting
- Hand gesture recognition
- Boundary detection

**Mathematical Representation:**
A contour is a sequence of points: C = [(x‚ÇÅ, y‚ÇÅ), (x‚ÇÇ, y‚ÇÇ), ..., (x‚Çô, y‚Çô)]

**Contour Properties:**
1. **Area:** Number of pixels inside contour
2. **Perimeter:** Length of contour boundary
3. **Centroid:** Center of mass
4. **Bounding Box:** Smallest rectangle enclosing contour
5. **Convex Hull:** Smallest convex polygon enclosing contour
6. **Moments:** Statistical properties for shape description

#### üí° OpenCV Contour Operations

```python
import cv2
import numpy as np

# Read and preprocess image
img = cv2.imread('shapes.jpg')
gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)
ret, thresh = cv2.threshold(gray, 127, 255, cv2.THRESH_BINARY)

# Find contours
contours, hierarchy = cv2.findContours(thresh,
                                        cv2.RETR_TREE,
                                        cv2.CHAIN_APPROX_SIMPLE)

print(f"Number of contours found: {len(contours)}")

# Draw all contours
img_contours = img.copy()
cv2.drawContours(img_contours, contours, -1, (0, 255, 0), 2)

# Analyze each contour
for i, cnt in enumerate(contours):
    # Calculate properties
    area = cv2.contourArea(cnt)
    perimeter = cv2.arcLength(cnt, True)

    # Get bounding rectangle
    x, y, w, h = cv2.boundingRect(cnt)
    cv2.rectangle(img_contours, (x, y), (x+w, y+h), (255, 0, 0), 2)

    # Calculate moments
    M = cv2.moments(cnt)
    if M['m00'] != 0:
        cx = int(M['m10']/M['m00'])  # centroid x
        cy = int(M['m01']/M['m00'])  # centroid y
        cv2.circle(img_contours, (cx, cy), 5, (0, 0, 255), -1)

    # Display info
    print(f"Contour {i}: Area={area:.2f}, Perimeter={perimeter:.2f}")

cv2.imshow('Original', img)
cv2.imshow('Contours', img_contours)
cv2.waitKey(0)
cv2.destroyAllWindows()
```

**Contour Retrieval Modes:**
- `RETR_EXTERNAL`: Only extreme outer contours
- `RETR_LIST`: All contours (no hierarchy)
- `RETR_TREE`: Full hierarchy of contours
- `RETR_CCOMP`: Two-level hierarchy

**Contour Approximation Methods:**
- `CHAIN_APPROX_NONE`: Store all boundary points
- `CHAIN_APPROX_SIMPLE`: Compress horizontal, vertical, diagonal segments

**Shape Detection Example:**
```python
def detect_shape(contour):
    """Classify shape based on contour properties"""
    # Approximate contour to polygon
    epsilon = 0.04 * cv2.arcLength(contour, True)
    approx = cv2.approxPolyDP(contour, epsilon, True)

    vertices = len(approx)

    if vertices == 3:
        return "Triangle"
    elif vertices == 4:
        # Check if rectangle or square
        x, y, w, h = cv2.boundingRect(approx)
        aspect_ratio = float(w)/h
        if 0.95 <= aspect_ratio <= 1.05:
            return "Square"
        else:
            return "Rectangle"
    elif vertices == 5:
        return "Pentagon"
    elif vertices > 5:
        # Distinguish circle from other shapes
        area = cv2.contourArea(contour)
        perimeter = cv2.arcLength(contour, True)
        circularity = 4 * np.pi * area / (perimeter ** 2)
        if circularity > 0.8:
            return "Circle"

    return "Unknown"
```

---

### Segment 2.2: Watershed Algorithm (15 minutes)

#### üîç Concept and Intuition

**Topographic Interpretation:**
Imagine the grayscale image as a **topographic surface**:
- Pixel intensity = altitude
- **Catchment basins** = regions
- **Watershed lines** = boundaries between regions

**Algorithm Metaphor:**
Think of water filling the landscape from local minima:
1. Water rises from different basins
2. When waters from different basins meet, build a dam (watershed line)
3. Continue until entire landscape is flooded
4. Dams form the segmentation boundaries

**Why Watershed is Powerful:**
- Produces **closed contours** (always connected boundaries)
- Works well for **touching/overlapping objects**
- Particularly effective for **separating connected cells, coins, etc.**

#### ‚ö†Ô∏è The Over-Segmentation Problem

**Challenge:**
Watershed is **very sensitive to noise** ‚Üí produces too many small regions

**Solution: Marker-Based Watershed**
1. Pre-process image to identify:
   - **Sure foreground** (definitely objects)
   - **Sure background** (definitely background)
   - **Unknown region** (might be boundaries)
2. Use these markers to guide watershed algorithm

#### üí° OpenCV Watershed Implementation

```python
import cv2
import numpy as np
from scipy import ndimage as ndi

# Read image
img = cv2.imread('coins.jpg')
gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)

# Step 1: Noise removal using morphological operations
kernel = np.ones((3, 3), np.uint8)
opening = cv2.morphologyEx(gray, cv2.MORPH_OPEN, kernel, iterations=2)

# Step 2: Sure background area (dilation)
sure_bg = cv2.dilate(opening, kernel, iterations=3)

# Step 3: Finding sure foreground area (distance transform + threshold)
dist_transform = cv2.distanceTransform(opening, cv2.DIST_L2, 5)
ret, sure_fg = cv2.threshold(dist_transform, 0.7*dist_transform.max(),
                               255, 0)

# Step 4: Finding unknown region
sure_fg = np.uint8(sure_fg)
unknown = cv2.subtract(sure_bg, sure_fg)

# Step 5: Marker labelling
ret, markers = cv2.connectedComponents(sure_fg)

# Add 1 to all labels (background becomes 1, not 0)
markers = markers + 1

# Mark unknown region as 0
markers[unknown == 255] = 0

# Step 6: Apply watershed
markers = cv2.watershed(img, markers)

# Mark boundaries in red
img[markers == -1] = [0, 0, 255]

# Visualize results
cv2.imshow('Original', img)
cv2.imshow('Segmented', img)
cv2.waitKey(0)
cv2.destroyAllWindows()
```

**Watershed Parameters to Tune:**
1. **Morphological kernel size:** Controls noise removal
2. **Distance transform threshold:** Defines sure foreground (0.7 is typical)
3. **Dilation iterations:** Expands sure background

**Applications:**
- Separating touching coins in images
- Cell segmentation in microscopy
- Fruit counting in agriculture
- Particle analysis

---

### Segment 2.3: K-Means Color Segmentation (15 minutes)

#### üîç Clustering-Based Segmentation

**Concept:**
Treat each pixel as a data point in **color space** (RGB, HSV, LAB):
- Group similar pixels together using clustering
- Each cluster becomes a segment
- Works well for color-based segmentation

**K-Means Algorithm:**
1. Choose K (number of clusters)
2. Initialize K cluster centers randomly
3. Assign each pixel to nearest cluster center
4. Update cluster centers as mean of assigned pixels
5. Repeat steps 3-4 until convergence

**Mathematical Formulation:**
Minimize within-cluster sum of squares:
```
argmin Œ£·µ¢‚Çå‚ÇÅ·¥∑ Œ£‚Çì‚ààS·µ¢ ||x - Œº·µ¢||¬≤
```
Where:
- K = number of clusters
- S·µ¢ = set of pixels in cluster i
- Œº·µ¢ = mean of cluster i

#### üí° OpenCV K-Means Implementation

```python
import cv2
import numpy as np
import matplotlib.pyplot as plt

def kmeans_segmentation(img, K=3):
    """
    Perform K-means color segmentation

    Args:
        img: Input image (BGR)
        K: Number of clusters

    Returns:
        Segmented image
    """
    # Reshape image to 2D array of pixels
    pixel_values = img.reshape((-1, 3))
    pixel_values = np.float32(pixel_values)

    # Define criteria and apply K-means
    criteria = (cv2.TERM_CRITERIA_EPS + cv2.TERM_CRITERIA_MAX_ITER,
                100, 0.2)

    _, labels, centers = cv2.kmeans(pixel_values, K, None,
                                     criteria, 10,
                                     cv2.KMEANS_RANDOM_CENTERS)

    # Convert centers to uint8
    centers = np.uint8(centers)

    # Flatten labels array
    labels = labels.flatten()

    # Create segmented image
    segmented_img = centers[labels]
    segmented_img = segmented_img.reshape(img.shape)

    return segmented_img, labels.reshape(img.shape[:2])

# Load image
img = cv2.imread('landscape.jpg')
img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)

# Try different K values
K_values = [2, 3, 5, 8]
plt.figure(figsize=(15, 8))

plt.subplot(2, 3, 1)
plt.imshow(img_rgb)
plt.title('Original Image')
plt.axis('off')

for i, K in enumerate(K_values):
    segmented, labels = kmeans_segmentation(img, K)
    segmented_rgb = cv2.cvtColor(segmented, cv2.COLOR_BGR2RGB)

    plt.subplot(2, 3, i+2)
    plt.imshow(segmented_rgb)
    plt.title(f'K = {K} clusters')
    plt.axis('off')

plt.tight_layout()
plt.show()
```

**Advantages:**
- Simple and intuitive
- Works well for color-based segmentation
- Fast for small K values

**Limitations:**
- Need to specify K (number of clusters) manually
- Sensitive to initialization
- Not good for spatial relationships
- Computationally expensive for large images

**Tips for Better Results:**
1. **Convert to LAB color space** (more perceptually uniform)
2. **Include spatial coordinates** as features: [x, y, R, G, B]
3. **Preprocess image** (blur to reduce noise)
4. **Try multiple K values** and evaluate

---

## üîÑ Wrap-up & Synthesis (10 minutes)

### Key Takeaways

**1. Segmentation is Essential for Computer Vision**
- Converts raw pixels into meaningful regions
- Bridge between low-level processing and high-level understanding
- Critical preprocessing step for deep learning (Module 4)

**2. Multiple Techniques, Different Strengths**

| When to Use | Technique | Key Advantage |
|-------------|-----------|---------------|
| Simple, high contrast | Thresholding | Fast, easy |
| Text, documents | Adaptive thresholding | Handles varying illumination |
| Shape detection | Contours | Rich geometric properties |
| Touching objects | Watershed | Separates connected regions |
| Color-based | K-Means | Intuitive, color clustering |

**3. No Single "Best" Method**
- Choose based on:
  - Image characteristics (contrast, noise, complexity)
  - Application requirements (speed, accuracy)
  - Available computational resources
- Often **combine multiple techniques** for best results

**4. Preprocessing is Critical**
- Noise removal (from Week 7)
- Morphological operations
- Edge enhancement
- *Garbage in = Garbage out*

**5. Connection to Deep Learning**
- Traditional methods: Manual feature engineering
- Deep learning (coming in Module 4): Automatic feature learning
- But traditional methods still valuable for:
  - Preprocessing
  - Post-processing
  - Situations with limited training data

---

### Next Session Preview

**Tomorrow (DO4 - Oct 9): Tutorial T8**
- **Hands-on implementation** of all techniques covered today
- **Live coding session** with OpenCV
- **Real datasets:** Medical images, satellite imagery, industrial inspection
- **Assignment:** Implement segmentation pipeline for specific application

**Upcoming (Week 8-9):**
- **ROI Segmentation** (Region of Interest extraction)
- **Morphological Processing** (erosion, dilation, opening, closing)
- **Feature Extraction** (shape descriptors, texture, color)
- Leading to **CNNs in Module 4** (Week 10)

---

### Preparation for Tutorial T8

**Required Setup:**
- [ ] Python 3.8+ with OpenCV installed
- [ ] Google Colab account (recommended)
- [ ] Download sample images from course portal
- [ ] Review Week 7 OpenCV basics

**Pre-Tutorial Exercise:**
Try implementing simple global thresholding on your own image:
```python
import cv2
img = cv2.imread('your_image.jpg', cv2.IMREAD_GRAYSCALE)
_, thresh = cv2.threshold(img, 127, 255, cv2.THRESH_BINARY)
cv2.imshow('Result', thresh)
cv2.waitKey(0)
```

**Assignment Due (Oct 15):**
- **Topic:** Comparative analysis of segmentation methods
- **Deliverable:** Jupyter notebook + report
- **Dataset:** Provided on course portal
- **Focus:** Apply 3+ techniques, compare results, justify choices

---

## üì¶ Resources & References

### Essential Reading
1. **Chollet, F.** "Deep Learning with Python" (2021)
   - Chapter 5: Computer Vision basics

2. **Gonzalez & Woods** "Digital Image Processing" (4th Ed)
   - Chapter 10: Image Segmentation

3. **Szeliski, R.** "Computer Vision: Algorithms and Applications" (2022)
   - Chapter 5: Segmentation

### OpenCV Documentation
- [Image Thresholding](https://docs.opencv.org/4.x/d7/d4d/tutorial_py_thresholding.html)
- [Contours](https://docs.opencv.org/4.x/d4/d73/tutorial_py_contours_begin.html)
- [Watershed](https://docs.opencv.org/4.x/d3/db4/tutorial_py_watershed.html)
- [K-Means Clustering](https://docs.opencv.org/4.x/d1/d5c/tutorial_py_kmeans_opencv.html)

### Video Tutorials
- OpenCV Python Tutorial Series (FreeCodeCamp)
- Computer Vision Basics (Stanford CS231n)

### Datasets for Practice
1. **BSD500** - Berkeley Segmentation Dataset
2. **COCO** - Common Objects in Context (segmentation annotations)
3. **Medical Segmentation Decathlon** - Various medical imaging tasks
4. **Cityscapes** - Urban street scenes for autonomous driving

### Code Examples Repository
All code from today's lecture available at:
- Course GitHub: [repository_link]
- Google Colab notebooks: [colab_link]

---

## üìä Assessment Connection

### For Unit Test 2 (Oct 31)

**Expected Question Types:**

**MCQs (10 marks):**
- Definition and purpose of segmentation
- Comparison of techniques
- When to apply specific methods
- OpenCV function names and parameters

**5-Mark Questions:**
- Explain Otsu's thresholding algorithm
- Compare adaptive thresholding vs. global thresholding
- Describe watershed algorithm with diagram
- Advantages and limitations of K-means segmentation

**10-Mark Questions:**
- Implement complete segmentation pipeline (pseudocode)
- Design segmentation approach for given application
- Compare 3+ segmentation techniques with examples
- Explain marker-based watershed algorithm

### Practical Evaluation (FT-IV)

**Tutorial T8 Assessment Criteria:**
1. **Implementation (60%):**
   - Correct use of OpenCV functions
   - Proper parameter tuning
   - Code organization and comments

2. **Analysis (30%):**
   - Comparison of results
   - Justification of technique choices
   - Understanding of limitations

3. **Presentation (10%):**
   - Clear visualization
   - Professional documentation

---

## üìù Instructor Notes

### What Worked Well
- [Space for post-lecture reflection]
- Student engagement points:
- Timing of demonstrations:

### Areas for Improvement
- [Notes for next iteration]
- Concepts needing more time:
- Technical issues encountered:

### Student Questions/Issues
- Common misunderstandings:
- Difficult concepts:
- Requests for additional examples:

### Timing Analysis
- Segment 1.1 (actual): ____ minutes (planned: 15)
- Segment 1.2 (actual): ____ minutes (planned: 15)
- Segment 1.3 (actual): ____ minutes (planned: 20)
- Segment 2.1 (actual): ____ minutes (planned: 20)
- Segment 2.2 (actual): ____ minutes (planned: 15)
- Segment 2.3 (actual): ____ minutes (planned: 15)

### Follow-up Actions
- [ ] Share code examples on course portal
- [ ] Clarify concepts from Q&A
- [ ] Prepare additional resources for struggling students
- [ ] Update slides based on student feedback

---

## üîó Course Integration

### Links to Previous Content

**Week 7 Foundations:**
- Image enhancement ‚Üí Better contrast for thresholding
- Edge detection ‚Üí Input for edge-based segmentation
- Noise removal ‚Üí Preprocessing for watershed

**Module 1-2 Concepts:**
- Mathematical optimization ‚Üí K-means clustering
- Feature engineering ‚Üí Preparation for CNN features

### Links to Future Content

**Week 9 (Next Week):**
- ROI segmentation ‚Üí Extract regions for feature analysis
- Morphological operations ‚Üí Refine segmentation results
- Feature extraction ‚Üí Describe segmented regions

**Module 4 (Weeks 10-12):**
- CNNs learn features automatically ‚Üí Contrast with manual segmentation
- Semantic segmentation ‚Üí Deep learning approach
- Transfer learning ‚Üí Pre-trained segmentation models

**Module 5 (Weeks 13-15):**
- Object detection ‚Üí Combines segmentation + classification
- YOLO, R-CNN ‚Üí Advanced segmentation architectures

### Cross-Module Integration

**Computer Vision Pipeline:**
```
Raw Image ‚Üí Enhancement (Week 7) ‚Üí Segmentation (Week 8) ‚Üí
Feature Extraction (Week 9) ‚Üí Classification (Weeks 10-15)
```

**Deep Learning Context:**
- Traditional methods (Weeks 7-9): Understanding fundamentals
- Deep learning methods (Weeks 10-15): Automatic feature learning
- Both approaches complement each other in real applications

---

## üéì Learning Assessment Checklist

### By End of Lecture, Students Should:

**Conceptual Understanding:**
- [ ] Define image segmentation and its purpose
- [ ] List 4+ segmentation techniques
- [ ] Explain when to use each technique
- [ ] Understand over-segmentation problem

**Technical Skills:**
- [ ] Implement basic thresholding in OpenCV
- [ ] Use Otsu's method for automatic thresholding
- [ ] Apply adaptive thresholding
- [ ] Detect and analyze contours
- [ ] Understand watershed algorithm concept
- [ ] Use K-means for color segmentation

**Application Knowledge:**
- [ ] Choose appropriate method for given image
- [ ] Identify common segmentation challenges
- [ ] Connect segmentation to DNN preprocessing

### Exit Ticket Question
*"In one sentence, explain when you would use adaptive thresholding instead of global thresholding, and provide a real-world example."*

---

**Lecture Prepared by:** Dr. Ramesh Babu
**Course:** 21CSE558T - Deep Neural Network Architectures
**Department:** School of Computing, SRM University
**Version:** 1.0 (October 2025)

---

## üìé Appendix: Quick Reference Code Snippets

### A1: Complete Segmentation Comparison Pipeline

```python
import cv2
import numpy as np
import matplotlib.pyplot as plt

def compare_segmentation_methods(image_path):
    """
    Compare multiple segmentation techniques on single image
    """
    # Read image
    img = cv2.imread(image_path)
    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)

    # 1. Global thresholding
    _, thresh_global = cv2.threshold(gray, 127, 255, cv2.THRESH_BINARY)

    # 2. Otsu's thresholding
    _, thresh_otsu = cv2.threshold(gray, 0, 255,
                                    cv2.THRESH_BINARY + cv2.THRESH_OTSU)

    # 3. Adaptive thresholding
    thresh_adaptive = cv2.adaptiveThreshold(gray, 255,
                                            cv2.ADAPTIVE_THRESH_GAUSSIAN_C,
                                            cv2.THRESH_BINARY, 11, 2)

    # 4. Canny edge detection (from Week 7)
    edges = cv2.Canny(gray, 100, 200)

    # 5. K-means (K=3)
    pixel_values = img.reshape((-1, 3))
    pixel_values = np.float32(pixel_values)
    criteria = (cv2.TERM_CRITERIA_EPS + cv2.TERM_CRITERIA_MAX_ITER, 100, 0.2)
    _, labels, centers = cv2.kmeans(pixel_values, 3, None, criteria, 10,
                                     cv2.KMEANS_RANDOM_CENTERS)
    centers = np.uint8(centers)
    segmented_kmeans = centers[labels.flatten()]
    segmented_kmeans = segmented_kmeans.reshape(img.shape)

    # Visualize all methods
    results = [
        ('Original', cv2.cvtColor(img, cv2.COLOR_BGR2RGB)),
        ('Global Threshold', thresh_global),
        ('Otsu Threshold', thresh_otsu),
        ('Adaptive Threshold', thresh_adaptive),
        ('Canny Edges', edges),
        ('K-Means (K=3)', cv2.cvtColor(segmented_kmeans, cv2.COLOR_BGR2RGB))
    ]

    fig, axes = plt.subplots(2, 3, figsize=(15, 10))
    for ax, (title, result) in zip(axes.flat, results):
        ax.imshow(result, cmap='gray' if len(result.shape) == 2 else None)
        ax.set_title(title, fontsize=12, fontweight='bold')
        ax.axis('off')

    plt.tight_layout()
    plt.savefig('segmentation_comparison.png', dpi=300, bbox_inches='tight')
    plt.show()

# Usage
compare_segmentation_methods('test_image.jpg')
```

### A2: Interactive Threshold Tuning

```python
def interactive_threshold(image_path):
    """
    Interactive window for threshold adjustment
    """
    img = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)

    cv2.namedWindow('Threshold Adjustment')

    def update_threshold(val):
        _, thresh = cv2.threshold(img, val, 255, cv2.THRESH_BINARY)
        cv2.imshow('Threshold Adjustment', thresh)

    # Create trackbar
    cv2.createTrackbar('Threshold', 'Threshold Adjustment',
                       127, 255, update_threshold)

    # Initial display
    update_threshold(127)

    cv2.waitKey(0)
    cv2.destroyAllWindows()

# Usage
interactive_threshold('test_image.jpg')
```

---

*End of Comprehensive Lecture Notes - Week 8, Day Order 3*