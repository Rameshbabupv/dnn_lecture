{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notebook 3: 2D Convolution for Images\n\n**Week 10 - Module 4: CNN Basics**\n**DO3 (October 27, 2025) - Saturday**\n**Duration:** 25-30 minutes\n\n---\n\n## Learning Objectives\n\nBy the end of this notebook, you will be able to:\n\n1. \u2705 **Calculate** 2D convolution operations by hand\n2. \u2705 **Understand** how convolution applies to images\n3. \u2705 **Implement** 2D convolution using NumPy and SciPy\n4. \u2705 **Apply** edge detection filters to real images\n5. \u2705 **Visualize** feature maps and filter responses\n\n---\n\n## Prerequisites\n\n- \u2705 Completed Notebook 2 (1D Convolution)\n- \u2705 Understanding of images as 2D arrays\n- \u2705 Matrix multiplication concepts\n\n---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup and Imports"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "import numpy as np\nimport matplotlib.pyplot as plt\nfrom scipy import signal, ndimage\nfrom skimage import data, color, filters\nimport cv2\n\n# Set random seed\nnp.random.seed(42)\n\n# Configure matplotlib\nplt.style.use('seaborn-v0_8-darkgrid')\nplt.rcParams['figure.figsize'] = (14, 8)\nplt.rcParams['font.size'] = 11\n\nprint(\"\u2705 Setup complete!\")\nprint(\"Libraries loaded: NumPy, Matplotlib, SciPy, scikit-image, OpenCV\")"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n\n## 2. The Story: Character: Meera's Medical Imaging Challenge\n\n### \ud83d\udcd6 Narrative\n\n**Character: Meera**, a medical imaging researcher, needs to analyze X-ray images for **Character: Dr. Rajesh**'s radiology clinic.\n\n**The Problem:**\n\n> \"These X-ray images are blurry, and I need to detect bone edges clearly,\" explains **Character: Dr. Rajesh**. \"Can you enhance the edges automatically?\"\n\n**Character: Meera** responds: \"Perfect! I'll use 2D convolution with edge detection kernels. Let me show you how 2D convolution extends what we learned in 1D.\"\n\n---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. From 1D to 2D: Mathematical Extension\n\n### \ud83d\udcd0 The 2D Convolution Formula\n\nFor 2D images, convolution extends naturally:\n\n$$\n\\text{output}[i, j] = \\sum_{m=0}^{M-1} \\sum_{n=0}^{N-1} \\text{input}[i+m, j+n] \\cdot \\text{kernel}[m, n]\n$$\n\nWhere:\n- `input`: 2D image matrix (height \u00d7 width)\n- `kernel`: 2D filter matrix (M \u00d7 N)\n- `output`: Convolved feature map\n\n**In Plain English:**\n\n\"Slide a 2D filter across the image, multiply overlapping values, sum them up.\"\n\n---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Hand Calculation: Simple 2D Example\n\nLet's calculate 2D convolution **by hand** with a tiny example.\n\n### Example Setup:\n\n**Input (4\u00d74 image):**\n```\n[1, 2, 3, 4]\n[5, 6, 7, 8]\n[9, 10, 11, 12]\n[13, 14, 15, 16]\n```\n\n**Kernel (3\u00d73 edge detector):**\n```\n[1, 0, -1]\n[2, 0, -2]\n[1, 0, -1]\n```\n\nThis is the **Sobel vertical edge detector** (detects vertical edges).\n\n---"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Define input image and kernel\ninput_image = np.array([\n    [1, 2, 3, 4],\n    [5, 6, 7, 8],\n    [9, 10, 11, 12],\n    [13, 14, 15, 16]\n])\n\nsobel_vertical = np.array([\n    [1, 0, -1],\n    [2, 0, -2],\n    [1, 0, -1]\n])\n\nprint(\"Input Image (4\u00d74):\")\nprint(input_image)\nprint(\"\\nSobel Vertical Kernel (3\u00d73):\")\nprint(sobel_vertical)\nprint(\"\\nWe will calculate output at position (0, 0)...\")"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step-by-Step Calculation: Position (0, 0)\n\nExtract 3\u00d73 window from top-left corner:\n\n```\nWindow:        Kernel:\n[1,  2,  3]    [1,  0, -1]\n[5,  6,  7]    [2,  0, -2]\n[9, 10, 11]    [1,  0, -1]\n```\n\n**Element-wise multiplication:**\n\n```\n1\u00d71  + 2\u00d70  + 3\u00d7(-1)  = 1 + 0 - 3   = -2\n5\u00d72  + 6\u00d70  + 7\u00d7(-2)  = 10 + 0 - 14 = -4\n9\u00d71  + 10\u00d70 + 11\u00d7(-1) = 9 + 0 - 11  = -2\n```\n\n**Sum all products:**\n\n$$\n\\text{output}[0, 0] = -2 + (-4) + (-2) = -8\n$$\n\n---"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Manual calculation for position (0, 0)\nwindow = input_image[0:3, 0:3]\nprint(\"Extracted 3\u00d73 window:\")\nprint(window)\nprint(\"\\nElement-wise multiplication:\")\nelement_wise = window * sobel_vertical\nprint(element_wise)\nprint(\"\\nSum of all elements:\")\nresult = np.sum(element_wise)\nprint(f\"output[0, 0] = {result}\")"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n\n## 5. NumPy/SciPy Implementation\n\nNow let's compute the full convolution using built-in functions.\n\n---"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Using scipy.signal.convolve2d\nfrom scipy.signal import convolve2d\n\n# Full convolution\nfull_output = convolve2d(input_image, sobel_vertical, mode='valid')\n\nprint(\"Full Output (valid mode):\")\nprint(full_output)\nprint(f\"\\nOutput shape: {full_output.shape}\")\nprint(f\"Input shape: {input_image.shape}\")\nprint(f\"Kernel shape: {sobel_vertical.shape}\")\nprint(f\"\\n\u2705 Verified: output[0, 0] = {full_output[0, 0]}\")"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n\n## 6. Real-World Application: Edge Detection\n\nLet's apply 2D convolution to detect edges in real images.\n\n---"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Load a sample image (camera from scikit-image)\ncamera = data.camera()  # 512\u00d7512 grayscale image\n\n# Define edge detection kernels\nkernels = {\n    'Sobel Vertical': np.array([[1, 0, -1],\n                                 [2, 0, -2],\n                                 [1, 0, -1]]),\n    'Sobel Horizontal': np.array([[1, 2, 1],\n                                   [0, 0, 0],\n                                   [-1, -2, -1]]),\n    'Laplacian': np.array([[0, 1, 0],\n                           [1, -4, 1],\n                           [0, 1, 0]]),\n    'Box Blur': np.ones((5, 5)) / 25\n}\n\n# Apply each kernel\nfig, axes = plt.subplots(3, 2, figsize=(14, 16))\naxes = axes.flatten()\n\n# Original image\naxes[0].imshow(camera, cmap='gray')\naxes[0].set_title('Original Image (512\u00d7512)', fontsize=14, fontweight='bold')\naxes[0].axis('off')\n\n# Apply kernels\nfor idx, (name, kernel) in enumerate(kernels.items(), 1):\n    filtered = convolve2d(camera, kernel, mode='same', boundary='symm')\n    axes[idx].imshow(filtered, cmap='gray')\n    axes[idx].set_title(f'{name} Filter', fontsize=14, fontweight='bold')\n    axes[idx].axis('off')\n\n# Show kernel for Sobel Vertical\naxes[5].imshow(kernels['Sobel Vertical'], cmap='RdBu', interpolation='nearest')\naxes[5].set_title('Sobel Vertical Kernel (3\u00d73)', fontsize=14, fontweight='bold')\nfor i in range(3):\n    for j in range(3):\n        axes[5].text(j, i, f\"{kernels['Sobel Vertical'][i, j]}\",\n                    ha='center', va='center', fontsize=12, fontweight='bold')\n\nplt.tight_layout()\nplt.show()\n\nprint(\"\u2705 Character: Meera successfully detected edges in X-ray images!\")"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n\n## 7. Custom 2D Convolution Implementation\n\nLet's implement 2D convolution from scratch for deep understanding.\n\n---"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "def conv2d_manual(image, kernel):\n    \"\"\"\n    Manual implementation of 2D convolution (valid mode).\n\n    Parameters:\n    -----------\n    image : np.ndarray\n        Input 2D image\n    kernel : np.ndarray\n        2D convolution kernel\n\n    Returns:\n    --------\n    output : np.ndarray\n        Convolved output\n    \"\"\"\n    img_h, img_w = image.shape\n    ker_h, ker_w = kernel.shape\n\n    out_h = img_h - ker_h + 1\n    out_w = img_w - ker_w + 1\n\n    output = np.zeros((out_h, out_w))\n\n    for i in range(out_h):\n        for j in range(out_w):\n            # Extract window\n            window = image[i:i+ker_h, j:j+ker_w]\n            # Element-wise multiply and sum\n            output[i, j] = np.sum(window * kernel)\n\n    return output\n\n# Test on small image\ntest_img = np.array([[1, 2, 3], [4, 5, 6], [7, 8, 9]])\ntest_kernel = np.array([[1, 0], [0, -1]])\n\ncustom_result = conv2d_manual(test_img, test_kernel)\nscipy_result = convolve2d(test_img, test_kernel, mode='valid')\n\nprint(\"Custom Implementation:\")\nprint(custom_result)\nprint(\"\\nSciPy Implementation:\")\nprint(scipy_result)\nprint(f\"\\n\u2705 Match: {np.allclose(custom_result, scipy_result)}\")"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n\n## 8. Visualizing Multiple Feature Maps\n\nIn CNNs, we apply multiple filters to extract different features. Let's visualize this.\n\n---"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Create multiple feature detectors\nfeature_kernels = {\n    'Vertical Edges': np.array([[-1, 0, 1], [-2, 0, 2], [-1, 0, 1]]),\n    'Horizontal Edges': np.array([[-1, -2, -1], [0, 0, 0], [1, 2, 1]]),\n    'Diagonal 45\u00b0': np.array([[0, 1, 2], [-1, 0, 1], [-2, -1, 0]]),\n    'Diagonal 135\u00b0': np.array([[2, 1, 0], [1, 0, -1], [0, -1, -2]]),\n    'Sharpen': np.array([[0, -1, 0], [-1, 5, -1], [0, -1, 0]]),\n    'Emboss': np.array([[-2, -1, 0], [-1, 1, 1], [0, 1, 2]])\n}\n\n# Use a smaller region for clarity\nimg_region = camera[100:300, 100:300]\n\n# Apply all kernels\nfig, axes = plt.subplots(3, 3, figsize=(15, 15))\naxes = axes.flatten()\n\n# Original\naxes[0].imshow(img_region, cmap='gray')\naxes[0].set_title('Original Region', fontsize=13, fontweight='bold')\naxes[0].axis('off')\n\n# Feature maps\nfor idx, (name, kernel) in enumerate(feature_kernels.items(), 1):\n    feature_map = convolve2d(img_region, kernel, mode='same', boundary='symm')\n    axes[idx].imshow(feature_map, cmap='gray')\n    axes[idx].set_title(f'Feature Map: {name}', fontsize=13, fontweight='bold')\n    axes[idx].axis('off')\n\n# Hide extra subplot\naxes[-1].axis('off')\n\nplt.tight_layout()\nplt.show()\n\nprint(\"\ud83c\udfaf Multiple Feature Maps:\")\nprint(\"  Each filter detects different patterns in the same image\")\nprint(\"  This is exactly how CNNs learn hierarchical features!\")"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n\n## 9. Summary and Key Takeaways\n\n### \ud83c\udfaf What We Learned\n\n1. **2D Convolution Formula**\n   - Extends 1D: slide 2D kernel across 2D image\n   - Output: `(H - Kh + 1) \u00d7 (W - Kw + 1)` (valid mode)\n\n2. **Hand Calculation**\n   - Extract window, multiply element-wise, sum\n   - Same principle as 1D, but in 2 dimensions\n\n3. **Edge Detection**\n   - Sobel, Laplacian, etc.\n   - Detect different orientations (vertical, horizontal, diagonal)\n\n4. **Multiple Feature Maps**\n   - Different kernels \u2192 different patterns\n   - Foundation of CNN feature learning\n\n### \ud83d\udd2e What's Next?\n\nIn **Notebook 4**, we'll explore **Convolution Parameters**:\n- Stride (how much to slide)\n- Padding (maintaining dimensions)\n- Output dimension calculations\n- Parameter trade-offs\n\n---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Practice Exercises\n\n### Exercise 1: Hand Calculation\nCalculate 2D convolution manually:\n- Input: 3\u00d73 image `[[1,2,3], [4,5,6], [7,8,9]]`\n- Kernel: 2\u00d72 `[[1,0], [0,-1]]`\n- Calculate all output positions\n\n### Exercise 2: Custom Edge Detector\nDesign a kernel that detects:\n- Edges at 45\u00b0 diagonal\n- Test on checkerboard pattern\n\n### Exercise 3: Multi-Channel Thinking\nHow would you apply convolution to RGB images (3 channels)?\n- Hint: Think about kernel depth\n\n---\n\n**Next Notebook:** [Notebook 4: Convolution Parameters](04_convolution_parameters.ipynb)\n\n---\n\n*Week 10 - Deep Neural Network Architectures (21CSE558T)*\n*SRM University - M.Tech Program*"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}