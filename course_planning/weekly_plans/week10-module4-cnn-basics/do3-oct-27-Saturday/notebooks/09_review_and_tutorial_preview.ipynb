{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notebook 9: Review & Tutorial T10 Preview\n\n**Week 10 - Module 4: CNN Basics**\n**DO3 (October 27, 2025) - Saturday**\n**Duration:** 15-20 minutes\n\n## Objectives\n\n1. \u2705 **Review** all concepts from Notebooks 0-8\n2. \u2705 **Preview** Tutorial T10 (building CNN in Keras)\n3. \u2705 **Prepare** for hands-on session\n\n---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Complete Concept Map\n\n```\nWeek 10 CNN Journey\n\u2502\n\u251c\u2500\u2500 Notebook 0: Setup & Prerequisites\n\u2502   \u2514\u2500\u2500 NumPy, Matplotlib, helper functions\n\u2502\n\u251c\u2500\u2500 Notebook 1: Convolution Concept & Intuition\n\u2502   \u2514\u2500\u2500 Sliding window, pattern detection\n\u2502\n\u251c\u2500\u2500 Notebook 2: 1D Convolution Math & Code\n\u2502   \u2514\u2500\u2500 Signal processing, manual calculation\n\u2502\n\u251c\u2500\u2500 Notebook 3: 2D Convolution for Images\n\u2502   \u2514\u2500\u2500 Edge detection, feature maps\n\u2502\n\u251c\u2500\u2500 Notebook 4: Convolution Parameters\n\u2502   \u2514\u2500\u2500 Stride, padding, kernel size, output formula\n\u2502\n\u251c\u2500\u2500 Notebook 5: Hierarchical Feature Learning\n\u2502   \u2514\u2500\u2500 Edges \u2192 textures \u2192 parts \u2192 objects\n\u2502\n\u251c\u2500\u2500 Notebook 6: Pooling Layers\n\u2502   \u2514\u2500\u2500 Max pooling, average pooling, dimension reduction\n\u2502\n\u251c\u2500\u2500 Notebook 7: Complete CNN Architecture\n\u2502   \u2514\u2500\u2500 [Conv\u2192ReLU\u2192Pool]\u00d7N \u2192 Flatten \u2192 Dense\n\u2502\n\u2514\u2500\u2500 Notebook 8: 3D Convolution Preview\n    \u2514\u2500\u2500 Videos, medical imaging, spatiotemporal\n```\n\n---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Key Formulas Cheat Sheet\n\n### Output Dimension Formula:\n$$\n\\text{Output} = \\left\\lfloor \\frac{W - F + 2P}{S} \\right\\rfloor + 1\n$$\n\n### Convolution Parameter Count:\n$$\n\\text{Params} = (F_h \\times F_w \\times C_{in} + 1) \\times C_{out}\n$$\n\n### Dense Parameter Count:\n$$\n\\text{Params} = (\\text{input\\_units} + 1) \\times \\text{output\\_units}\n$$\n\n### Same Padding Formula:\n$$\nP = \\frac{F - 1}{2} \\quad \\text{(for stride = 1)}\n$$\n\n---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Connection to Week 9\n\n| Week 9 (Manual) | Week 10 (Learned) |\n|-----------------|-------------------|\n| LBP (Local Binary Patterns) | Conv Layer 1 (edges) |\n| GLCM (Texture) | Conv Layer 2 (textures) |\n| Shape Features | Conv Layer 3 (parts) |\n| Manually designed | Automatically learned! |\n\n**Key Insight:** CNNs learn the feature extractors that we manually designed in Week 9!\n\n---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Tutorial T10 Preview\n\n**Tomorrow's Tutorial (DO4, Oct 29, Monday):**\n\n### Task: Build CNN for Fashion-MNIST Classification\n\n**Steps:**\n\n1. **Load Data**\n   ```python\n   from tensorflow.keras.datasets import fashion_mnist\n   (X_train, y_train), (X_test, y_test) = fashion_mnist.load_data()\n   ```\n\n2. **Build CNN**\n   ```python\n   model = keras.Sequential([\n       Conv2D(32, (3,3), activation='relu', input_shape=(28,28,1)),\n       MaxPooling2D((2,2)),\n       Conv2D(64, (3,3), activation='relu'),\n       MaxPooling2D((2,2)),\n       Flatten(),\n       Dense(128, activation='relu'),\n       Dense(10, activation='softmax')\n   ])\n   ```\n\n3. **Train & Evaluate**\n   ```python\n   model.compile(optimizer='adam',\n                 loss='sparse_categorical_crossentropy',\n                 metrics=['accuracy'])\n   model.fit(X_train, y_train, epochs=5, validation_split=0.2)\n   ```\n\n4. **Visualize Filters** (Bonus)\n\n---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Self-Assessment Questions\n\n### Question 1: Dimension Calculation\nInput: 32\u00d732\u00d73, Filter: 5\u00d75, Stride: 1, Padding: 0\n- What is output dimension?\n- **Answer**: $(32 - 5 + 0)/1 + 1 = 28$ \u2192 **28\u00d728**\n\n### Question 2: Parameter Count\nConv layer: 3\u00d73 kernel, 64 input channels, 128 output channels\n- How many parameters?\n- **Answer**: $(3 \\times 3 \\times 64 + 1) \\times 128 = 73,856$\n\n### Question 3: Architecture Design\nDesign a CNN for 64\u00d764 RGB images, 5 classes:\n- **Suggested**:\n  - Conv(32) \u2192 Pool \u2192 Conv(64) \u2192 Pool \u2192 Flatten \u2192 Dense(128) \u2192 Dense(5)\n\n---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Common Pitfalls to Avoid\n\n### \u274c Mistake #1: Forgetting to Normalize\n```python\n# Wrong\nmodel.fit(X_train, y_train)  # Values in [0, 255]\n\n# Correct\nX_train = X_train / 255.0  # Normalize to [0, 1]\nmodel.fit(X_train, y_train)\n```\n\n### \u274c Mistake #2: Wrong Input Shape\n```python\n# Wrong\ninput_shape=(28, 28)  # Missing channel dimension\n\n# Correct\ninput_shape=(28, 28, 1)  # Grayscale\n# or\ninput_shape=(28, 28, 3)  # RGB\n```\n\n### \u274c Mistake #3: Dimension Mismatch\n```python\n# Wrong: Output of Flatten doesn't match Dense input\nFlatten() \u2192 Dense(10)  # Expects specific input size\n\n# Correct: Keras handles this automatically in Sequential\n```\n\n---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Preparation Checklist for Tutorial T10\n\n- [ ] Review convolution operation (Notebooks 1-3)\n- [ ] Understand stride, padding, pooling (Notebooks 4, 6)\n- [ ] Know how to calculate dimensions (Notebook 4)\n- [ ] Understand CNN architecture pattern (Notebook 7)\n- [ ] Have TensorFlow/Keras installed\n- [ ] Familiar with Fashion-MNIST dataset\n\n---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n\n### \ud83c\udfaf What We Accomplished\n\n**Notebooks 0-9:**\n1. Convolution intuition and mathematics\n2. 1D and 2D convolution implementations\n3. Stride, padding, kernel size parameters\n4. Hierarchical feature learning\n5. Pooling mechanisms\n6. Complete CNN architectures\n7. 3D convolution overview\n\n**Tomorrow (Tutorial T10):**\n- Build your first CNN in Keras!\n- Train on Fashion-MNIST\n- Achieve 90%+ accuracy\n- Visualize learned filters\n\n### \ud83c\udf93 Final Thoughts\n\n**From Week 9 to Week 10:**\n- Week 9: Manual feature design (LBP, GLCM)\n- Week 10: Automatic feature learning (CNNs)\n\n**The Power of CNNs:**\n- Learn hierarchical features\n- Translation invariant\n- State-of-the-art image recognition\n\n---\n\n## Next Steps\n\n1. **Review** any confusing notebooks\n2. **Practice** dimension calculations\n3. **Install** TensorFlow/Keras if needed\n4. **Bring questions** to Tutorial T10!\n\n---\n\n**See you at Tutorial T10 (DO4, Oct 29, Monday)!**\n\n---\n\n*Week 10 - Deep Neural Network Architectures (21CSE558T)*\n*SRM University - M.Tech Program*\n\n---\n\n## \ud83c\udf89 Congratulations!\n\nYou've completed all 9 notebooks on CNN basics. You now understand:\n- \u2705 How convolution works mathematically\n- \u2705 Why CNNs are powerful for images\n- \u2705 How to design CNN architectures\n- \u2705 Ready to build your first CNN!\n\n**Happy Learning! \ud83d\ude80**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}