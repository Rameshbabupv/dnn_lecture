{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# 02: Feature Extraction - The Fast Solution\n",
        "\n",
        "**Course:** 21CSE558T - Deep Neural Network Architectures  \n",
        "**Module 4:** CNNs & Transfer Learning (Week 12)  \n",
        "**Estimated Time:** 8-10 minutes  \n",
        "**Prerequisites:** Notebook 01  \n",
        "**Goal:** Use transfer learning to achieve 88-92% accuracy\n",
        "\n",
        "---\n",
        "\n",
        "## \ud83d\udcda What You'll Learn\n",
        "\n",
        "In this notebook, you will:\n",
        "1. Load ResNet50 pre-trained on ImageNet (1.2M images)\n",
        "2. Freeze the base model (25M parameters)\n",
        "3. Train only the final classifier layer\n",
        "4. Achieve **88-92% accuracy** with same 3,000 images!\n",
        "\n",
        "**Key Message:** _\"Don't reinvent the wheel - borrow knowledge from ImageNet!\"_\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Setup\n",
        "import tensorflow as tf\n",
        "import tensorflow_datasets as tfds\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from tensorflow.keras.applications import ResNet50\n",
        "from tensorflow.keras import Sequential\n",
        "from tensorflow.keras.layers import GlobalAveragePooling2D, Dense\n",
        "\n",
        "print(f\"\u2705 TensorFlow: {tf.__version__}\")\n",
        "print(\"\u2705 Ready to see transfer learning magic!\\n\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 1: Load Same Dataset (TF Flowers)\n",
        "\n",
        "We'll use the EXACT same dataset as Notebook 01 to prove transfer learning works!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Load flowers dataset\n",
        "(train_ds, val_ds), info = tfds.load(\n",
        "    'tf_flowers',\n",
        "    split=['train[:80%]', 'train[80%:]'],\n",
        "    as_supervised=True,\n",
        "    with_info=True\n",
        ")\n",
        "\n",
        "num_classes = info.features['label'].num_classes\n",
        "class_names = info.features['label'].names\n",
        "\n",
        "# Preprocess for ResNet50 (224\u00d7224 input required)\n",
        "IMG_SIZE = 224  # ResNet50 default\n",
        "BATCH_SIZE = 32\n",
        "\n",
        "def preprocess(image, label):\n",
        "    # Resize to 224x224\n",
        "    image = tf.image.resize(image, (IMG_SIZE, IMG_SIZE))\n",
        "    \n",
        "    # IMPORTANT: Use ResNet50's preprocessing function!\n",
        "    # This applies ImageNet-specific preprocessing (RGB->BGR, zero-centering)\n",
        "    image = tf.keras.applications.resnet50.preprocess_input(image)\n",
        "    \n",
        "    return image, label\n",
        "\n",
        "train_ds = train_ds.map(preprocess).batch(BATCH_SIZE).prefetch(tf.data.AUTOTUNE)\n",
        "val_ds = val_ds.map(preprocess).batch(BATCH_SIZE).prefetch(tf.data.AUTOTUNE)\n",
        "\n",
        "print(\"\u2705 Same 3,000 flowers dataset loaded!\")\n",
        "print(f\"   Classes: {class_names}\")\n",
        "print(\"\\n\ud83d\udd11 Using ResNet50-specific preprocessing!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 2: Load Pre-trained ResNet50\n",
        "\n",
        "**The Magic Step!**\n",
        "\n",
        "We'll load ResNet50 that was trained on ImageNet:\n",
        "- **Training data:** 1.2 million images, 1,000 categories\n",
        "- **Training time:** 2 weeks on 8 GPUs\n",
        "- **Training cost:** ~$15,000\n",
        "- **Our cost:** FREE! (We download pre-trained weights)\n",
        "\n",
        "Watch for the download message..."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Load ResNet50 pre-trained on ImageNet\n",
        "print(\"\ud83d\udce5 Loading ResNet50 pre-trained weights...\")\n",
        "print(\"   (This downloads 98 MB - first time only)\\n\")\n",
        "\n",
        "base_model = ResNet50(\n",
        "    weights='imagenet',        # \ud83d\udd11 KEY: Use ImageNet pre-trained weights!\n",
        "    include_top=False,         # Remove ImageNet classifier (1000 classes)\n",
        "    input_shape=(IMG_SIZE, IMG_SIZE, 3)\n",
        ")\n",
        "\n",
        "print(\"\\n\u2705 ResNet50 loaded with ImageNet knowledge!\")\n",
        "print(f\"   Total parameters: {base_model.count_params():,}\")\n",
        "print(\"\\n   This model already learned:\")\n",
        "print(\"   \ud83d\udd38 Edges, textures, colors (early layers)\")\n",
        "print(\"   \ud83d\udd38 Shapes, patterns (middle layers)\")\n",
        "print(\"   \ud83d\udd38 Object parts (deep layers)\")\n",
        "print(\"\\n   These features work on ANY image - including flowers!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 3: FREEZE the Base Model\n",
        "\n",
        "**THE MOST IMPORTANT LINE IN TRANSFER LEARNING:**\n",
        "\n",
        "```python\n",
        "base_model.trainable = False\n",
        "```\n",
        "\n",
        "This freezes all 25M parameters - we won't update them during training!\n",
        "\n",
        "**Why freeze?**\n",
        "- These features are already perfect (learned from 1.2M images)\n",
        "- We only have 3,000 images - not enough to improve them\n",
        "- Freezing = 10\u00d7 faster training, prevents overfitting"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# FREEZE the base model\n",
        "base_model.trainable = False  # \u2744\ufe0f THE KEY LINE!\n",
        "\n",
        "print(\"\u2744\ufe0f  Base model FROZEN!\")\n",
        "print(f\"   Frozen parameters: {base_model.count_params():,}\")\n",
        "print(\"   These won't update during training.\")\n",
        "print(\"\\n   \u2705 We're borrowing ImageNet knowledge, not reinventing it!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 4: Add Custom Classifier\n",
        "\n",
        "We'll add our own classifier for 5 flower classes:\n",
        "```\n",
        "ResNet50 (frozen 25M params)\n",
        "    \u2193\n",
        "GlobalAveragePooling2D\n",
        "    \u2193\n",
        "Dense(5, softmax)  \u2190 ONLY THIS TRAINS!\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Build complete model\n",
        "model = Sequential([\n",
        "    base_model,                              # Frozen ResNet50\n",
        "    GlobalAveragePooling2D(),                # Reduce spatial dimensions\n",
        "    Dense(num_classes, activation='softmax') # Our classifier (5 classes)\n",
        "], name='ResNet50_FeatureExtraction')\n",
        "\n",
        "# Compile\n",
        "model.compile(\n",
        "    optimizer='adam',\n",
        "    loss='sparse_categorical_crossentropy',\n",
        "    metrics=['accuracy']\n",
        ")\n",
        "\n",
        "# Print summary\n",
        "model.summary()\n",
        "\n",
        "# Count trainable vs non-trainable\n",
        "trainable = sum([tf.size(w).numpy() for w in model.trainable_weights])\n",
        "non_trainable = sum([tf.size(w).numpy() for w in model.non_trainable_weights])\n",
        "\n",
        "print(\"\\n\ud83d\udcca PARAMETER COUNT:\")\n",
        "print(\"=\"*50)\n",
        "print(f\"\u2744\ufe0f  Frozen (non-trainable): {non_trainable:,}\")\n",
        "print(f\"\ud83d\udd25 Training (trainable):   {trainable:,}\")\n",
        "print(f\"\ud83d\udcc9 We're training only {trainable/non_trainable*100:.3f}% of params!\")\n",
        "print(\"=\"*50)\n",
        "print(\"\\n\u2705 Model ready! Let's train ONLY the classifier.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 5: Train (Watch the Magic!)\n",
        "\n",
        "**Prediction:** \n",
        "- Notebook 01 (from scratch): 45-55% accuracy \u274c\n",
        "- Notebook 02 (transfer learning): 88-92% accuracy \u2705\n",
        "\n",
        "**Watch for:**\n",
        "- Epoch 1: Already ~75% accuracy (much higher than scratch!)\n",
        "- Epoch 5: Reaches 88-92% accuracy\n",
        "- Training time: ~3 minutes (vs 2-3 min for scratch, but MUCH better!)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Train!\n",
        "print(\"\ud83d\ude80 Training with transfer learning...\\n\")\n",
        "print(\"\ud83c\udfaf Watch the validation accuracy - should start HIGH!\\n\")\n",
        "\n",
        "history = model.fit(\n",
        "    train_ds,\n",
        "    validation_data=val_ds,\n",
        "    epochs=5,  # Only need 5 epochs!\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "print(\"\\n\u2705 Training complete!\")\n",
        "print(\"\\n\ud83c\udf89 THE MAGIC HAPPENED! Let's analyze...\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 6: Compare Results\n",
        "\n",
        "Let's compare Notebook 01 (scratch) vs Notebook 02 (transfer learning)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Plot comparison\n",
        "plt.figure(figsize=(14, 5))\n",
        "\n",
        "# Accuracy\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(history.history['accuracy'], label='Training Acc', marker='o', linewidth=2)\n",
        "plt.plot(history.history['val_accuracy'], label='Validation Acc', marker='s', linewidth=2)\n",
        "plt.axhline(y=0.50, color='red', linestyle='--', label='Notebook 01 Result (50%)', alpha=0.7)\n",
        "plt.title('Transfer Learning: Much Better Accuracy!', fontsize=14, fontweight='bold')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend()\n",
        "plt.grid(True, alpha=0.3)\n",
        "\n",
        "# Loss\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(history.history['loss'], label='Training Loss', marker='o', linewidth=2)\n",
        "plt.plot(history.history['val_loss'], label='Validation Loss', marker='s', linewidth=2)\n",
        "plt.title('Transfer Learning: Lower Loss', fontsize=14, fontweight='bold')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "plt.grid(True, alpha=0.3)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Print results\n",
        "final_val_acc = history.history['val_accuracy'][-1]\n",
        "\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"\ud83c\udfaf FINAL COMPARISON\")\n",
        "print(\"=\"*70)\n",
        "print(f\"\\n{'Method':<30} {'Val Accuracy':<20} {'Improvement'}\")\n",
        "print(\"-\"*70)\n",
        "print(f\"{'Notebook 01 (Scratch)':<30} {'~50%':<20} {'Baseline'}\")\n",
        "print(f\"{'Notebook 02 (Transfer)':<30} {f'{final_val_acc:.1%}':<20} {'+' + f'{(final_val_acc - 0.50)*100:.0f}'} percentage points! \u2728\")\n",
        "print(\"-\"*70)\n",
        "print(f\"\\n\ud83c\udf89 We achieved {final_val_acc:.1%} accuracy with SAME 3,000 images!\")\n",
        "print(f\"   That's a {(final_val_acc/0.50 - 1)*100:.0f}% relative improvement!\")\n",
        "print(\"\\n\u2728 THAT is the power of transfer learning!\")\n",
        "print(\"=\"*70)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 7: Visualize Predictions\n",
        "\n",
        "Let's see our model in action!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Get predictions on validation set\n",
        "plt.figure(figsize=(15, 10))\n",
        "for i, (image_batch, label_batch) in enumerate(val_ds.take(1)):\n",
        "    predictions = model.predict(image_batch)\n",
        "    \n",
        "    for j in range(min(9, len(image_batch))):\n",
        "        plt.subplot(3, 3, j + 1)\n",
        "        plt.imshow(image_batch[j].numpy())\n",
        "        \n",
        "        true_label = class_names[label_batch[j].numpy()]\n",
        "        pred_label = class_names[np.argmax(predictions[j])]\n",
        "        confidence = np.max(predictions[j]) * 100\n",
        "        \n",
        "        color = 'green' if true_label == pred_label else 'red'\n",
        "        plt.title(f\"True: {true_label}\\nPred: {pred_label} ({confidence:.0f}%)\", \n",
        "                 color=color, fontsize=10)\n",
        "        plt.axis('off')\n",
        "\n",
        "plt.suptitle('Sample Predictions (Green = Correct, Red = Wrong)', fontsize=14, fontweight='bold')\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "print(\"\\n\u2705 Model making confident, accurate predictions!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "## \ud83c\udf93 Summary: What You Learned\n",
        "\n",
        "### The Solution:\n",
        "1. \u2705 **Load pre-trained model:** ResNet50 with ImageNet weights\n",
        "2. \u2705 **Freeze base model:** Don't update 25M parameters\n",
        "3. \u2705 **Add custom classifier:** Train only final layer (~20K params)\n",
        "4. \u2705 **Train fast:** 5 epochs, ~3 minutes\n",
        "5. \u2705 **Achieve great accuracy:** 88-92% vs 45-55% from scratch!\n",
        "\n",
        "### The Impact:\n",
        "| Metric | Scratch (Notebook 01) | Transfer (Notebook 02) | Improvement |\n",
        "|--------|---------------------|---------------------|-------------|\n",
        "| Validation Accuracy | 45-55% | 88-92% | **+40%** |\n",
        "| Overfitting | Severe | Minimal | Much better |\n",
        "| Training Time | 3 min | 3 min | Same |\n",
        "| Data Required | 100K+ images | 3K images | **30\u00d7 less** |\n",
        "\n",
        "### The Key Insight:\n",
        "**\"ImageNet knowledge transfers to flowers!\"**\n",
        "\n",
        "ResNet50 learned universal features from 1.2M images:\n",
        "- Edges \u2192 Work on flower petals \u2705\n",
        "- Textures \u2192 Work on flower patterns \u2705\n",
        "- Shapes \u2192 Work on flower structure \u2705\n",
        "\n",
        "We just taught it: \"These features = daisy, these = rose, etc.\"\n",
        "\n",
        "---\n",
        "\n",
        "## \u2705 Key Takeaways\n",
        "\n",
        "Before moving to Notebook 03, make sure you understand:\n",
        "\n",
        "- \u2705 **Feature extraction strategy:** Freeze base, train classifier only\n",
        "- \u2705 **Why it works:** Universal features transfer across domains\n",
        "- \u2705 **When to use:** Small datasets (<5K images), limited compute\n",
        "- \u2705 **Code pattern:** `base.trainable = False` is the key line!\n",
        "\n",
        "**Question:** Can we do EVEN BETTER than 90%?\n",
        "\n",
        "**Answer:** YES! \u2192 Notebook 03: Fine-Tuning\n",
        "\n",
        "---\n",
        "\n",
        "## \ud83d\ude80 Next Steps\n",
        "\n",
        "**Two options:**\n",
        "\n",
        "**Option 1: Learn Fine-Tuning (Advanced)**\n",
        "\ud83d\udc49 Open Notebook 03 to learn how to unfreeze top layers and reach 92-95% accuracy\n",
        "\n",
        "**Option 2: Compare Models**\n",
        "\ud83d\udc49 Open Notebook 04 to compare VGG16, ResNet50, MobileNetV2\n",
        "\n",
        "**Recommended:** Do both! But Notebook 03 teaches the most valuable skill.\n",
        "\n",
        "---\n",
        "\n",
        "**End of Notebook 02**\n",
        "\n",
        "**Status:** \u2705 Feature extraction mastered!\n",
        "\n",
        "**Achievement Unlocked:** \ud83c\udfc6 90% accuracy with small dataset\n",
        "\n",
        "**Time spent:** ~8-10 minutes\n",
        "\n",
        "**Next:** Notebook 03 - Fine-Tuning (optional but powerful!) \ud83d\udd25"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.8.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}