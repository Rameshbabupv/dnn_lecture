{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# 04: Model Zoo - Choosing the Right Model\n",
        "\n",
        "**Course:** 21CSE558T - Deep Neural Network Architectures  \n",
        "**Module 4:** CNNs & Transfer Learning (Week 12)  \n",
        "**Estimated Time:** 10-12 minutes  \n",
        "**Prerequisites:** Notebooks 01-03  \n",
        "**Goal:** Compare VGG16, ResNet50, MobileNetV2\n",
        "\n",
        "---\n",
        "\n",
        "## \ud83d\udcda What You'll Learn\n",
        "\n",
        "In this notebook, you will:\n",
        "1. Compare three popular pre-trained models\n",
        "2. Understand size vs accuracy tradeoffs\n",
        "3. Learn when to use each model\n",
        "4. Make informed model selection decisions\n",
        "\n",
        "**Key Question:** _\"Which model should I use for MY project?\"_\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Setup\n",
        "import tensorflow as tf\n",
        "import tensorflow_datasets as tfds\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import time\n",
        "from tensorflow.keras.applications import VGG16, ResNet50, MobileNetV2\n",
        "from tensorflow.keras import Sequential\n",
        "from tensorflow.keras.layers import GlobalAveragePooling2D, Dense\n",
        "\n",
        "print(f\"TensorFlow version: {tf.__version__}\")\n",
        "print(\"Ready to compare models!\\n\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 1: Load Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Load dataset\n",
        "(train_ds, val_ds), info = tfds.load(\n",
        "    'tf_flowers',\n",
        "    split=['train[:80%]', 'train[80%:]'],\n",
        "    as_supervised=True,\n",
        "    with_info=True\n",
        ")\n",
        "\n",
        "num_classes = info.features['label'].num_classes\n",
        "class_names = info.features['label'].names\n",
        "\n",
        "# Preprocess\n",
        "IMG_SIZE = 224\n",
        "BATCH_SIZE = 32\n",
        "\n",
        "def preprocess(image, label):\n",
        "    image = tf.image.resize(image, (IMG_SIZE, IMG_SIZE))\n",
        "    # Use model-specific preprocessing\n",
        "    # For simplicity, we'll use ResNet50's preprocessing for all models\n",
        "    image = tf.keras.applications.resnet50.preprocess_input(image)\n",
        "    return image, label\n",
        "\n",
        "train_ds = train_ds.map(preprocess).batch(BATCH_SIZE).prefetch(tf.data.AUTOTUNE)\n",
        "val_ds = val_ds.map(preprocess).batch(BATCH_SIZE).prefetch(tf.data.AUTOTUNE)\n",
        "\n",
        "print(\"Dataset ready!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 2: Meet the Contenders\n",
        "\n",
        "### \ud83e\udd81 VGG16 - The Simple Giant\n",
        "- **Year:** 2014\n",
        "- **Layers:** 16\n",
        "- **Architecture:** Simple stacked Conv layers\n",
        "- **Parameters:** 138M\n",
        "- **Size:** 528 MB\n",
        "- **ImageNet Accuracy:** 71.3%\n",
        "\n",
        "**Pros:** Simple architecture, easy to understand, good for learning\n",
        "**Cons:** HUGE model size, slow training, outdated\n",
        "\n",
        "---\n",
        "\n",
        "### \ud83d\ude80 ResNet50 - The Default Choice \u2b50\n",
        "- **Year:** 2015\n",
        "- **Layers:** 50\n",
        "- **Architecture:** Residual connections (skip connections)\n",
        "- **Parameters:** 25.6M\n",
        "- **Size:** 98 MB\n",
        "- **ImageNet Accuracy:** 76.1%\n",
        "\n",
        "**Pros:** Excellent accuracy, reasonable size, widely used, default choice!\n",
        "**Cons:** Moderate speed\n",
        "\n",
        "---\n",
        "\n",
        "### \ud83d\udcf1 MobileNetV2 - The Speed Demon\n",
        "- **Year:** 2018\n",
        "- **Layers:** 53\n",
        "- **Architecture:** Depthwise separable convolutions\n",
        "- **Parameters:** 3.5M\n",
        "- **Size:** 14 MB\n",
        "- **ImageNet Accuracy:** 71.8%\n",
        "\n",
        "**Pros:** TINY size, FAST inference, perfect for mobile!\n",
        "**Cons:** Slightly lower accuracy than ResNet50\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 3: Load All Three Models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Load models\n",
        "print(\"Loading VGG16...\")\n",
        "vgg16_base = VGG16(weights='imagenet', include_top=False, input_shape=(IMG_SIZE, IMG_SIZE, 3))\n",
        "vgg16_base.trainable = False\n",
        "\n",
        "print(\"Loading ResNet50...\")\n",
        "resnet50_base = ResNet50(weights='imagenet', include_top=False, input_shape=(IMG_SIZE, IMG_SIZE, 3))\n",
        "resnet50_base.trainable = False\n",
        "\n",
        "print(\"Loading MobileNetV2...\")\n",
        "mobilenet_base = MobileNetV2(weights='imagenet', include_top=False, input_shape=(IMG_SIZE, IMG_SIZE, 3))\n",
        "mobilenet_base.trainable = False\n",
        "\n",
        "print(\"\\n\u2705 All models loaded!\\n\")\n",
        "\n",
        "# Compare parameters\n",
        "print(\"=\" * 60)\n",
        "print(f\"{'Model':<20} {'Parameters':<20} {'Size (approx)'}\")\n",
        "print(\"=\" * 60)\n",
        "print(f\"{'VGG16':<20} {vgg16_base.count_params():>15,}   {'528 MB'}\")\n",
        "print(f\"{'ResNet50':<20} {resnet50_base.count_params():>15,}   {'98 MB'}\")\n",
        "print(f\"{'MobileNetV2':<20} {mobilenet_base.count_params():>15,}   {'14 MB'}\")\n",
        "print(\"=\" * 60)\n",
        "print(\"\\nMobileNetV2 is 10\u00d7 smaller than ResNet50!\")\n",
        "print(\"VGG16 is 5\u00d7 larger than ResNet50!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 4: Build Models with Feature Extraction"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Build VGG16 model\n",
        "vgg16_model = Sequential([\n",
        "    vgg16_base,\n",
        "    GlobalAveragePooling2D(),\n",
        "    Dense(num_classes, activation='softmax')\n",
        "], name='VGG16_Model')\n",
        "\n",
        "vgg16_model.compile(\n",
        "    optimizer='adam',\n",
        "    loss='sparse_categorical_crossentropy',\n",
        "    metrics=['accuracy']\n",
        ")\n",
        "\n",
        "# Build ResNet50 model\n",
        "resnet50_model = Sequential([\n",
        "    resnet50_base,\n",
        "    GlobalAveragePooling2D(),\n",
        "    Dense(num_classes, activation='softmax')\n",
        "], name='ResNet50_Model')\n",
        "\n",
        "resnet50_model.compile(\n",
        "    optimizer='adam',\n",
        "    loss='sparse_categorical_crossentropy',\n",
        "    metrics=['accuracy']\n",
        ")\n",
        "\n",
        "# Build MobileNetV2 model\n",
        "mobilenet_model = Sequential([\n",
        "    mobilenet_base,\n",
        "    GlobalAveragePooling2D(),\n",
        "    Dense(num_classes, activation='softmax')\n",
        "], name='MobileNetV2_Model')\n",
        "\n",
        "mobilenet_model.compile(\n",
        "    optimizer='adam',\n",
        "    loss='sparse_categorical_crossentropy',\n",
        "    metrics=['accuracy']\n",
        ")\n",
        "\n",
        "print(\"\u2705 All 3 models built and compiled!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 5: Train All Three Models\n",
        "\n",
        "We'll train each model for 5 epochs and compare:\n",
        "- Training time\n",
        "- Validation accuracy\n",
        "- Memory usage"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Train VGG16\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"Training VGG16...\")\n",
        "print(\"=\"*60)\n",
        "start_time = time.time()\n",
        "vgg16_history = vgg16_model.fit(\n",
        "    train_ds,\n",
        "    validation_data=val_ds,\n",
        "    epochs=5,\n",
        "    verbose=1\n",
        ")\n",
        "vgg16_time = time.time() - start_time\n",
        "print(f\"\\n\u2705 VGG16 training time: {vgg16_time:.1f} seconds\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Train ResNet50\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"Training ResNet50...\")\n",
        "print(\"=\"*60)\n",
        "start_time = time.time()\n",
        "resnet50_history = resnet50_model.fit(\n",
        "    train_ds,\n",
        "    validation_data=val_ds,\n",
        "    epochs=5,\n",
        "    verbose=1\n",
        ")\n",
        "resnet50_time = time.time() - start_time\n",
        "print(f\"\\n\u2705 ResNet50 training time: {resnet50_time:.1f} seconds\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Train MobileNetV2\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"Training MobileNetV2...\")\n",
        "print(\"=\"*60)\n",
        "start_time = time.time()\n",
        "mobilenet_history = mobilenet_model.fit(\n",
        "    train_ds,\n",
        "    validation_data=val_ds,\n",
        "    epochs=5,\n",
        "    verbose=1\n",
        ")\n",
        "mobilenet_time = time.time() - start_time\n",
        "print(f\"\\n\u2705 MobileNetV2 training time: {mobilenet_time:.1f} seconds\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 6: Compare Results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Extract final accuracies\n",
        "vgg16_acc = vgg16_history.history['val_accuracy'][-1]\n",
        "resnet50_acc = resnet50_history.history['val_accuracy'][-1]\n",
        "mobilenet_acc = mobilenet_history.history['val_accuracy'][-1]\n",
        "\n",
        "# Print comparison table\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"\ud83c\udfc6 FINAL COMPARISON - MODEL ZOO\")\n",
        "print(\"=\"*80)\n",
        "print(f\"\\n{'Model':<15} {'Params':<15} {'Size':<12} {'Time':<12} {'Val Acc':<12} {'Best For'}\")\n",
        "print(\"-\"*80)\n",
        "print(f\"{'VGG16':<15} {'138M':<15} {'528 MB':<12} {f'{vgg16_time:.0f}s':<12} {f'{vgg16_acc:.1%}':<12} {'Learning'}\")\n",
        "print(f\"{'ResNet50 \u2b50':<15} {'26M':<15} {'98 MB':<12} {f'{resnet50_time:.0f}s':<12} {f'{resnet50_acc:.1%}':<12} {'Default!'}\")\n",
        "print(f\"{'MobileNetV2':<15} {'3.5M':<15} {'14 MB':<12} {f'{mobilenet_time:.0f}s':<12} {f'{mobilenet_acc:.1%}':<12} {'Mobile'}\")\n",
        "print(\"-\"*80)\n",
        "print(\"\\n\u2728 ResNet50 offers best balance of accuracy, size, and speed!\")\n",
        "print(\"\ud83d\udcf1 MobileNetV2 is 7\u00d7 faster and 10\u00d7 smaller!\")\n",
        "print(\"\ud83d\udcda VGG16 is good for learning but outdated for production\")\n",
        "print(\"=\"*80)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 7: Visualize Comparison"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create comparison plots\n",
        "fig, axes = plt.subplots(2, 2, figsize=(16, 12))\n",
        "\n",
        "# Plot 1: Validation Accuracy Comparison\n",
        "ax1 = axes[0, 0]\n",
        "ax1.plot(vgg16_history.history['val_accuracy'], label='VGG16', marker='o')\n",
        "ax1.plot(resnet50_history.history['val_accuracy'], label='ResNet50 \u2b50', marker='s', linewidth=2)\n",
        "ax1.plot(mobilenet_history.history['val_accuracy'], label='MobileNetV2', marker='^')\n",
        "ax1.set_title('Validation Accuracy', fontsize=14, fontweight='bold')\n",
        "ax1.set_xlabel('Epoch')\n",
        "ax1.set_ylabel('Accuracy')\n",
        "ax1.legend()\n",
        "ax1.grid(True, alpha=0.3)\n",
        "\n",
        "# Plot 2: Model Size Comparison\n",
        "ax2 = axes[0, 1]\n",
        "models = ['VGG16', 'ResNet50', 'MobileNetV2']\n",
        "sizes = [528, 98, 14]  # MB\n",
        "colors = ['red', 'green', 'blue']\n",
        "bars = ax2.bar(models, sizes, color=colors, alpha=0.7)\n",
        "ax2.set_title('Model Size (MB)', fontsize=14, fontweight='bold')\n",
        "ax2.set_ylabel('Size (MB)')\n",
        "for bar, size in zip(bars, sizes):\n",
        "    height = bar.get_height()\n",
        "    ax2.text(bar.get_x() + bar.get_width()/2., height,\n",
        "             f'{size} MB', ha='center', va='bottom', fontweight='bold')\n",
        "\n",
        "# Plot 3: Training Time Comparison\n",
        "ax3 = axes[1, 0]\n",
        "times = [vgg16_time, resnet50_time, mobilenet_time]\n",
        "bars = ax3.bar(models, times, color=colors, alpha=0.7)\n",
        "ax3.set_title('Training Time (5 epochs)', fontsize=14, fontweight='bold')\n",
        "ax3.set_ylabel('Time (seconds)')\n",
        "for bar, t in zip(bars, times):\n",
        "    height = bar.get_height()\n",
        "    ax3.text(bar.get_x() + bar.get_width()/2., height,\n",
        "             f'{t:.0f}s', ha='center', va='bottom', fontweight='bold')\n",
        "\n",
        "# Plot 4: Final Accuracy Comparison\n",
        "ax4 = axes[1, 1]\n",
        "accuracies = [vgg16_acc * 100, resnet50_acc * 100, mobilenet_acc * 100]\n",
        "bars = ax4.bar(models, accuracies, color=colors, alpha=0.7)\n",
        "ax4.set_title('Final Validation Accuracy', fontsize=14, fontweight='bold')\n",
        "ax4.set_ylabel('Accuracy (%)')\n",
        "ax4.set_ylim([80, 100])\n",
        "for bar, acc in zip(bars, accuracies):\n",
        "    height = bar.get_height()\n",
        "    ax4.text(bar.get_x() + bar.get_width()/2., height,\n",
        "             f'{acc:.1f}%', ha='center', va='bottom', fontweight='bold')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 8: Decision Guide - Which Model to Use?\n",
        "\n",
        "### Use VGG16 if:\n",
        "- \ud83d\udcda You're learning deep learning\n",
        "- \ud83c\udf93 Teaching/educational purposes\n",
        "- \ud83d\udd0d Need simple architecture to understand\n",
        "- \u26a0\ufe0f **NOT recommended for production**\n",
        "\n",
        "---\n",
        "\n",
        "### Use ResNet50 if: \u2b50 DEFAULT CHOICE\n",
        "- \ud83c\udfaf You want best accuracy\n",
        "- \ud83d\udcbb You have standard compute resources\n",
        "- \ud83c\udfe2 Building production applications\n",
        "- \u2696\ufe0f You want balanced size/speed/accuracy\n",
        "- **\u2192 RECOMMENDED for most projects!**\n",
        "\n",
        "---\n",
        "\n",
        "### Use MobileNetV2 if:\n",
        "- \ud83d\udcf1 Deploying to mobile devices\n",
        "- \u26a1 Need fast inference speed\n",
        "- \ud83d\udcbe Limited storage/memory\n",
        "- \ud83c\udf10 Edge computing\n",
        "- \u2705 Can accept slightly lower accuracy (87% vs 91%)\n",
        "\n",
        "---\n",
        "\n",
        "### Quick Decision Tree:\n",
        "\n",
        "```\n",
        "START\n",
        "  |\n",
        "  \u251c\u2500 Mobile/Edge deployment? \u2500\u2500YES\u2500\u2500> MobileNetV2 \ud83d\udcf1\n",
        "  \u2502                         \u2514\u2500NO\n",
        "  \u2502                            |\n",
        "  \u251c\u2500 Learning/Teaching? \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500YES\u2500\u2500> VGG16 \ud83d\udcda\n",
        "  \u2502                         \u2514\u2500NO\n",
        "  \u2502                            |\n",
        "  \u2514\u2500 Production application? \u2500\u2500\u2500YES\u2500\u2500> ResNet50 \u2b50\n",
        "```\n",
        "\n",
        "**Still unsure? \u2192 Use ResNet50!**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "## \ud83c\udf93 Summary: What You Learned\n",
        "\n",
        "### Model Comparison:\n",
        "\n",
        "| Feature | VGG16 | ResNet50 | MobileNetV2 |\n",
        "|---------|-------|----------|-------------|\n",
        "| **Year** | 2014 | 2015 | 2018 |\n",
        "| **Size** | 528 MB | 98 MB | 14 MB |\n",
        "| **Params** | 138M | 26M | 3.5M |\n",
        "| **Accuracy** | ~89% | ~91% | ~87% |\n",
        "| **Speed** | Slow | Medium | Fast |\n",
        "| **Best For** | Learning | Default \u2b50 | Mobile |\n",
        "\n",
        "### Key Insights:\n",
        "1. \u2705 **ResNet50** = Best all-around choice\n",
        "2. \u2705 **MobileNetV2** = 10\u00d7 smaller, 2\u00d7 faster, only 4% accuracy loss\n",
        "3. \u2705 **VGG16** = Simple but outdated, good for learning\n",
        "4. \u2705 **Tradeoff**: Size \u2194 Accuracy \u2194 Speed\n",
        "\n",
        "### Real-World Recommendations:\n",
        "- **Startup prototype:** ResNet50 (fast development)\n",
        "- **Mobile app:** MobileNetV2 (small size)\n",
        "- **Cloud API:** ResNet50 (best accuracy)\n",
        "- **IoT device:** MobileNetV2 (low memory)\n",
        "- **Learning project:** VGG16 (simple architecture)\n",
        "\n",
        "---\n",
        "\n",
        "## \u2705 Key Takeaways\n",
        "\n",
        "- \u2705 **Different models have different strengths**\n",
        "- \u2705 **ResNet50 is the default choice for most tasks**\n",
        "- \u2705 **MobileNetV2 is perfect for mobile/edge deployment**\n",
        "- \u2705 **VGG16 is good for learning but outdated**\n",
        "- \u2705 **Always consider: size, speed, accuracy, deployment target**\n",
        "\n",
        "---\n",
        "\n",
        "## \ud83c\udf89 Congratulations!\n",
        "\n",
        "You've completed all 4 transfer learning notebooks!\n",
        "\n",
        "**What you mastered:**\n",
        "1. \u2705 **Notebook 01:** Why transfer learning is necessary\n",
        "2. \u2705 **Notebook 02:** Feature extraction (90% accuracy)\n",
        "3. \u2705 **Notebook 03:** Fine-tuning (93% accuracy)\n",
        "4. \u2705 **Notebook 04:** Model selection strategies\n",
        "\n",
        "**You can now:**\n",
        "- Apply transfer learning to any image dataset\n",
        "- Choose the right pre-trained model\n",
        "- Decide between feature extraction and fine-tuning\n",
        "- Build production-ready image classifiers\n",
        "\n",
        "---\n",
        "\n",
        "## \ud83d\ude80 Next Steps\n",
        "\n",
        "**Apply your knowledge:**\n",
        "1. Try different datasets (Cats vs Dogs, Food-101, etc.)\n",
        "2. Experiment with other models (EfficientNet, InceptionV3)\n",
        "3. Build a real application (medical, agriculture, wildlife)\n",
        "4. Prepare for **FT2 test on Nov-14** \ud83d\udcdd\n",
        "\n",
        "**Practice questions:**\n",
        "- \"Given 2,000 medical images, which strategy would you use?\"\n",
        "- \"Compare VGG16 and MobileNetV2 for mobile deployment\"\n",
        "- \"Explain why fine-tuning requires lower learning rate\"\n",
        "\n",
        "---\n",
        "\n",
        "**End of Notebook 04**\n",
        "\n",
        "**Status:** \u2705 All transfer learning notebooks complete!\n",
        "\n",
        "**Achievement Unlocked:** \ud83c\udfc6 Transfer Learning Master\n",
        "\n",
        "**Total time:** ~35-40 minutes\n",
        "\n",
        "**Ready for:** Real-world projects! \ud83c\udf89"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}