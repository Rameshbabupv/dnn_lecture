{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "header"
   },
   "source": [
    "# Week 9 - Tutorial T9: Feature Extraction from Images\n",
    "## Deep Neural Network Architectures (21CSE558T)\n",
    "\n",
    "**Module 3:** Image Processing and Deep Neural Networks  \n",
    "**Date:** October 16, 2025 (Day Order 4)  \n",
    "**Duration:** 1 hour practical session  \n",
    "**Learning Outcome:** CO-3 - Apply deep neural networks in image processing\n",
    "\n",
    "---\n",
    "\n",
    "## üìã Notebook Overview\n",
    "\n",
    "In this hands-on tutorial, you will learn to:\n",
    "1. **Extract shape features** from segmented objects (area, perimeter, circularity, Hu moments)\n",
    "2. **Compute color features** using histograms and statistical moments\n",
    "3. **Calculate texture features** using edge density and GLCM properties\n",
    "4. **Build feature vectors** combining multiple descriptors\n",
    "5. **Implement classification** using traditional ML algorithms\n",
    "\n",
    "### Why This Matters\n",
    "Understanding manual feature extraction helps you:\n",
    "- Appreciate what CNNs learn automatically (Module 4 next week)\n",
    "- Work with small datasets where CNNs struggle\n",
    "- Build explainable AI systems\n",
    "- Understand computer vision fundamentals\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "setup"
   },
   "source": [
    "## üîß Setup and Installation\n",
    "\n",
    "Let's install and import all required libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "install"
   },
   "outputs": [],
   "source": [
    "# Install required packages (run this in Google Colab)\n",
    "!pip install opencv-python-headless scikit-image scikit-learn matplotlib numpy\n",
    "\n",
    "print(\"‚úÖ Installation complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "imports"
   },
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "from skimage.feature import graycomatrix, graycoprops, local_binary_pattern\n",
    "import pandas as pd\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "np.random.seed(42)\n",
    "\n",
    "print(\"‚úÖ All libraries imported successfully!\")\n",
    "print(f\"OpenCV version: {cv2.__version__}\")\n",
    "print(f\"NumPy version: {np.__version__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "helper_functions"
   },
   "source": [
    "## üõ†Ô∏è Helper Functions for Visualization\n",
    "\n",
    "These functions will help us display images nicely."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "display_functions"
   },
   "outputs": [],
   "source": [
    "def display_image(image, title=\"Image\", cmap=None, figsize=(8, 6)):\n",
    "    \"\"\"\n",
    "    Display a single image with title.\n",
    "    \n",
    "    Args:\n",
    "        image: Image array\n",
    "        title: Display title\n",
    "        cmap: Colormap (None for color images, 'gray' for grayscale)\n",
    "        figsize: Figure size\n",
    "    \"\"\"\n",
    "    plt.figure(figsize=figsize)\n",
    "    if len(image.shape) == 3 and image.shape[2] == 3:\n",
    "        # BGR to RGB for matplotlib\n",
    "        plt.imshow(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))\n",
    "    else:\n",
    "        plt.imshow(image, cmap=cmap)\n",
    "    plt.title(title, fontsize=14, fontweight='bold')\n",
    "    plt.axis('off')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "def display_images_grid(images, titles, rows=1, cols=3, figsize=(15, 5), cmap=None):\n",
    "    \"\"\"\n",
    "    Display multiple images in a grid.\n",
    "    \n",
    "    Args:\n",
    "        images: List of image arrays\n",
    "        titles: List of titles\n",
    "        rows: Number of rows\n",
    "        cols: Number of columns\n",
    "        figsize: Figure size\n",
    "        cmap: Colormap\n",
    "    \"\"\"\n",
    "    fig, axes = plt.subplots(rows, cols, figsize=figsize)\n",
    "    if rows == 1:\n",
    "        axes = [axes] if cols == 1 else axes\n",
    "    else:\n",
    "        axes = axes.flatten()\n",
    "    \n",
    "    for idx, (img, title) in enumerate(zip(images, titles)):\n",
    "        if len(img.shape) == 3 and img.shape[2] == 3:\n",
    "            axes[idx].imshow(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))\n",
    "        else:\n",
    "            axes[idx].imshow(img, cmap=cmap if cmap else 'gray')\n",
    "        axes[idx].set_title(title, fontweight='bold')\n",
    "        axes[idx].axis('off')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "print(\"‚úÖ Helper functions defined!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "part1_header"
   },
   "source": [
    "---\n",
    "\n",
    "# Part 1: Shape Features üî∑\n",
    "\n",
    "## The Cookie Factory Robot Analogy\n",
    "Remember: We're teaching the computer to measure geometric properties, just like a quality control robot in a cookie factory checks if cookies are the right shape!\n",
    "\n",
    "### Shape Features We'll Extract:\n",
    "1. **Area** - How much space inside?\n",
    "2. **Perimeter** - Length of boundary\n",
    "3. **Circularity** - How round is it? (1.0 = perfect circle)\n",
    "4. **Aspect Ratio** - Tall or wide?\n",
    "5. **Solidity** - How filled is it?\n",
    "6. **Extent** - How well does it fill bounding box?\n",
    "7. **Hu Moments** - Shape fingerprint (rotation invariant)\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "create_sample_shapes"
   },
   "source": [
    "## 1.1 Create Sample Shapes\n",
    "\n",
    "Let's create simple geometric shapes to practice on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "generate_shapes"
   },
   "outputs": [],
   "source": [
    "def create_circle(size=300):\n",
    "    \"\"\"Create a white circle on black background.\"\"\"\n",
    "    img = np.zeros((size, size), dtype=np.uint8)\n",
    "    center = (size // 2, size // 2)\n",
    "    radius = size // 3\n",
    "    cv2.circle(img, center, radius, 255, -1)\n",
    "    return img\n",
    "\n",
    "def create_rectangle(size=300):\n",
    "    \"\"\"Create a white rectangle on black background.\"\"\"\n",
    "    img = np.zeros((size, size), dtype=np.uint8)\n",
    "    pt1 = (size // 4, size // 3)\n",
    "    pt2 = (3 * size // 4, 2 * size // 3)\n",
    "    cv2.rectangle(img, pt1, pt2, 255, -1)\n",
    "    return img\n",
    "\n",
    "def create_triangle(size=300):\n",
    "    \"\"\"Create a white triangle on black background.\"\"\"\n",
    "    img = np.zeros((size, size), dtype=np.uint8)\n",
    "    pts = np.array([[size//2, size//4], [size//4, 3*size//4], [3*size//4, 3*size//4]])\n",
    "    cv2.fillPoly(img, [pts], 255)\n",
    "    return img\n",
    "\n",
    "def create_star(size=300):\n",
    "    \"\"\"Create a white star on black background.\"\"\"\n",
    "    img = np.zeros((size, size), dtype=np.uint8)\n",
    "    center = (size // 2, size // 2)\n",
    "    outer_radius = size // 3\n",
    "    inner_radius = size // 6\n",
    "    \n",
    "    # Create 5-pointed star\n",
    "    pts = []\n",
    "    for i in range(10):\n",
    "        angle = i * np.pi / 5 - np.pi / 2\n",
    "        radius = outer_radius if i % 2 == 0 else inner_radius\n",
    "        x = int(center[0] + radius * np.cos(angle))\n",
    "        y = int(center[1] + radius * np.sin(angle))\n",
    "        pts.append([x, y])\n",
    "    \n",
    "    pts = np.array(pts)\n",
    "    cv2.fillPoly(img, [pts], 255)\n",
    "    return img\n",
    "\n",
    "# Create shapes\n",
    "circle = create_circle()\n",
    "rectangle = create_rectangle()\n",
    "triangle = create_triangle()\n",
    "star = create_star()\n",
    "\n",
    "# Display all shapes\n",
    "display_images_grid(\n",
    "    [circle, rectangle, triangle, star],\n",
    "    ['Circle', 'Rectangle', 'Triangle', 'Star'],\n",
    "    rows=1, cols=4, figsize=(16, 4), cmap='gray'\n",
    ")\n",
    "\n",
    "print(\"‚úÖ Sample shapes created!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "extract_contours"
   },
   "source": [
    "## 1.2 Find Contours\n",
    "\n",
    "Before extracting features, we need to find the **contours** (boundaries) of objects."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "find_contours"
   },
   "outputs": [],
   "source": [
    "def find_largest_contour(image):\n",
    "    \"\"\"\n",
    "    Find the largest contour in a binary image.\n",
    "    \n",
    "    Args:\n",
    "        image: Binary image (0s and 255s)\n",
    "    \n",
    "    Returns:\n",
    "        Largest contour\n",
    "    \"\"\"\n",
    "    contours, _ = cv2.findContours(image, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    \n",
    "    if len(contours) == 0:\n",
    "        return None\n",
    "    \n",
    "    # Find largest contour by area\n",
    "    largest_contour = max(contours, key=cv2.contourArea)\n",
    "    return largest_contour\n",
    "\n",
    "# Find contours for all shapes\n",
    "contour_circle = find_largest_contour(circle)\n",
    "contour_rectangle = find_largest_contour(rectangle)\n",
    "contour_triangle = find_largest_contour(triangle)\n",
    "contour_star = find_largest_contour(star)\n",
    "\n",
    "# Visualize contours\n",
    "circle_vis = cv2.cvtColor(circle, cv2.COLOR_GRAY2BGR)\n",
    "cv2.drawContours(circle_vis, [contour_circle], -1, (0, 255, 0), 2)\n",
    "\n",
    "rectangle_vis = cv2.cvtColor(rectangle, cv2.COLOR_GRAY2BGR)\n",
    "cv2.drawContours(rectangle_vis, [contour_rectangle], -1, (0, 255, 0), 2)\n",
    "\n",
    "display_images_grid(\n",
    "    [circle_vis, rectangle_vis],\n",
    "    ['Circle Contour', 'Rectangle Contour'],\n",
    "    rows=1, cols=2, figsize=(12, 5)\n",
    ")\n",
    "\n",
    "print(\"‚úÖ Contours found!\")\n",
    "print(f\"Circle contour points: {len(contour_circle)}\")\n",
    "print(f\"Rectangle contour points: {len(contour_rectangle)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "shape_features_extraction"
   },
   "source": [
    "## 1.3 Extract Shape Features\n",
    "\n",
    "Now let's extract ALL shape features from our contours!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "extract_shape_features"
   },
   "outputs": [],
   "source": [
    "def extract_shape_features(contour):\n",
    "    \"\"\"\n",
    "    Extract comprehensive shape features from a contour.\n",
    "    \n",
    "    Args:\n",
    "        contour: OpenCV contour object\n",
    "    \n",
    "    Returns:\n",
    "        Dictionary with shape features\n",
    "    \"\"\"\n",
    "    features = {}\n",
    "    \n",
    "    # 1. Area - How much space inside?\n",
    "    area = cv2.contourArea(contour)\n",
    "    features['area'] = area\n",
    "    \n",
    "    # 2. Perimeter - Length of boundary\n",
    "    perimeter = cv2.arcLength(contour, True)\n",
    "    features['perimeter'] = perimeter\n",
    "    \n",
    "    # 3. Circularity - How circle-like? (1.0 = perfect circle)\n",
    "    # Formula: 4œÄ √ó Area / Perimeter¬≤\n",
    "    if perimeter > 0:\n",
    "        circularity = 4 * np.pi * area / (perimeter ** 2)\n",
    "    else:\n",
    "        circularity = 0\n",
    "    features['circularity'] = circularity\n",
    "    \n",
    "    # 4. Bounding Box - Smallest rectangle that fits\n",
    "    x, y, w, h = cv2.boundingRect(contour)\n",
    "    features['bbox_x'] = x\n",
    "    features['bbox_y'] = y\n",
    "    features['bbox_width'] = w\n",
    "    features['bbox_height'] = h\n",
    "    \n",
    "    # 5. Aspect Ratio - Tall or wide?\n",
    "    if h > 0:\n",
    "        aspect_ratio = float(w) / h\n",
    "    else:\n",
    "        aspect_ratio = 0\n",
    "    features['aspect_ratio'] = aspect_ratio\n",
    "    \n",
    "    # 6. Extent - How well does it fill bounding box?\n",
    "    rect_area = w * h\n",
    "    if rect_area > 0:\n",
    "        extent = area / rect_area\n",
    "    else:\n",
    "        extent = 0\n",
    "    features['extent'] = extent\n",
    "    \n",
    "    # 7. Convex Hull - Smallest convex shape around object\n",
    "    hull = cv2.convexHull(contour)\n",
    "    hull_area = cv2.contourArea(hull)\n",
    "    features['hull_area'] = hull_area\n",
    "    \n",
    "    # 8. Solidity - How filled is it?\n",
    "    if hull_area > 0:\n",
    "        solidity = area / hull_area\n",
    "    else:\n",
    "        solidity = 0\n",
    "    features['solidity'] = solidity\n",
    "    \n",
    "    # 9. Hu Moments - Shape fingerprint (7 values)\n",
    "    moments = cv2.moments(contour)\n",
    "    hu_moments = cv2.HuMoments(moments)\n",
    "    \n",
    "    # Log transform for better scale\n",
    "    for i in range(7):\n",
    "        if hu_moments[i][0] != 0:\n",
    "            hu_moments[i][0] = -np.sign(hu_moments[i][0]) * np.log10(abs(hu_moments[i][0]))\n",
    "    \n",
    "    features['hu_moment_1'] = hu_moments[0][0]\n",
    "    features['hu_moment_2'] = hu_moments[1][0]\n",
    "    features['hu_moment_3'] = hu_moments[2][0]\n",
    "    features['hu_moment_4'] = hu_moments[3][0]\n",
    "    features['hu_moment_5'] = hu_moments[4][0]\n",
    "    features['hu_moment_6'] = hu_moments[5][0]\n",
    "    features['hu_moment_7'] = hu_moments[6][0]\n",
    "    \n",
    "    return features\n",
    "\n",
    "# Extract features for all shapes\n",
    "shape_names = ['Circle', 'Rectangle', 'Triangle', 'Star']\n",
    "contours_list = [contour_circle, contour_rectangle, contour_triangle, contour_star]\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"SHAPE FEATURES EXTRACTION RESULTS\")\n",
    "print(\"=\"*80 + \"\\n\")\n",
    "\n",
    "all_shape_features = []\n",
    "for name, contour in zip(shape_names, contours_list):\n",
    "    features = extract_shape_features(contour)\n",
    "    all_shape_features.append(features)\n",
    "    \n",
    "    print(f\"üìê {name.upper()}:\")\n",
    "    print(f\"   Area:         {features['area']:.2f} pixels¬≤\")\n",
    "    print(f\"   Perimeter:    {features['perimeter']:.2f} pixels\")\n",
    "    print(f\"   Circularity:  {features['circularity']:.3f} (1.0 = perfect circle)\")\n",
    "    print(f\"   Aspect Ratio: {features['aspect_ratio']:.3f} (1.0 = square)\")\n",
    "    print(f\"   Extent:       {features['extent']:.3f} (how well it fills bbox)\")\n",
    "    print(f\"   Solidity:     {features['solidity']:.3f} (1.0 = convex shape)\")\n",
    "    print(f\"   Hu Moment 1:  {features['hu_moment_1']:.3f} (shape fingerprint)\")\n",
    "    print()\n",
    "\n",
    "# Create comparison DataFrame\n",
    "df_shapes = pd.DataFrame(all_shape_features, index=shape_names)\n",
    "print(\"\\nüìä SHAPE FEATURES COMPARISON TABLE:\")\n",
    "print(df_shapes[['area', 'perimeter', 'circularity', 'aspect_ratio', 'solidity']].round(3))\n",
    "\n",
    "print(\"\\n‚úÖ Shape features extracted successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "shape_analysis"
   },
   "source": [
    "## 1.4 Analyze Shape Features\n",
    "\n",
    "Let's understand what these numbers tell us!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "visualize_shape_features"
   },
   "outputs": [],
   "source": [
    "# Visualize key shape features\n",
    "fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
    "\n",
    "# 1. Area comparison\n",
    "axes[0, 0].bar(shape_names, [f['area'] for f in all_shape_features], color='skyblue')\n",
    "axes[0, 0].set_title('Area Comparison', fontweight='bold', fontsize=12)\n",
    "axes[0, 0].set_ylabel('Area (pixels¬≤)')\n",
    "axes[0, 0].grid(axis='y', alpha=0.3)\n",
    "\n",
    "# 2. Circularity comparison\n",
    "axes[0, 1].bar(shape_names, [f['circularity'] for f in all_shape_features], color='lightcoral')\n",
    "axes[0, 1].set_title('Circularity (1.0 = Perfect Circle)', fontweight='bold', fontsize=12)\n",
    "axes[0, 1].set_ylabel('Circularity')\n",
    "axes[0, 1].axhline(y=1.0, color='red', linestyle='--', label='Perfect Circle')\n",
    "axes[0, 1].legend()\n",
    "axes[0, 1].grid(axis='y', alpha=0.3)\n",
    "\n",
    "# 3. Aspect Ratio comparison\n",
    "axes[1, 0].bar(shape_names, [f['aspect_ratio'] for f in all_shape_features], color='lightgreen')\n",
    "axes[1, 0].set_title('Aspect Ratio (1.0 = Square)', fontweight='bold', fontsize=12)\n",
    "axes[1, 0].set_ylabel('Aspect Ratio')\n",
    "axes[1, 0].axhline(y=1.0, color='green', linestyle='--', label='Square')\n",
    "axes[1, 0].legend()\n",
    "axes[1, 0].grid(axis='y', alpha=0.3)\n",
    "\n",
    "# 4. Solidity comparison\n",
    "axes[1, 1].bar(shape_names, [f['solidity'] for f in all_shape_features], color='plum')\n",
    "axes[1, 1].set_title('Solidity (1.0 = Convex)', fontweight='bold', fontsize=12)\n",
    "axes[1, 1].set_ylabel('Solidity')\n",
    "axes[1, 1].axhline(y=1.0, color='purple', linestyle='--', label='Fully Convex')\n",
    "axes[1, 1].legend()\n",
    "axes[1, 1].grid(axis='y', alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nüîç OBSERVATIONS:\")\n",
    "print(\"   ‚úì Circle has highest circularity (closest to 1.0)\")\n",
    "print(\"   ‚úì Star has lowest solidity (concave shape)\")\n",
    "print(\"   ‚úì Rectangle has aspect ratio ‚â† 1.0 (not square)\")\n",
    "print(\"   ‚úì Each shape has unique feature signature!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "part2_header"
   },
   "source": [
    "---\n",
    "\n",
    "# Part 2: Color Features üé®\n",
    "\n",
    "## The Artist's Palette Analogy\n",
    "Just like an artist identifies paintings by color usage, we teach computers to describe images using color statistics!\n",
    "\n",
    "### Color Features We'll Extract:\n",
    "1. **Color Histograms** - Distribution of colors\n",
    "2. **Mean RGB** - Average color\n",
    "3. **Standard Deviation** - Color variation\n",
    "4. **Dominant Colors** - Main colors using K-means\n",
    "5. **HSV Features** - Hue, Saturation, Value\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "create_colored_images"
   },
   "source": [
    "## 2.1 Create Colored Sample Images\n",
    "\n",
    "Let's create colorful shapes to practice color feature extraction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "generate_colored_shapes"
   },
   "outputs": [],
   "source": [
    "def create_colored_circle(size=300, color=(0, 0, 255)):  # BGR format\n",
    "    \"\"\"Create a colored circle.\"\"\"\n",
    "    img = np.zeros((size, size, 3), dtype=np.uint8)\n",
    "    center = (size // 2, size // 2)\n",
    "    radius = size // 3\n",
    "    cv2.circle(img, center, radius, color, -1)\n",
    "    return img\n",
    "\n",
    "# Create colorful shapes\n",
    "red_circle = create_colored_circle(color=(0, 0, 255))     # Red in BGR\n",
    "green_circle = create_colored_circle(color=(0, 255, 0))   # Green\n",
    "blue_circle = create_colored_circle(color=(255, 0, 0))    # Blue\n",
    "orange_circle = create_colored_circle(color=(0, 165, 255)) # Orange\n",
    "\n",
    "# Create a multi-colored gradient image\n",
    "gradient = np.zeros((300, 300, 3), dtype=np.uint8)\n",
    "for i in range(300):\n",
    "    gradient[:, i] = [i * 255 // 300, (300-i) * 255 // 300, 128]\n",
    "\n",
    "display_images_grid(\n",
    "    [red_circle, green_circle, blue_circle, orange_circle, gradient],\n",
    "    ['Red Circle', 'Green Circle', 'Blue Circle', 'Orange Circle', 'Gradient'],\n",
    "    rows=1, cols=5, figsize=(20, 4)\n",
    ")\n",
    "\n",
    "print(\"‚úÖ Colored shapes created!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "color_histograms"
   },
   "source": [
    "## 2.2 Color Histograms\n",
    "\n",
    "A histogram shows the **distribution** of pixel intensities for each color channel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "compute_histograms"
   },
   "outputs": [],
   "source": [
    "def compute_color_histogram(image, bins=16):\n",
    "    \"\"\"\n",
    "    Compute color histogram for each channel.\n",
    "    \n",
    "    Args:\n",
    "        image: BGR color image\n",
    "        bins: Number of bins (default 16 for compact representation)\n",
    "    \n",
    "    Returns:\n",
    "        Concatenated histogram for all channels\n",
    "    \"\"\"\n",
    "    hist_features = []\n",
    "    \n",
    "    for channel in range(3):\n",
    "        hist = cv2.calcHist([image], [channel], None, [bins], [0, 256])\n",
    "        hist = hist.flatten()\n",
    "        hist = hist / (hist.sum() + 1e-7)  # Normalize\n",
    "        hist_features.extend(hist)\n",
    "    \n",
    "    return np.array(hist_features)\n",
    "\n",
    "# Visualize histograms for red circle\n",
    "fig, axes = plt.subplots(1, 4, figsize=(18, 4))\n",
    "\n",
    "# Display image\n",
    "axes[0].imshow(cv2.cvtColor(red_circle, cv2.COLOR_BGR2RGB))\n",
    "axes[0].set_title('Red Circle', fontweight='bold')\n",
    "axes[0].axis('off')\n",
    "\n",
    "# Plot histograms for each channel\n",
    "colors = ['blue', 'green', 'red']  # BGR order\n",
    "channel_names = ['Blue', 'Green', 'Red']\n",
    "\n",
    "for i, (color, name) in enumerate(zip(colors, channel_names)):\n",
    "    hist = cv2.calcHist([red_circle], [i], None, [256], [0, 256])\n",
    "    axes[i+1].plot(hist, color=color, linewidth=2)\n",
    "    axes[i+1].set_title(f'{name} Channel Histogram', fontweight='bold')\n",
    "    axes[i+1].set_xlabel('Pixel Intensity')\n",
    "    axes[i+1].set_ylabel('Frequency')\n",
    "    axes[i+1].grid(alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nüîç OBSERVATION:\")\n",
    "print(\"   ‚úì Red channel has high values (peak at 255)\")\n",
    "print(\"   ‚úì Blue and Green channels are near zero\")\n",
    "print(\"   ‚úì This signature uniquely identifies RED objects!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "color_moments"
   },
   "source": [
    "## 2.3 Color Statistical Moments\n",
    "\n",
    "Instead of full histogram (256 values), we can use **statistics** (just 3 numbers per channel)!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "extract_color_moments"
   },
   "outputs": [],
   "source": [
    "def extract_color_features(image):\n",
    "    \"\"\"\n",
    "    Extract comprehensive color features.\n",
    "    \n",
    "    Args:\n",
    "        image: BGR color image\n",
    "    \n",
    "    Returns:\n",
    "        Dictionary with color features\n",
    "    \"\"\"\n",
    "    features = {}\n",
    "    \n",
    "    # Convert to different color spaces\n",
    "    hsv = cv2.cvtColor(image, cv2.COLOR_BGR2HSV)\n",
    "    \n",
    "    # Extract mean for each channel (BGR)\n",
    "    mean_b, mean_g, mean_r = cv2.mean(image)[:3]\n",
    "    features['mean_blue'] = mean_b\n",
    "    features['mean_green'] = mean_g\n",
    "    features['mean_red'] = mean_r\n",
    "    \n",
    "    # Extract standard deviation for each channel\n",
    "    features['std_blue'] = np.std(image[:, :, 0])\n",
    "    features['std_green'] = np.std(image[:, :, 1])\n",
    "    features['std_red'] = np.std(image[:, :, 2])\n",
    "    \n",
    "    # HSV features\n",
    "    mean_h, mean_s, mean_v = cv2.mean(hsv)[:3]\n",
    "    features['mean_hue'] = mean_h\n",
    "    features['mean_saturation'] = mean_s\n",
    "    features['mean_value'] = mean_v\n",
    "    \n",
    "    # Compact histogram (16 bins per channel)\n",
    "    hist = compute_color_histogram(image, bins=16)\n",
    "    for i, val in enumerate(hist):\n",
    "        features[f'hist_bin_{i}'] = val\n",
    "    \n",
    "    return features\n",
    "\n",
    "# Extract color features for all colored shapes\n",
    "colored_shapes = {\n",
    "    'Red': red_circle,\n",
    "    'Green': green_circle,\n",
    "    'Blue': blue_circle,\n",
    "    'Orange': orange_circle\n",
    "}\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"COLOR FEATURES EXTRACTION RESULTS\")\n",
    "print(\"=\"*80 + \"\\n\")\n",
    "\n",
    "all_color_features = []\n",
    "for name, img in colored_shapes.items():\n",
    "    features = extract_color_features(img)\n",
    "    all_color_features.append(features)\n",
    "    \n",
    "    print(f\"üé® {name.upper()} CIRCLE:\")\n",
    "    print(f\"   Mean BGR:  ({features['mean_blue']:.1f}, {features['mean_green']:.1f}, {features['mean_red']:.1f})\")\n",
    "    print(f\"   Std BGR:   ({features['std_blue']:.1f}, {features['std_green']:.1f}, {features['std_red']:.1f})\")\n",
    "    print(f\"   Mean HSV:  (H:{features['mean_hue']:.1f}¬∞, S:{features['mean_saturation']:.1f}, V:{features['mean_value']:.1f})\")\n",
    "    print()\n",
    "\n",
    "# Create comparison DataFrame\n",
    "df_colors = pd.DataFrame(all_color_features, index=colored_shapes.keys())\n",
    "print(\"\\nüìä COLOR FEATURES COMPARISON:\")\n",
    "print(df_colors[['mean_blue', 'mean_green', 'mean_red', 'mean_hue', 'mean_saturation']].round(2))\n",
    "\n",
    "print(\"\\n‚úÖ Color features extracted successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dominant_colors"
   },
   "source": [
    "## 2.4 Dominant Color Extraction using K-Means\n",
    "\n",
    "Find the **main colors** in an image using K-means clustering."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kmeans_colors"
   },
   "outputs": [],
   "source": [
    "def extract_dominant_colors(image, k=3):\n",
    "    \"\"\"\n",
    "    Extract k dominant colors using K-means clustering.\n",
    "    \n",
    "    Args:\n",
    "        image: BGR color image\n",
    "        k: Number of dominant colors to extract\n",
    "    \n",
    "    Returns:\n",
    "        Array of dominant colors in BGR\n",
    "    \"\"\"\n",
    "    # Reshape image to list of pixels\n",
    "    pixels = image.reshape(-1, 3).astype(np.float32)\n",
    "    \n",
    "    # K-means clustering\n",
    "    criteria = (cv2.TERM_CRITERIA_EPS + cv2.TERM_CRITERIA_MAX_ITER, 100, 0.2)\n",
    "    _, labels, centers = cv2.kmeans(pixels, k, None, criteria, 10, cv2.KMEANS_RANDOM_CENTERS)\n",
    "    \n",
    "    # Convert back to uint8\n",
    "    centers = centers.astype(np.uint8)\n",
    "    \n",
    "    return centers\n",
    "\n",
    "def visualize_dominant_colors(image, colors):\n",
    "    \"\"\"Visualize dominant colors as color palette.\"\"\"\n",
    "    palette = np.zeros((100, 300, 3), dtype=np.uint8)\n",
    "    width = 300 // len(colors)\n",
    "    \n",
    "    for i, color in enumerate(colors):\n",
    "        palette[:, i*width:(i+1)*width] = color\n",
    "    \n",
    "    return palette\n",
    "\n",
    "# Extract dominant colors from gradient image\n",
    "dominant_colors = extract_dominant_colors(gradient, k=3)\n",
    "palette = visualize_dominant_colors(gradient, dominant_colors)\n",
    "\n",
    "display_images_grid(\n",
    "    [gradient, palette],\n",
    "    ['Original Gradient', '3 Dominant Colors'],\n",
    "    rows=1, cols=2, figsize=(12, 4)\n",
    ")\n",
    "\n",
    "print(\"\\nüé® DOMINANT COLORS (BGR format):\")\n",
    "for i, color in enumerate(dominant_colors):\n",
    "    print(f\"   Color {i+1}: B={color[0]}, G={color[1]}, R={color[2]}\")\n",
    "\n",
    "print(\"\\n‚úÖ Dominant color extraction complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "part3_header"
   },
   "source": [
    "---\n",
    "\n",
    "# Part 3: Texture Features üßµ\n",
    "\n",
    "## The Fabric Store Analogy\n",
    "Imagine shopping for fabric blindfolded - you identify materials by touch (smooth silk vs rough burlap). We teach computers to \"feel\" textures through patterns!\n",
    "\n",
    "### Texture Features We'll Extract:\n",
    "1. **Edge Density** - How rough is the surface?\n",
    "2. **Standard Deviation** - Intensity variation\n",
    "3. **GLCM Properties** - Co-occurrence patterns\n",
    "   - Contrast\n",
    "   - Homogeneity\n",
    "   - Energy\n",
    "   - Correlation\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "create_textures"
   },
   "source": [
    "## 3.1 Create Sample Textures\n",
    "\n",
    "Let's generate images with different texture patterns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "generate_textures"
   },
   "outputs": [],
   "source": [
    "def create_smooth_texture(size=200):\n",
    "    \"\"\"Create smooth texture (low variation).\"\"\"\n",
    "    texture = np.ones((size, size), dtype=np.uint8) * 128\n",
    "    # Add slight noise\n",
    "    noise = np.random.normal(0, 5, (size, size))\n",
    "    texture = np.clip(texture + noise, 0, 255).astype(np.uint8)\n",
    "    return texture\n",
    "\n",
    "def create_rough_texture(size=200):\n",
    "    \"\"\"Create rough texture (high variation).\"\"\"\n",
    "    texture = np.random.randint(0, 256, (size, size), dtype=np.uint8)\n",
    "    # Blur slightly to make it more realistic\n",
    "    texture = cv2.GaussianBlur(texture, (3, 3), 0)\n",
    "    return texture\n",
    "\n",
    "def create_striped_texture(size=200):\n",
    "    \"\"\"Create striped texture (regular pattern).\"\"\"\n",
    "    texture = np.zeros((size, size), dtype=np.uint8)\n",
    "    for i in range(0, size, 20):\n",
    "        texture[:, i:i+10] = 255\n",
    "    return texture\n",
    "\n",
    "def create_checkered_texture(size=200, block_size=20):\n",
    "    \"\"\"Create checkered texture.\"\"\"\n",
    "    texture = np.zeros((size, size), dtype=np.uint8)\n",
    "    for i in range(0, size, block_size*2):\n",
    "        for j in range(0, size, block_size*2):\n",
    "            texture[i:i+block_size, j:j+block_size] = 255\n",
    "            texture[i+block_size:i+block_size*2, j+block_size:j+block_size*2] = 255\n",
    "    return texture\n",
    "\n",
    "# Create different textures\n",
    "smooth = create_smooth_texture()\n",
    "rough = create_rough_texture()\n",
    "striped = create_striped_texture()\n",
    "checkered = create_checkered_texture()\n",
    "\n",
    "display_images_grid(\n",
    "    [smooth, rough, striped, checkered],\n",
    "    ['Smooth Texture', 'Rough Texture', 'Striped Pattern', 'Checkered Pattern'],\n",
    "    rows=1, cols=4, figsize=(16, 4), cmap='gray'\n",
    ")\n",
    "\n",
    "print(\"‚úÖ Sample textures created!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "simple_texture_features"
   },
   "source": [
    "## 3.2 Simple Texture Features\n",
    "\n",
    "Let's start with basic texture measurements."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "extract_simple_texture"
   },
   "outputs": [],
   "source": [
    "def extract_simple_texture_features(image):\n",
    "    \"\"\"\n",
    "    Extract simple texture features.\n",
    "    \n",
    "    Args:\n",
    "        image: Grayscale image\n",
    "    \n",
    "    Returns:\n",
    "        Dictionary with texture features\n",
    "    \"\"\"\n",
    "    features = {}\n",
    "    \n",
    "    # 1. Standard Deviation - Intensity variation\n",
    "    features['std_dev'] = np.std(image)\n",
    "    \n",
    "    # 2. Edge Density - How many edges?\n",
    "    edges = cv2.Canny(image, 50, 150)\n",
    "    edge_density = np.sum(edges > 0) / edges.size\n",
    "    features['edge_density'] = edge_density\n",
    "    \n",
    "    # 3. Mean intensity\n",
    "    features['mean_intensity'] = np.mean(image)\n",
    "    \n",
    "    return features\n",
    "\n",
    "# Extract features for all textures\n",
    "texture_names = ['Smooth', 'Rough', 'Striped', 'Checkered']\n",
    "textures = [smooth, rough, striped, checkered]\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"SIMPLE TEXTURE FEATURES\")\n",
    "print(\"=\"*80 + \"\\n\")\n",
    "\n",
    "simple_texture_features = []\n",
    "for name, texture in zip(texture_names, textures):\n",
    "    features = extract_simple_texture_features(texture)\n",
    "    simple_texture_features.append(features)\n",
    "    \n",
    "    print(f\"üßµ {name.upper()}:\")\n",
    "    print(f\"   Mean Intensity:  {features['mean_intensity']:.2f}\")\n",
    "    print(f\"   Std Deviation:   {features['std_dev']:.2f} (higher = more variation)\")\n",
    "    print(f\"   Edge Density:    {features['edge_density']:.4f} (higher = rougher)\")\n",
    "    print()\n",
    "\n",
    "# Visualize\n",
    "df_texture_simple = pd.DataFrame(simple_texture_features, index=texture_names)\n",
    "print(\"\\nüìä TEXTURE COMPARISON:\")\n",
    "print(df_texture_simple.round(4))\n",
    "\n",
    "print(\"\\n‚úÖ Simple texture features extracted!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "glcm_features"
   },
   "source": [
    "## 3.3 GLCM (Gray-Level Co-occurrence Matrix) Features\n",
    "\n",
    "GLCM analyzes **spatial relationships** between pixel intensities - \"How often does pixel value X appear next to pixel value Y?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "extract_glcm"
   },
   "outputs": [],
   "source": [
    "def extract_glcm_features(image):\n",
    "    \"\"\"\n",
    "    Extract GLCM texture features.\n",
    "    \n",
    "    Args:\n",
    "        image: Grayscale image\n",
    "    \n",
    "    Returns:\n",
    "        Dictionary with GLCM features\n",
    "    \"\"\"\n",
    "    features = {}\n",
    "    \n",
    "    # Normalize image to 0-255 range and reduce to 64 levels for efficiency\n",
    "    image_normalized = ((image / image.max()) * 255).astype(np.uint8)\n",
    "    image_reduced = image_normalized // 4  # Reduce to 64 levels\n",
    "    \n",
    "    # Compute GLCM\n",
    "    # distances: [1] means check immediate neighbors\n",
    "    # angles: [0, œÄ/4, œÄ/2, 3œÄ/4] means check in 4 directions\n",
    "    distances = [1]\n",
    "    angles = [0, np.pi/4, np.pi/2, 3*np.pi/4]\n",
    "    \n",
    "    glcm = graycomatrix(image_reduced, distances=distances, angles=angles,\n",
    "                        levels=64, symmetric=True, normed=True)\n",
    "    \n",
    "    # Extract GLCM properties (average over all directions)\n",
    "    features['glcm_contrast'] = graycoprops(glcm, 'contrast')[0].mean()\n",
    "    features['glcm_homogeneity'] = graycoprops(glcm, 'homogeneity')[0].mean()\n",
    "    features['glcm_energy'] = graycoprops(glcm, 'energy')[0].mean()\n",
    "    features['glcm_correlation'] = graycoprops(glcm, 'correlation')[0].mean()\n",
    "    \n",
    "    return features\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"GLCM TEXTURE FEATURES\")\n",
    "print(\"=\"*80 + \"\\n\")\n",
    "\n",
    "glcm_features_list = []\n",
    "for name, texture in zip(texture_names, textures):\n",
    "    features = extract_glcm_features(texture)\n",
    "    glcm_features_list.append(features)\n",
    "    \n",
    "    print(f\"üî¨ {name.upper()}:\")\n",
    "    print(f\"   Contrast:     {features['glcm_contrast']:.4f} (difference between neighbors)\")\n",
    "    print(f\"   Homogeneity:  {features['glcm_homogeneity']:.4f} (uniformity, 1.0 = very uniform)\")\n",
    "    print(f\"   Energy:       {features['glcm_energy']:.4f} (pattern repetition)\")\n",
    "    print(f\"   Correlation:  {features['glcm_correlation']:.4f} (directional pattern)\")\n",
    "    print()\n",
    "\n",
    "df_glcm = pd.DataFrame(glcm_features_list, index=texture_names)\n",
    "print(\"\\nüìä GLCM FEATURES COMPARISON:\")\n",
    "print(df_glcm.round(4))\n",
    "\n",
    "print(\"\\nüîç OBSERVATIONS:\")\n",
    "print(\"   ‚úì Smooth texture: High homogeneity, low contrast\")\n",
    "print(\"   ‚úì Rough texture: Low homogeneity, high contrast\")\n",
    "print(\"   ‚úì Regular patterns: High energy (repetitive)\")\n",
    "\n",
    "print(\"\\n‚úÖ GLCM features extracted successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "part4_header"
   },
   "source": [
    "---\n",
    "\n",
    "# Part 4: Complete Feature Extraction Pipeline üîÑ\n",
    "\n",
    "Now let's combine **ALL features** (shape + color + texture) into a single feature vector for classification!\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "complete_pipeline"
   },
   "source": [
    "## 4.1 Complete Feature Extraction Function\n",
    "\n",
    "This function extracts ALL features from an image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "extract_all_features"
   },
   "outputs": [],
   "source": [
    "def extract_all_features(image, contour=None):\n",
    "    \"\"\"\n",
    "    Extract comprehensive features: shape + color + texture.\n",
    "    \n",
    "    Args:\n",
    "        image: BGR color image\n",
    "        contour: Optional contour for shape features\n",
    "    \n",
    "    Returns:\n",
    "        Feature vector (numpy array)\n",
    "    \"\"\"\n",
    "    feature_vector = []\n",
    "    \n",
    "    # 1. SHAPE FEATURES (if contour provided)\n",
    "    if contour is not None:\n",
    "        shape_features = extract_shape_features(contour)\n",
    "        feature_vector.extend([\n",
    "            shape_features['area'],\n",
    "            shape_features['perimeter'],\n",
    "            shape_features['circularity'],\n",
    "            shape_features['aspect_ratio'],\n",
    "            shape_features['extent'],\n",
    "            shape_features['solidity'],\n",
    "            shape_features['hu_moment_1'],\n",
    "            shape_features['hu_moment_2']\n",
    "        ])\n",
    "    \n",
    "    # 2. COLOR FEATURES\n",
    "    color_features = extract_color_features(image)\n",
    "    feature_vector.extend([\n",
    "        color_features['mean_blue'],\n",
    "        color_features['mean_green'],\n",
    "        color_features['mean_red'],\n",
    "        color_features['std_blue'],\n",
    "        color_features['std_green'],\n",
    "        color_features['std_red'],\n",
    "        color_features['mean_hue'],\n",
    "        color_features['mean_saturation'],\n",
    "        color_features['mean_value']\n",
    "    ])\n",
    "    \n",
    "    # 3. TEXTURE FEATURES\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    simple_texture = extract_simple_texture_features(gray)\n",
    "    glcm_texture = extract_glcm_features(gray)\n",
    "    \n",
    "    feature_vector.extend([\n",
    "        simple_texture['std_dev'],\n",
    "        simple_texture['edge_density'],\n",
    "        glcm_texture['glcm_contrast'],\n",
    "        glcm_texture['glcm_homogeneity'],\n",
    "        glcm_texture['glcm_energy'],\n",
    "        glcm_texture['glcm_correlation']\n",
    "    ])\n",
    "    \n",
    "    return np.array(feature_vector)\n",
    "\n",
    "# Test with red circle\n",
    "test_contour = find_largest_contour(cv2.cvtColor(red_circle, cv2.COLOR_BGR2GRAY))\n",
    "test_features = extract_all_features(red_circle, test_contour)\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"COMPLETE FEATURE VECTOR EXAMPLE\")\n",
    "print(\"=\"*80 + \"\\n\")\n",
    "print(f\"Feature vector length: {len(test_features)} features\")\n",
    "print(f\"\\nFeature breakdown:\")\n",
    "print(f\"   Shape features:    8 values\")\n",
    "print(f\"   Color features:    9 values\")\n",
    "print(f\"   Texture features:  6 values\")\n",
    "print(f\"   Total:            {len(test_features)} values\")\n",
    "print(f\"\\nFirst 10 features: {test_features[:10]}\")\n",
    "\n",
    "print(\"\\n‚úÖ Complete feature extraction function ready!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "classification_header"
   },
   "source": [
    "---\n",
    "\n",
    "# Part 5: Classification Pipeline üéØ\n",
    "\n",
    "Now we'll use our extracted features to **classify objects** using traditional machine learning!\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "create_dataset"
   },
   "source": [
    "## 5.1 Create a Simple Dataset\n",
    "\n",
    "Let's create a small dataset of different colored shapes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "generate_dataset"
   },
   "outputs": [],
   "source": [
    "def create_dataset(num_samples_per_class=20):\n",
    "    \"\"\"\n",
    "    Create a synthetic dataset of colored shapes.\n",
    "    \n",
    "    Returns:\n",
    "        X: Feature matrix (samples √ó features)\n",
    "        y: Labels\n",
    "    \"\"\"\n",
    "    X = []\n",
    "    y = []\n",
    "    \n",
    "    classes = [\n",
    "        ('red_circle', (0, 0, 255)),\n",
    "        ('green_circle', (0, 255, 0)),\n",
    "        ('blue_square', (255, 0, 0))\n",
    "    ]\n",
    "    \n",
    "    for class_name, base_color in classes:\n",
    "        for _ in range(num_samples_per_class):\n",
    "            # Add some variation to color\n",
    "            color = tuple([int(c + np.random.randint(-30, 30)) for c in base_color])\n",
    "            color = tuple([max(0, min(255, c)) for c in color])  # Clip to valid range\n",
    "            \n",
    "            # Create shape\n",
    "            if 'circle' in class_name:\n",
    "                img = create_colored_circle(color=color)\n",
    "                gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "                contour = find_largest_contour(gray)\n",
    "            else:  # square\n",
    "                img = np.zeros((300, 300, 3), dtype=np.uint8)\n",
    "                pt1 = (75, 75)\n",
    "                pt2 = (225, 225)\n",
    "                cv2.rectangle(img, pt1, pt2, color, -1)\n",
    "                gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "                contour = find_largest_contour(gray)\n",
    "            \n",
    "            # Extract features\n",
    "            features = extract_all_features(img, contour)\n",
    "            X.append(features)\n",
    "            y.append(class_name)\n",
    "    \n",
    "    return np.array(X), np.array(y)\n",
    "\n",
    "# Create dataset\n",
    "print(\"\\n‚è≥ Creating dataset...\")\n",
    "X, y = create_dataset(num_samples_per_class=30)\n",
    "\n",
    "print(f\"\\n‚úÖ Dataset created!\")\n",
    "print(f\"   Total samples: {len(X)}\")\n",
    "print(f\"   Features per sample: {X.shape[1]}\")\n",
    "print(f\"   Classes: {np.unique(y)}\")\n",
    "print(f\"   Samples per class: {len(y[y == 'red_circle'])}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "train_classifiers"
   },
   "source": [
    "## 5.2 Train Multiple Classifiers\n",
    "\n",
    "Let's train three different classifiers and compare their performance!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "train_models"
   },
   "outputs": [],
   "source": [
    "# Split dataset\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42, stratify=y)\n",
    "\n",
    "print(f\"Training set: {len(X_train)} samples\")\n",
    "print(f\"Test set: {len(X_test)} samples\")\n",
    "\n",
    "# Normalize features\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "print(\"\\n‚úÖ Features normalized!\")\n",
    "\n",
    "# Train multiple classifiers\n",
    "classifiers = {\n",
    "    'K-Nearest Neighbors': KNeighborsClassifier(n_neighbors=3),\n",
    "    'Support Vector Machine': SVC(kernel='rbf', probability=True),\n",
    "    'Random Forest': RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "}\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"TRAINING CLASSIFIERS\")\n",
    "print(\"=\"*80 + \"\\n\")\n",
    "\n",
    "results = {}\n",
    "for name, clf in classifiers.items():\n",
    "    print(f\"ü§ñ Training {name}...\")\n",
    "    clf.fit(X_train_scaled, y_train)\n",
    "    y_pred = clf.predict(X_test_scaled)\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    results[name] = accuracy\n",
    "    print(f\"   Accuracy: {accuracy*100:.2f}%\")\n",
    "    print()\n",
    "\n",
    "print(\"\\n‚úÖ All classifiers trained!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "evaluate_models"
   },
   "source": [
    "## 5.3 Evaluate and Compare Classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "evaluation"
   },
   "outputs": [],
   "source": [
    "# Choose best classifier\n",
    "best_classifier_name = max(results, key=results.get)\n",
    "best_classifier = classifiers[best_classifier_name]\n",
    "y_pred = best_classifier.predict(X_test_scaled)\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(f\"BEST CLASSIFIER: {best_classifier_name}\")\n",
    "print(\"=\"*80 + \"\\n\")\n",
    "\n",
    "# Classification report\n",
    "print(\"üìä CLASSIFICATION REPORT:\\n\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "# Confusion matrix\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "class_names = np.unique(y)\n",
    "\n",
    "# Visualize confusion matrix\n",
    "plt.figure(figsize=(10, 8))\n",
    "plt.imshow(cm, interpolation='nearest', cmap='Blues')\n",
    "plt.title(f'Confusion Matrix - {best_classifier_name}', fontweight='bold', fontsize=14)\n",
    "plt.colorbar()\n",
    "tick_marks = np.arange(len(class_names))\n",
    "plt.xticks(tick_marks, class_names, rotation=45)\n",
    "plt.yticks(tick_marks, class_names)\n",
    "\n",
    "# Add numbers to cells\n",
    "thresh = cm.max() / 2.\n",
    "for i, j in np.ndindex(cm.shape):\n",
    "    plt.text(j, i, format(cm[i, j], 'd'),\n",
    "             ha=\"center\", va=\"center\",\n",
    "             color=\"white\" if cm[i, j] > thresh else \"black\",\n",
    "             fontsize=14, fontweight='bold')\n",
    "\n",
    "plt.ylabel('True Label', fontweight='bold')\n",
    "plt.xlabel('Predicted Label', fontweight='bold')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Compare all classifiers\n",
    "plt.figure(figsize=(10, 6))\n",
    "names = list(results.keys())\n",
    "accuracies = [results[name] * 100 for name in names]\n",
    "colors = ['skyblue', 'lightcoral', 'lightgreen']\n",
    "\n",
    "bars = plt.bar(names, accuracies, color=colors)\n",
    "plt.title('Classifier Comparison', fontweight='bold', fontsize=14)\n",
    "plt.ylabel('Accuracy (%)', fontweight='bold')\n",
    "plt.ylim([0, 110])\n",
    "plt.grid(axis='y', alpha=0.3)\n",
    "\n",
    "# Add value labels on bars\n",
    "for bar, acc in zip(bars, accuracies):\n",
    "    height = bar.get_height()\n",
    "    plt.text(bar.get_x() + bar.get_width()/2., height,\n",
    "             f'{acc:.1f}%',\n",
    "             ha='center', va='bottom', fontweight='bold')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\n‚úÖ Evaluation complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "prediction_demo"
   },
   "source": [
    "## 5.4 Test with New Images\n",
    "\n",
    "Let's create a new shape and see how our classifier performs!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "test_prediction"
   },
   "outputs": [],
   "source": [
    "def predict_shape(image, contour, classifier, scaler):\n",
    "    \"\"\"\n",
    "    Predict the class of a shape.\n",
    "    \n",
    "    Args:\n",
    "        image: BGR color image\n",
    "        contour: Shape contour\n",
    "        classifier: Trained classifier\n",
    "        scaler: Fitted scaler\n",
    "    \n",
    "    Returns:\n",
    "        Predicted class and probabilities\n",
    "    \"\"\"\n",
    "    # Extract features\n",
    "    features = extract_all_features(image, contour)\n",
    "    features_scaled = scaler.transform([features])\n",
    "    \n",
    "    # Predict\n",
    "    prediction = classifier.predict(features_scaled)[0]\n",
    "    probabilities = classifier.predict_proba(features_scaled)[0]\n",
    "    \n",
    "    return prediction, probabilities\n",
    "\n",
    "# Create test images\n",
    "test_red = create_colored_circle(color=(10, 10, 250))  # Red circle\n",
    "test_green = create_colored_circle(color=(10, 240, 10))  # Green circle\n",
    "test_blue_rect = np.zeros((300, 300, 3), dtype=np.uint8)\n",
    "cv2.rectangle(test_blue_rect, (75, 75), (225, 225), (240, 10, 10), -1)  # Blue square\n",
    "\n",
    "test_images = [test_red, test_green, test_blue_rect]\n",
    "test_names = ['Test Red Circle', 'Test Green Circle', 'Test Blue Square']\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"TESTING WITH NEW IMAGES\")\n",
    "print(\"=\"*80 + \"\\n\")\n",
    "\n",
    "fig, axes = plt.subplots(1, 3, figsize=(15, 5))\n",
    "\n",
    "for idx, (img, name) in enumerate(zip(test_images, test_names)):\n",
    "    # Find contour\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    contour = find_largest_contour(gray)\n",
    "    \n",
    "    # Predict\n",
    "    prediction, probs = predict_shape(img, contour, best_classifier, scaler)\n",
    "    \n",
    "    # Display\n",
    "    axes[idx].imshow(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))\n",
    "    axes[idx].set_title(f'{name}\\nPredicted: {prediction}', fontweight='bold')\n",
    "    axes[idx].axis('off')\n",
    "    \n",
    "    # Print results\n",
    "    print(f\"üîç {name}:\")\n",
    "    print(f\"   Predicted Class: {prediction}\")\n",
    "    print(f\"   Confidence: {max(probs)*100:.1f}%\")\n",
    "    print(f\"   All Probabilities:\")\n",
    "    for cls, prob in zip(best_classifier.classes_, probs):\n",
    "        print(f\"      {cls}: {prob*100:.1f}%\")\n",
    "    print()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"‚úÖ Prediction complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "summary"
   },
   "source": [
    "---\n",
    "\n",
    "# üéì Summary and Key Takeaways\n",
    "\n",
    "## What We Learned Today\n",
    "\n",
    "### 1. Shape Features (The Geometry Detective)\n",
    "- ‚úÖ Area, perimeter, circularity\n",
    "- ‚úÖ Aspect ratio, extent, solidity\n",
    "- ‚úÖ Hu moments (rotation-invariant shape fingerprints)\n",
    "\n",
    "### 2. Color Features (The Artist's Palette)\n",
    "- ‚úÖ Color histograms (distribution of colors)\n",
    "- ‚úÖ Statistical moments (mean, std dev)\n",
    "- ‚úÖ HSV color space features\n",
    "- ‚úÖ Dominant colors using K-means\n",
    "\n",
    "### 3. Texture Features (The Surface Detective)\n",
    "- ‚úÖ Edge density and standard deviation\n",
    "- ‚úÖ GLCM properties (contrast, homogeneity, energy, correlation)\n",
    "- ‚úÖ Understanding smooth vs rough textures\n",
    "\n",
    "### 4. Complete Pipeline\n",
    "- ‚úÖ Combined shape + color + texture features\n",
    "- ‚úÖ Feature vector normalization\n",
    "- ‚úÖ Training classifiers (KNN, SVM, Random Forest)\n",
    "- ‚úÖ Evaluation and comparison\n",
    "\n",
    "## The Big Picture\n",
    "\n",
    "```\n",
    "Raw Image (millions of pixels)\n",
    "          ‚Üì\n",
    "Feature Extraction (23 numbers)\n",
    "          ‚Üì\n",
    "Normalization (scaling)\n",
    "          ‚Üì\n",
    "Classification (KNN/SVM/RF)\n",
    "          ‚Üì\n",
    "Prediction (class label + confidence)\n",
    "```\n",
    "\n",
    "## Traditional ML vs Deep Learning\n",
    "\n",
    "**This Week (Manual Features):**\n",
    "- ‚úÖ WE design features (shape, color, texture)\n",
    "- ‚úÖ Works with small datasets\n",
    "- ‚úÖ Explainable (we know what the model sees)\n",
    "- ‚úÖ Fast to train\n",
    "\n",
    "**Next Week (CNNs - Module 4):**\n",
    "- ü§ñ CNN learns features automatically\n",
    "- ü§ñ Needs large datasets\n",
    "- ü§ñ Better accuracy on complex problems\n",
    "- ü§ñ Requires more computational power\n",
    "\n",
    "**Both approaches are valuable!** Use traditional features for:\n",
    "- Small datasets (< 1000 images)\n",
    "- When explainability is required\n",
    "- Resource-constrained environments\n",
    "- Domain-specific problems\n",
    "\n",
    "---\n",
    "\n",
    "## üìù Tutorial T9 Assessment Checklist\n",
    "\n",
    "Make sure you can:\n",
    "- [ ] Extract shape features from contours\n",
    "- [ ] Compute color histograms and moments\n",
    "- [ ] Calculate texture features (GLCM)\n",
    "- [ ] Build complete feature vectors\n",
    "- [ ] Train and evaluate classifiers\n",
    "- [ ] Understand when to use manual vs CNN features\n",
    "\n",
    "---\n",
    "\n",
    "## üöÄ Next Steps\n",
    "\n",
    "1. **Practice:** Try this notebook with your own images\n",
    "2. **Experiment:** Add more features (LBP, Gabor filters)\n",
    "3. **Compare:** Test different classifiers\n",
    "4. **Prepare:** Get ready for Week 10 - CNNs!\n",
    "\n",
    "---\n",
    "\n",
    "## üìö Additional Resources\n",
    "\n",
    "- OpenCV Documentation: https://docs.opencv.org/\n",
    "- Scikit-learn Guide: https://scikit-learn.org/stable/\n",
    "- Feature Extraction Tutorial: https://scikit-image.org/docs/stable/auto_examples/\n",
    "\n",
    "---\n",
    "\n",
    "**End of Tutorial T9**\n",
    "\n",
    "**Course:** 21CSE558T - Deep Neural Network Architectures  \n",
    "**Instructor:** Prof. Ramesh Babu  \n",
    "**SRM University - School of Computing**\n",
    "\n",
    "---"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
